{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflow_diabetes_NN1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "185un9A9yD0UUudXhmtQ5NU8cf3WkA7FF",
      "authorship_tag": "ABX9TyMY7+LPZN3lX8u0w9mHOpHd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HIsu1231/AI_INOVATION_SQUARE/blob/master/tensorflow_diabetes_NN1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3txQLSgwEr0",
        "outputId": "27e1b6d3-9dd9-4f36-c497-5294f98d4082"
      },
      "source": [
        "!pip uninstall tensorflow"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.3.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow-2.3.0.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUUDZ8DmyN_q",
        "outputId": "d8548f32-cd32-4ab0-c410-9accf9334796"
      },
      "source": [
        "!pip install tensorflow==1.15"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 32kB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 32.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.34.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.18.5)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.12.4)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 42.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.3.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.36.1)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.10.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.12.1)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.15) (50.3.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.4.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7542 sha256=e78abeffc85342eaefa9d5bc54c534bf1b26a986f2bf0087173f1b87e2ae3f0f\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, gast, keras-applications, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x26paz1EyU7f"
      },
      "source": [
        "import numpy as np\r\n",
        "import tensorflow as tf"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9KGdP-nOUeq"
      },
      "source": [
        "class DataGeneration():\r\n",
        "\r\n",
        "    def __init__(self, file_path, seperation_rate, target_position):\r\n",
        "\r\n",
        "        self.file_path = file_path\r\n",
        "\r\n",
        "        self.seperation_rate = seperation_rate\r\n",
        "\r\n",
        "        if target_position == -1 or target_postion == 0:\r\n",
        "            self.target_position = target_position\r\n",
        "        else:\r\n",
        "            str_err = 'target_position must be -1 or 0'\r\n",
        "            raise Exception(str_err)\r\n",
        "\r\n",
        "    def __display_target_distribution(self, data, str_of_kind):\r\n",
        "\r\n",
        "        target_data = data[:,target_position]\r\n",
        "        \r\n",
        "        unique, counts = np.unique(target_data, return_counts = True)\r\n",
        "\r\n",
        "        unique_target = []\r\n",
        "\r\n",
        "        print(\"=============================================================================================================\")\r\n",
        "        for i in range(len(unique)):\r\n",
        "\r\n",
        "            print(\"[Data Generation] unique number of \" + str_of_kind + \" = \", unique[i], \", count = \", counts[i])\r\n",
        "\r\n",
        "            unique_target.append(unique[i])\r\n",
        "\r\n",
        "            print(\"[Data Generation] unique number of \" + str_of_kind + \" = \", unique[i], \", ratio =  \",  np.round(100 * counts[i] / len(target_data),2), '%')\r\n",
        "        print(\"=============================================================================================================\")\r\n",
        "\r\n",
        "    def generate(self):\r\n",
        "\r\n",
        "          try: \r\n",
        "            loaded_data = np.loadtxt(self.file_path, delimiter=',', dtype=np.float32)\r\n",
        "          \r\n",
        "          except Exception as err:\r\n",
        "            print('[Data generation::generate()]', (str(err)))\r\n",
        "            raise Exception (str(err))\r\n",
        "\r\n",
        "          print(\"loaded_data.shape = \", loaded_data.shape)\r\n",
        "          self.__display_target_distribution(loaded_data, 'original data')\r\n",
        "\r\n",
        "          total_data_num = len(loaded_data)\r\n",
        "          test_data_num = int(total_data_num * self.seperation_rate)\r\n",
        "\r\n",
        "          np.random.shuffle(loaded_data)\r\n",
        "\r\n",
        "          test_data = loaded_data[0:test_data_num]\r\n",
        "          training_data = loaded_data[test_data_num: ]\r\n",
        "\r\n",
        "          self.__display_target_distribution(training_data, 'training data')\r\n",
        "          self.__display_target_distribution(test_data, 'test data')\r\n",
        "\r\n",
        "          return training_data, test_data"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i53Lc7dQY29m",
        "outputId": "997a9641-4261-4b62-af68-b63d9c07f6ec"
      },
      "source": [
        "file_path = './drive/MyDrive/AI_INOVATION_SQUARE/data/(200309)diabetes.csv'\r\n",
        "seperation_rate = 0.2\r\n",
        "target_position = -1\r\n",
        "\r\n",
        "data_obj = DataGeneration(file_path, seperation_rate, target_position)\r\n",
        "\r\n",
        "(training_data, test_data) = data_obj.generate()\r\n",
        "\r\n",
        "print(\"training_data.shape = \", training_data.shape)\r\n",
        "print(\"test_data.shape = \", test_data.shape)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loaded_data.shape =  (759, 9)\n",
            "=============================================================================================================\n",
            "[Data Generation] unique number of original data =  0.0 , count =  263\n",
            "[Data Generation] unique number of original data =  0.0 , ratio =   34.65 %\n",
            "[Data Generation] unique number of original data =  1.0 , count =  496\n",
            "[Data Generation] unique number of original data =  1.0 , ratio =   65.35 %\n",
            "=============================================================================================================\n",
            "=============================================================================================================\n",
            "[Data Generation] unique number of training data =  0.0 , count =  208\n",
            "[Data Generation] unique number of training data =  0.0 , ratio =   34.21 %\n",
            "[Data Generation] unique number of training data =  1.0 , count =  400\n",
            "[Data Generation] unique number of training data =  1.0 , ratio =   65.79 %\n",
            "=============================================================================================================\n",
            "=============================================================================================================\n",
            "[Data Generation] unique number of test data =  0.0 , count =  55\n",
            "[Data Generation] unique number of test data =  0.0 , ratio =   36.42 %\n",
            "[Data Generation] unique number of test data =  1.0 , count =  96\n",
            "[Data Generation] unique number of test data =  1.0 , ratio =   63.58 %\n",
            "=============================================================================================================\n",
            "training_data.shape =  (608, 9)\n",
            "test_data.shape =  (151, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsSA_Z3Iazfa",
        "outputId": "6d905d98-5cf3-46fc-fc4f-318b7bdbf816"
      },
      "source": [
        "training_x_data = training_data[:,0:-1]\r\n",
        "training_t_data = training_data[:, [-1]]\r\n",
        "\r\n",
        "print(\"training_x_data.shape = \", training_x_data.shape)\r\n",
        "print(\"training_t_data.shape = \", training_t_data.shape)\r\n",
        "\r\n",
        "test_x_data = test_data[:, 0:-1]\r\n",
        "test_t_data = test_data[:, [-1]]\r\n",
        "\r\n",
        "print(\"test_x_data.shape = \", test_x_data.shape)\r\n",
        "print(\"test_t_data.shape = \", test_t_data.shape)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training_x_data.shape =  (608, 8)\n",
            "training_t_data.shape =  (608, 1)\n",
            "test_x_data.shape =  (151, 8)\n",
            "test_t_data.shape =  (151, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eM3V6g9ib-vE"
      },
      "source": [
        "input_nodes = training_x_data.shape[1]\r\n",
        "hidden_nodes = 30\r\n",
        "output_nodes = 1"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcceQ2P2cgq5"
      },
      "source": [
        "X = tf.placeholder(tf.float32, [None,input_nodes])\r\n",
        "T = tf.placeholder(tf.float32, [None,output_nodes])\r\n",
        "\r\n",
        "W2 = tf.Variable(tf.random_normal([input_nodes, hidden_nodes]))\r\n",
        "b2 = tf.Variable(tf.random_normal([hidden_nodes]))\r\n",
        "\r\n",
        "W3 = tf.Variable(tf.random_normal([hidden_nodes, output_nodes]))\r\n",
        "b3 = tf.Variable(tf.random_normal([output_nodes]))"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-bdd75Oc4pL"
      },
      "source": [
        "z2 = tf.matmul(X,W2) + b2\r\n",
        "a2 = tf.sigmoid(z2)\r\n",
        "\r\n",
        "z3 = tf.matmul(a2,W3) + b3\r\n",
        "y = tf.sigmoid(z3)\r\n",
        "\r\n",
        "loss = -tf.reduce_mean(T * tf.log(y) + (1-T) * tf.log(1-y))"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYZgMOv7dKlX"
      },
      "source": [
        "learning_rate = 1e-1\r\n",
        "\r\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\r\n",
        "\r\n",
        "train = optimizer.minimize(loss)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvNz-8vBdeTn"
      },
      "source": [
        "predicted = tf.cast(y>0.5, dtype=tf.float32)\r\n",
        "\r\n",
        "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted,T),dtype=tf.float32))"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6KQkY7ldtxE",
        "outputId": "fb6ed209-4132-4aa4-98a0-2a96e43a6a5f"
      },
      "source": [
        "with tf.Session() as sess:\r\n",
        "\r\n",
        "    sess.run(tf.global_variables_initializer())\r\n",
        "\r\n",
        "    for i in range(10001):\r\n",
        "\r\n",
        "        loss_val, _ = sess.run([loss, train], feed_dict={X: training_x_data, T: training_t_data}) \r\n",
        "\r\n",
        "        if i % 500 == 0:\r\n",
        "            print(\"step = \", i, \", loss value = \", loss_val)\r\n",
        "\r\n",
        "    y_val, predicted_val, accuracy_val = sess.run([y, predicted, accuracy], feed_dict={X:test_x_data, T: test_t_data })\r\n",
        "\r\n",
        "    print(\"\\ny_val.shape = \", y_val.shape, \", predicted_val.shape = \", predicted_val.shape)\r\n",
        "    print(\"\\nAccuracy = \",accuracy_val)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step =  0 , loss value =  0.8513866\n",
            "step =  500 , loss value =  0.4961977\n",
            "step =  1000 , loss value =  0.47970968\n",
            "step =  1500 , loss value =  0.47412863\n",
            "step =  2000 , loss value =  0.4706198\n",
            "step =  2500 , loss value =  0.4676843\n",
            "step =  3000 , loss value =  0.46496743\n",
            "step =  3500 , loss value =  0.4623398\n",
            "step =  4000 , loss value =  0.45974225\n",
            "step =  4500 , loss value =  0.45714915\n",
            "step =  5000 , loss value =  0.45455432\n",
            "step =  5500 , loss value =  0.45196423\n",
            "step =  6000 , loss value =  0.44939333\n",
            "step =  6500 , loss value =  0.44686136\n",
            "step =  7000 , loss value =  0.44438994\n",
            "step =  7500 , loss value =  0.44200054\n",
            "step =  8000 , loss value =  0.43971214\n",
            "step =  8500 , loss value =  0.4375397\n",
            "step =  9000 , loss value =  0.43549317\n",
            "step =  9500 , loss value =  0.43357745\n",
            "step =  10000 , loss value =  0.43179256\n",
            "\n",
            "y_val.shape =  (151, 1) , predicted_val.shape =  (151, 1)\n",
            "\n",
            "Accuracy =  0.77483445\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}