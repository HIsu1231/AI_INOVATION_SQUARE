{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_RandomRand.ipynb",
      "provenance": [],
      "mount_file_id": "1QXa37u1jn8c4HVsurv746cf9WGmznicF",
      "authorship_tag": "ABX9TyMkEvJ84/U9CNlts01uxuuH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HIsu1231/AI_INOVATION_SQUARE/blob/master/MNIST_RandomRand.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlkHP_vJaCyt"
      },
      "source": [
        "import numpy as np\n",
        "from datetime import datetime"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kwIBw96hHXz"
      },
      "source": [
        "# 수치미분 함수\n",
        "\n",
        "def numerical_derivative(f, x):\n",
        "    delta_x = 1e-4 # 0.0001\n",
        "    grad = np.zeros_like(x)\n",
        "    \n",
        "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
        "    \n",
        "    while not it.finished:\n",
        "        idx = it.multi_index        \n",
        "        tmp_val = x[idx]\n",
        "        x[idx] = float(tmp_val) + delta_x\n",
        "        fx1 = f(x) # f(x+delta_x)\n",
        "        \n",
        "        x[idx] = tmp_val - delta_x \n",
        "        fx2 = f(x) # f(x-delta_x)\n",
        "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
        "        \n",
        "        x[idx] = tmp_val \n",
        "        it.iternext()   \n",
        "        \n",
        "    return grad\n",
        "\n",
        "# sigmoid 함수\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1+np.exp(-x))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XTYB_0eanI6",
        "outputId": "62420d23-d254-47c9-f0b4-53a308aac0fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "training_data = np.loadtxt(\"./drive/My Drive/AI_INOVATION_SQUARE/prac/mnist_train.csv\",delimiter=',',dtype=np.float32)\n",
        "print(\"training data.shape = \",training_data.shape)\n",
        "\n",
        "test_data = np.loadtxt('./drive/My Drive/AI_INOVATION_SQUARE/prac/mnist_test.csv',delimiter=',',dtype=np.float32)\n",
        "\n",
        "print(\"test data.shape = \",test_data.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training data.shape =  (60000, 785)\n",
            "test data.shape =  (10000, 785)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sn9lFC4tgDh_"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7xsvhbIc4OQ"
      },
      "source": [
        "class MNIST_Test:\n",
        "  \n",
        "  def __init__(self, i_nodes, h_nodes, o_nodes, learning_rate):\n",
        "\n",
        "    self.W2 = np.random.rand(i_nodes,h_nodes)\n",
        "    self.b2 = np.random.rand(h_nodes)\n",
        "\n",
        "    self.W3 = np.random.rand(h_nodes,o_nodes)\n",
        "    self.b3 = np.random.rand(o_nodes)\n",
        "\n",
        "    self.learning_rate = learning_rate\n",
        "\n",
        "  def feed_forward(self):\n",
        "\n",
        "    delta = 1e-7\n",
        "\n",
        "    z2 = np.dot(self.input_data, self.W2) + self.b2\n",
        "    a2 = sigmoid(z2)\n",
        "\n",
        "    z3 = np.dot(a2, self.W3) + self.b3\n",
        "    y = a3 = sigmoid(z3)\n",
        "\n",
        "    return -np.sum(self.target_data*np.log(y+delta) + (1-self.target_data)*np.log((1-y)+delta))\n",
        "\n",
        "  def loss_val(self):\n",
        "    \n",
        "    delta = 1e-7\n",
        "\n",
        "    z2 = np.dot(self.input_data,self.W2) + self.b2\n",
        "    a2 = sigmoid(z2)\n",
        "\n",
        "    z3 = np.dot(a2,self.W3) + self.b3\n",
        "    y = a3 = sigmoid(z3)\n",
        "\n",
        "    return -np.sum(self.target_data*np.log(y+delta) + (1-self.target_data)*np.log((1-y)+delta))\n",
        "\n",
        "  def predict(self, input_data):\n",
        "    \n",
        "    z2 = np.dot(input_data, self.W2) + selfb2\n",
        "    a2 = sigmoid(z2)\n",
        "\n",
        "    z3 = np.dot(a2, self.W3) + self.b3\n",
        "    y = a3 = sigmoid(z3)\n",
        "\n",
        "    predicted_num = np.argmax(y)\n",
        "\n",
        "    return predicted_num\n",
        "  \n",
        "  def accuracy(self, input_data, target_data):\n",
        "\n",
        "    matched_list = []\n",
        "    unmatched_list = []\n",
        "\n",
        "    for i in range(len(input_data)):\n",
        "\n",
        "      label = int(target_data[i])\n",
        "      predicted_num = self.predict(input_data[i])\n",
        "\n",
        "      if label == predicted_num:\n",
        "        matched_list.append(i)\n",
        "      else:\n",
        "        unmatched_list.append(i)\n",
        "\n",
        "    accuracy_result = len(matched_list)/len(input_data)\n",
        "\n",
        "    print(\"Current Accuracy = \",accuracy_result)\n",
        "\n",
        "    return unmatched_list, accuracy_list      \n",
        "\n",
        "  def train(self,input_data, target_data):\n",
        "\n",
        "    self.input_data = input_data\n",
        "    self.target_data = target_data\n",
        "\n",
        "    f = lambda x : self.feed_forward()\n",
        "\n",
        "    self.W2 -= self.learning_rate * numerical_derivative(f,self.W2)\n",
        "    self.b2 -= self.learning_rate * numerical_derivative(f,self.b2)\n",
        "\n",
        "    self.W3 -= self.learning_rate * numerical_derivative(f,self.W3)\n",
        "    self.b3 -= self.learning_rate * numerical_derivative(f,self.b3)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhfu9SoifNba",
        "outputId": "d792432b-ba26-4dc4-9767-90f8f36d9491",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#hyper_parameter\n",
        "i_nodes = training_data.shape[1] - 1\n",
        "h_nodes = 1\n",
        "o_nodes = 10\n",
        "lr = 1e-2\n",
        "epochs = 1\n",
        "\n",
        "loss_val_list = []\n",
        "\n",
        "obj1 = MNIST_Test(i_nodes,h_nodes,o_nodes,lr)\n",
        "\n",
        "print(\"Neural Network Learning using Numerical Derivative...\")\n",
        "\n",
        "start_time = datetime.now()\n",
        "\n",
        "for step in range(epochs):\n",
        "  for i in range(len(training_data)):\n",
        "\n",
        "    input_data = ((training_data[i,1:]/255.0)*0.99)+0.01\n",
        "\n",
        "    target_data = np.zeros(10) + 0.01\n",
        "    target_data[int(training_data[i,0])] = 0.99\n",
        "\n",
        "    obj1.train(input_data,target_data)\n",
        "  \n",
        "    cur_loss_val = obj1.loss_val()\n",
        "    loss_val_list.append(cur_loss_val)\n",
        "\n",
        "    if i % 2000 == 0:\n",
        "     print(\"step = \",step,\"index = \",i,\", loss value = \",cur_loss_val)\n",
        "\n",
        "end_time = datetime.now()\n",
        "\n",
        "print(\"\")\n",
        "print(\"Elapsed time -> \",end_time - start_time)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Neural Network Learning using Numerical Derivative...\n",
            "step =  0 index =  0 , loss value =  11.045640595946159\n",
            "step =  0 index =  2000 , loss value =  3.4831233515642066\n",
            "step =  0 index =  4000 , loss value =  3.3374445173157112\n",
            "step =  0 index =  6000 , loss value =  3.289161159701995\n",
            "step =  0 index =  8000 , loss value =  3.351020314376909\n",
            "step =  0 index =  10000 , loss value =  3.334365885194155\n",
            "step =  0 index =  12000 , loss value =  3.350464221579765\n",
            "step =  0 index =  14000 , loss value =  3.3197472222167144\n",
            "step =  0 index =  16000 , loss value =  3.483924849544534\n",
            "step =  0 index =  18000 , loss value =  3.2821303177297616\n",
            "step =  0 index =  20000 , loss value =  3.3610273869133356\n",
            "step =  0 index =  22000 , loss value =  3.3076867030843906\n",
            "step =  0 index =  24000 , loss value =  3.4640807474914213\n",
            "step =  0 index =  26000 , loss value =  3.3172631948639766\n",
            "step =  0 index =  28000 , loss value =  3.2884439427563246\n",
            "step =  0 index =  30000 , loss value =  3.5427267356352337\n",
            "step =  0 index =  32000 , loss value =  3.4687860340833896\n",
            "step =  0 index =  34000 , loss value =  3.3471348191974455\n",
            "step =  0 index =  36000 , loss value =  3.4577210040286817\n",
            "step =  0 index =  38000 , loss value =  3.390739682087498\n",
            "step =  0 index =  40000 , loss value =  3.4781858461534254\n",
            "step =  0 index =  42000 , loss value =  3.1531866269250868\n",
            "step =  0 index =  44000 , loss value =  3.576535455574109\n",
            "step =  0 index =  46000 , loss value =  3.4548604207255327\n",
            "step =  0 index =  48000 , loss value =  3.545412797922583\n",
            "step =  0 index =  50000 , loss value =  3.299071724353978\n",
            "step =  0 index =  52000 , loss value =  3.4458657413124643\n",
            "step =  0 index =  54000 , loss value =  3.4452285337833466\n",
            "step =  0 index =  56000 , loss value =  3.4580967539714162\n",
            "step =  0 index =  58000 , loss value =  3.2608579916952256\n",
            "\n",
            "Elapsed time ->  0:53:05.887053\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyvW4pLLg-lA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}