{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_5X5X32_Filter.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOz27gvAV8Zk+d+LY9Rn14R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HIsu1231/AI_INOVATION_SQUARE/blob/master/CNN_5X5X32_Filter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJcO-2dSRcaK",
        "outputId": "5085a910-1105-44e2-cdf8-1de3ce443ae5"
      },
      "source": [
        "!pip uninstall tensorflow"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.4.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow-2.4.0.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlipDzyLRgBy",
        "outputId": "7ab1624f-6057-4d45-aece-2181cd668321"
      },
      "source": [
        "!pip install tensorflow==1.15"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 23kB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.19.4)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.12.4)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 38.1MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 42.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.12.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.36.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.10.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.32.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.3.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.15) (50.3.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.7.4.3)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=1bdd8d662a17ff70b939c76e84a813dfb691212f13df462a7daf5fa709bc5e34\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: keras-applications, tensorboard, tensorflow-estimator, gast, tensorflow\n",
            "  Found existing installation: tensorboard 2.4.0\n",
            "    Uninstalling tensorboard-2.4.0:\n",
            "      Successfully uninstalled tensorboard-2.4.0\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-4Qsx9hRi64",
        "outputId": "3292254f-e937-4e63-a984-586be255d9c2"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow.examples.tutorials.mnist import input_data\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from datetime import datetime\r\n",
        "\r\n",
        "mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)\r\n",
        "\r\n",
        "print(\"train images shape = \", mnist.train.images.shape)\r\n",
        "print(\"train labels shape = \", mnist.train.labels.shape )\r\n",
        "print(\"test images shape = \", mnist.test.images.shape)\r\n",
        "print(\"test lables shape = \", mnist.test.labels.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-4-661935e51e88>:7: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "train images shape =  (55000, 784)\n",
            "train labels shape =  (55000, 10)\n",
            "test images shape =  (10000, 784)\n",
            "test lables shape =  (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llCq2uvkSCNo"
      },
      "source": [
        "i_nodes = mnist.train.images.shape[1]\r\n",
        "o_nodes = mnist.train.labels.shape[1]\r\n",
        "\r\n",
        "#hyper_parameter\r\n",
        "learning_rate = 0.001\r\n",
        "epochs = 30\r\n",
        "batch_size = 100\r\n",
        "\r\n",
        "X = tf.placeholder(tf.float32, [None,i_nodes])\r\n",
        "T = tf.placeholder(tf.float32, [None,o_nodes])\r\n",
        "\r\n",
        "A1 = tf.reshape(X, [-1,28,28,1]) #28X28X1"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neHvSbaPTrbd"
      },
      "source": [
        "#5X5X32 Filter\r\n",
        "W2 = tf.Variable(tf.random_normal([5,5,1,32], stddev = 0.01))\r\n",
        "b2 = tf.Variable(tf.random_normal([32]))\r\n",
        "\r\n",
        "#28X28X32\r\n",
        "C2 = tf.nn.conv2d(A1, W2, strides =[1,1,1,1], padding='SAME')\r\n",
        "\r\n",
        "Z2 = tf.nn.relu(C2+b2)\r\n",
        "\r\n",
        "#14X14X32 (합성곱층에 zero-padding을 사용하며, 이 경우에는 출력 특성맵의 크기는 입력을 스트라이드로 나눈 다음 올림 한 것과 같다\r\n",
        "A2 = tf.nn.max_pool(Z2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\r\n",
        "\r\n",
        "\r\n",
        "A2_flat = tf.reshape(A2, [-1, 14*14*32])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2k-sOuNT8Fh"
      },
      "source": [
        "W3 = tf.Variable(tf.random_normal([14*14*32,10],stddev=0.01))\r\n",
        "b3 = tf.Variable(tf.random_normal([10]))\r\n",
        "\r\n",
        "Z3 = tf.matmul(A2_flat,W3) + b3\r\n",
        "\r\n",
        "A3 = tf.nn.softmax(Z3)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aT1ShbRVZ4B"
      },
      "source": [
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=Z3, labels=T))\r\n",
        "\r\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\r\n",
        "\r\n",
        "train = optimizer.minimize(loss)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mgjh8CAVwHM"
      },
      "source": [
        "predicted_val = tf.argmax(A3,1)\r\n",
        "\r\n",
        "predicted = tf.cast(tf.equal(tf.argmax(A3,1), tf.argmax(T,1)), dtype=tf.float32)\r\n",
        "\r\n",
        "accuracy = tf.reduce_mean(predicted)\r\n",
        "\r\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QArHBBOjWDgO",
        "outputId": "88e701a2-54e6-4d2f-cdbd-a6eaf80796e5"
      },
      "source": [
        "with tf.Session() as sess:\r\n",
        "\r\n",
        "    sess.run(tf.global_variables_initializer())\r\n",
        "\r\n",
        "    start_time = datetime.now()\r\n",
        "\r\n",
        "    false_list = []\r\n",
        "\r\n",
        "    for i in range(epochs):\r\n",
        "\r\n",
        "        total_batch = int(mnist.train.num_examples / batch_size)\r\n",
        "\r\n",
        "        for step in range(total_batch):\r\n",
        "\r\n",
        "            batch_x_data, batch_t_data = mnist.train.next_batch(batch_size)\r\n",
        "\r\n",
        "            loss_val, _ = sess.run([loss, train], feed_dict={X: batch_x_data, T: batch_t_data})  \r\n",
        "            \r\n",
        "            if step % 100 == 0:\r\n",
        "\r\n",
        "                print(\"epochs = \", i, \", step = \", step, \", loss value = \", loss_val)\r\n",
        "\r\n",
        "    end_time = datetime.now()\r\n",
        "\r\n",
        "    print(\"\\nElapsed time = \", end_time - start_time)\r\n",
        "\r\n",
        "\r\n",
        "    test_x_data = mnist.test.images\r\n",
        "    test_t_data = mnist.test.labels\r\n",
        "\r\n",
        "\r\n",
        "    accuracy_val, predicted_list, index_label = sess.run([accuracy, predicted_val, predicted], feed_dict={X: test_x_data, T: test_t_data})\r\n",
        "\r\n",
        "    index_label_list = list(index_label)\r\n",
        "    print(\"Accuracy = \", accuracy_val)\r\n",
        "    print(\"false label count = \",index_label_list.count([0]))\r\n",
        "\r\n",
        "    temp_list = []\r\n",
        "    index_label_prediction_list = []\r\n",
        "\r\n",
        "    for i in range(len(index_label)):\r\n",
        "\r\n",
        "      if index_label[i] == 0:\r\n",
        "\r\n",
        "          temp_list.append(i)\r\n",
        "          temp_list.append(np.argmax(test_t_data[i]))\r\n",
        "          temp_list.append(predicted_list[i])\r\n",
        "\r\n",
        "          index_label_prediction_list.append(temp_list)\r\n",
        "\r\n",
        "          temp_list = []"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epochs =  0 , step =  0 , loss value =  2.9748945\n",
            "epochs =  0 , step =  100 , loss value =  0.7350495\n",
            "epochs =  0 , step =  200 , loss value =  0.46770412\n",
            "epochs =  0 , step =  300 , loss value =  0.3555438\n",
            "epochs =  0 , step =  400 , loss value =  0.2542687\n",
            "epochs =  0 , step =  500 , loss value =  0.19231388\n",
            "epochs =  1 , step =  0 , loss value =  0.2186991\n",
            "epochs =  1 , step =  100 , loss value =  0.0647089\n",
            "epochs =  1 , step =  200 , loss value =  0.09715272\n",
            "epochs =  1 , step =  300 , loss value =  0.17685626\n",
            "epochs =  1 , step =  400 , loss value =  0.13786513\n",
            "epochs =  1 , step =  500 , loss value =  0.17679475\n",
            "epochs =  2 , step =  0 , loss value =  0.061761826\n",
            "epochs =  2 , step =  100 , loss value =  0.16051227\n",
            "epochs =  2 , step =  200 , loss value =  0.124439165\n",
            "epochs =  2 , step =  300 , loss value =  0.04139178\n",
            "epochs =  2 , step =  400 , loss value =  0.055228893\n",
            "epochs =  2 , step =  500 , loss value =  0.16658299\n",
            "epochs =  3 , step =  0 , loss value =  0.032243267\n",
            "epochs =  3 , step =  100 , loss value =  0.058400284\n",
            "epochs =  3 , step =  200 , loss value =  0.04173126\n",
            "epochs =  3 , step =  300 , loss value =  0.021049554\n",
            "epochs =  3 , step =  400 , loss value =  0.089616254\n",
            "epochs =  3 , step =  500 , loss value =  0.04177524\n",
            "epochs =  4 , step =  0 , loss value =  0.072698265\n",
            "epochs =  4 , step =  100 , loss value =  0.029675433\n",
            "epochs =  4 , step =  200 , loss value =  0.018297547\n",
            "epochs =  4 , step =  300 , loss value =  0.20549601\n",
            "epochs =  4 , step =  400 , loss value =  0.052265786\n",
            "epochs =  4 , step =  500 , loss value =  0.012389817\n",
            "epochs =  5 , step =  0 , loss value =  0.1045825\n",
            "epochs =  5 , step =  100 , loss value =  0.09226977\n",
            "epochs =  5 , step =  200 , loss value =  0.03453295\n",
            "epochs =  5 , step =  300 , loss value =  0.032239385\n",
            "epochs =  5 , step =  400 , loss value =  0.047113847\n",
            "epochs =  5 , step =  500 , loss value =  0.09233055\n",
            "epochs =  6 , step =  0 , loss value =  0.046820693\n",
            "epochs =  6 , step =  100 , loss value =  0.025987849\n",
            "epochs =  6 , step =  200 , loss value =  0.035600565\n",
            "epochs =  6 , step =  300 , loss value =  0.10514708\n",
            "epochs =  6 , step =  400 , loss value =  0.026199972\n",
            "epochs =  6 , step =  500 , loss value =  0.020974882\n",
            "epochs =  7 , step =  0 , loss value =  0.02795302\n",
            "epochs =  7 , step =  100 , loss value =  0.04608395\n",
            "epochs =  7 , step =  200 , loss value =  0.053271614\n",
            "epochs =  7 , step =  300 , loss value =  0.052108537\n",
            "epochs =  7 , step =  400 , loss value =  0.053990103\n",
            "epochs =  7 , step =  500 , loss value =  0.042297233\n",
            "epochs =  8 , step =  0 , loss value =  0.0555614\n",
            "epochs =  8 , step =  100 , loss value =  0.02256248\n",
            "epochs =  8 , step =  200 , loss value =  0.067966014\n",
            "epochs =  8 , step =  300 , loss value =  0.016697682\n",
            "epochs =  8 , step =  400 , loss value =  0.0068186847\n",
            "epochs =  8 , step =  500 , loss value =  0.03997717\n",
            "epochs =  9 , step =  0 , loss value =  0.035972904\n",
            "epochs =  9 , step =  100 , loss value =  0.060641453\n",
            "epochs =  9 , step =  200 , loss value =  0.020132856\n",
            "epochs =  9 , step =  300 , loss value =  0.012028158\n",
            "epochs =  9 , step =  400 , loss value =  0.025811996\n",
            "epochs =  9 , step =  500 , loss value =  0.05907711\n",
            "epochs =  10 , step =  0 , loss value =  0.00413307\n",
            "epochs =  10 , step =  100 , loss value =  0.023117187\n",
            "epochs =  10 , step =  200 , loss value =  0.014607612\n",
            "epochs =  10 , step =  300 , loss value =  0.15403032\n",
            "epochs =  10 , step =  400 , loss value =  0.02773727\n",
            "epochs =  10 , step =  500 , loss value =  0.031120054\n",
            "epochs =  11 , step =  0 , loss value =  0.06854822\n",
            "epochs =  11 , step =  100 , loss value =  0.02816551\n",
            "epochs =  11 , step =  200 , loss value =  0.06871306\n",
            "epochs =  11 , step =  300 , loss value =  0.010616896\n",
            "epochs =  11 , step =  400 , loss value =  0.0068959277\n",
            "epochs =  11 , step =  500 , loss value =  0.033516057\n",
            "epochs =  12 , step =  0 , loss value =  0.019616961\n",
            "epochs =  12 , step =  100 , loss value =  0.02436039\n",
            "epochs =  12 , step =  200 , loss value =  0.008778711\n",
            "epochs =  12 , step =  300 , loss value =  0.21483283\n",
            "epochs =  12 , step =  400 , loss value =  0.028265798\n",
            "epochs =  12 , step =  500 , loss value =  0.04190298\n",
            "epochs =  13 , step =  0 , loss value =  0.004883124\n",
            "epochs =  13 , step =  100 , loss value =  0.053684827\n",
            "epochs =  13 , step =  200 , loss value =  0.012513537\n",
            "epochs =  13 , step =  300 , loss value =  0.0063834274\n",
            "epochs =  13 , step =  400 , loss value =  0.05130128\n",
            "epochs =  13 , step =  500 , loss value =  0.010201246\n",
            "epochs =  14 , step =  0 , loss value =  0.021879755\n",
            "epochs =  14 , step =  100 , loss value =  0.016280586\n",
            "epochs =  14 , step =  200 , loss value =  0.041426096\n",
            "epochs =  14 , step =  300 , loss value =  0.011425395\n",
            "epochs =  14 , step =  400 , loss value =  0.06606011\n",
            "epochs =  14 , step =  500 , loss value =  0.033542246\n",
            "epochs =  15 , step =  0 , loss value =  0.023002861\n",
            "epochs =  15 , step =  100 , loss value =  0.014829335\n",
            "epochs =  15 , step =  200 , loss value =  0.012624823\n",
            "epochs =  15 , step =  300 , loss value =  0.007033092\n",
            "epochs =  15 , step =  400 , loss value =  0.07048908\n",
            "epochs =  15 , step =  500 , loss value =  0.060136557\n",
            "epochs =  16 , step =  0 , loss value =  0.03563632\n",
            "epochs =  16 , step =  100 , loss value =  0.015435521\n",
            "epochs =  16 , step =  200 , loss value =  0.01604784\n",
            "epochs =  16 , step =  300 , loss value =  0.004487445\n",
            "epochs =  16 , step =  400 , loss value =  0.03793906\n",
            "epochs =  16 , step =  500 , loss value =  0.008339102\n",
            "epochs =  17 , step =  0 , loss value =  0.009357167\n",
            "epochs =  17 , step =  100 , loss value =  0.008104938\n",
            "epochs =  17 , step =  200 , loss value =  0.037217755\n",
            "epochs =  17 , step =  300 , loss value =  0.010610469\n",
            "epochs =  17 , step =  400 , loss value =  0.0073602796\n",
            "epochs =  17 , step =  500 , loss value =  0.003336972\n",
            "epochs =  18 , step =  0 , loss value =  0.017073844\n",
            "epochs =  18 , step =  100 , loss value =  0.0052560335\n",
            "epochs =  18 , step =  200 , loss value =  0.0071112877\n",
            "epochs =  18 , step =  300 , loss value =  0.042240728\n",
            "epochs =  18 , step =  400 , loss value =  0.015160545\n",
            "epochs =  18 , step =  500 , loss value =  0.024353165\n",
            "epochs =  19 , step =  0 , loss value =  0.010963082\n",
            "epochs =  19 , step =  100 , loss value =  0.019910557\n",
            "epochs =  19 , step =  200 , loss value =  0.018291403\n",
            "epochs =  19 , step =  300 , loss value =  0.005303078\n",
            "epochs =  19 , step =  400 , loss value =  0.021650547\n",
            "epochs =  19 , step =  500 , loss value =  0.0059534647\n",
            "epochs =  20 , step =  0 , loss value =  0.008832854\n",
            "epochs =  20 , step =  100 , loss value =  0.005129341\n",
            "epochs =  20 , step =  200 , loss value =  0.0023899663\n",
            "epochs =  20 , step =  300 , loss value =  0.018953383\n",
            "epochs =  20 , step =  400 , loss value =  0.023569712\n",
            "epochs =  20 , step =  500 , loss value =  0.028539522\n",
            "epochs =  21 , step =  0 , loss value =  0.0010905231\n",
            "epochs =  21 , step =  100 , loss value =  0.0132067045\n",
            "epochs =  21 , step =  200 , loss value =  0.006214386\n",
            "epochs =  21 , step =  300 , loss value =  0.027659252\n",
            "epochs =  21 , step =  400 , loss value =  0.0056558726\n",
            "epochs =  21 , step =  500 , loss value =  0.0064626397\n",
            "epochs =  22 , step =  0 , loss value =  0.008635818\n",
            "epochs =  22 , step =  100 , loss value =  0.023352413\n",
            "epochs =  22 , step =  200 , loss value =  0.00633855\n",
            "epochs =  22 , step =  300 , loss value =  0.021087006\n",
            "epochs =  22 , step =  400 , loss value =  0.087728694\n",
            "epochs =  22 , step =  500 , loss value =  0.008030376\n",
            "epochs =  23 , step =  0 , loss value =  0.010045997\n",
            "epochs =  23 , step =  100 , loss value =  0.0019693116\n",
            "epochs =  23 , step =  200 , loss value =  0.00747672\n",
            "epochs =  23 , step =  300 , loss value =  0.014345776\n",
            "epochs =  23 , step =  400 , loss value =  0.010371533\n",
            "epochs =  23 , step =  500 , loss value =  0.004696531\n",
            "epochs =  24 , step =  0 , loss value =  0.00054912403\n",
            "epochs =  24 , step =  100 , loss value =  0.04928619\n",
            "epochs =  24 , step =  200 , loss value =  0.0030739491\n",
            "epochs =  24 , step =  300 , loss value =  0.008819092\n",
            "epochs =  24 , step =  400 , loss value =  0.003873674\n",
            "epochs =  24 , step =  500 , loss value =  0.009811167\n",
            "epochs =  25 , step =  0 , loss value =  0.032718107\n",
            "epochs =  25 , step =  100 , loss value =  0.016093252\n",
            "epochs =  25 , step =  200 , loss value =  0.007049041\n",
            "epochs =  25 , step =  300 , loss value =  0.010269456\n",
            "epochs =  25 , step =  400 , loss value =  0.01626602\n",
            "epochs =  25 , step =  500 , loss value =  0.0033770048\n",
            "epochs =  26 , step =  0 , loss value =  0.0065751527\n",
            "epochs =  26 , step =  100 , loss value =  0.003946601\n",
            "epochs =  26 , step =  200 , loss value =  0.0078009553\n",
            "epochs =  26 , step =  300 , loss value =  0.013807125\n",
            "epochs =  26 , step =  400 , loss value =  0.0054956847\n",
            "epochs =  26 , step =  500 , loss value =  0.005432901\n",
            "epochs =  27 , step =  0 , loss value =  0.010987883\n",
            "epochs =  27 , step =  100 , loss value =  0.009152195\n",
            "epochs =  27 , step =  200 , loss value =  0.0032793903\n",
            "epochs =  27 , step =  300 , loss value =  0.0025447775\n",
            "epochs =  27 , step =  400 , loss value =  0.00683868\n",
            "epochs =  27 , step =  500 , loss value =  0.0037622044\n",
            "epochs =  28 , step =  0 , loss value =  0.0041665207\n",
            "epochs =  28 , step =  100 , loss value =  0.0104493955\n",
            "epochs =  28 , step =  200 , loss value =  0.0012892382\n",
            "epochs =  28 , step =  300 , loss value =  0.037442926\n",
            "epochs =  28 , step =  400 , loss value =  0.001167729\n",
            "epochs =  28 , step =  500 , loss value =  0.0037245823\n",
            "epochs =  29 , step =  0 , loss value =  0.025812432\n",
            "epochs =  29 , step =  100 , loss value =  0.00206945\n",
            "epochs =  29 , step =  200 , loss value =  0.0065369047\n",
            "epochs =  29 , step =  300 , loss value =  0.005230674\n",
            "epochs =  29 , step =  400 , loss value =  0.006426497\n",
            "epochs =  29 , step =  500 , loss value =  0.0039153597\n",
            "\n",
            "Elapsed time =  0:14:47.876388\n",
            "Accuracy =  0.9829\n",
            "false label count =  171\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIjTcpn6kLkK",
        "outputId": "16673ec4-99d0-4b14-a933-d4d543c553e6"
      },
      "source": [
        "print(index_label_prediction_list)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[62, 9, 5], [232, 8, 5], [259, 6, 0], [340, 5, 3], [445, 6, 0], [449, 3, 5], [583, 2, 7], [684, 7, 3], [726, 7, 5], [870, 6, 5], [882, 9, 7], [883, 3, 5], [938, 3, 5], [947, 8, 9], [958, 3, 0], [1014, 6, 5], [1039, 7, 2], [1112, 4, 6], [1182, 6, 5], [1192, 9, 7], [1226, 7, 2], [1232, 9, 4], [1242, 4, 9], [1247, 9, 5], [1290, 3, 5], [1296, 6, 5], [1319, 8, 0], [1326, 7, 2], [1337, 2, 6], [1393, 5, 3], [1523, 8, 5], [1527, 1, 5], [1530, 8, 7], [1549, 4, 6], [1553, 9, 3], [1609, 2, 3], [1676, 6, 5], [1678, 2, 0], [1709, 9, 5], [1717, 8, 0], [1790, 2, 7], [1878, 8, 3], [1901, 9, 4], [1982, 6, 5], [2035, 5, 3], [2098, 2, 0], [2118, 6, 0], [2130, 4, 9], [2135, 6, 1], [2266, 1, 5], [2272, 8, 0], [2280, 3, 5], [2293, 9, 0], [2329, 0, 2], [2380, 9, 0], [2387, 9, 1], [2406, 9, 4], [2414, 9, 4], [2462, 2, 0], [2488, 2, 4], [2534, 3, 5], [2578, 7, 2], [2582, 9, 5], [2654, 6, 1], [2720, 9, 4], [2760, 9, 4], [2778, 4, 0], [2896, 8, 0], [2921, 3, 2], [2939, 9, 5], [2952, 3, 5], [2953, 3, 5], [2979, 9, 0], [2990, 8, 5], [2995, 6, 5], [3023, 8, 5], [3030, 6, 0], [3060, 9, 5], [3218, 6, 5], [3289, 8, 9], [3342, 6, 5], [3384, 2, 6], [3422, 6, 0], [3503, 9, 1], [3520, 6, 4], [3550, 6, 5], [3558, 5, 0], [3559, 8, 0], [3597, 9, 5], [3727, 8, 9], [3751, 7, 2], [3762, 6, 8], [3808, 7, 8], [3811, 2, 0], [3838, 7, 8], [3850, 9, 4], [3853, 6, 0], [3943, 3, 5], [3985, 9, 4], [4007, 7, 4], [4063, 6, 5], [4075, 8, 0], [4078, 9, 3], [4176, 2, 7], [4224, 9, 7], [4238, 7, 3], [4248, 2, 8], [4256, 3, 2], [4284, 9, 5], [4369, 9, 4], [4429, 8, 5], [4443, 3, 1], [4497, 8, 7], [4536, 6, 5], [4639, 8, 9], [4731, 8, 3], [4740, 3, 5], [4743, 8, 5], [4761, 9, 8], [4807, 8, 0], [4823, 9, 4], [4838, 6, 5], [4966, 7, 3], [5199, 6, 4], [5228, 6, 4], [5246, 7, 2], [5623, 3, 5], [5634, 2, 8], [5654, 7, 2], [5749, 8, 5], [5877, 6, 0], [5888, 4, 0], [5955, 3, 8], [5973, 3, 8], [6011, 3, 0], [6091, 9, 5], [6112, 9, 5], [6157, 9, 5], [6161, 8, 0], [6166, 9, 3], [6532, 0, 5], [6560, 9, 5], [6571, 9, 3], [6576, 7, 1], [6578, 8, 5], [6597, 0, 3], [6608, 9, 5], [6625, 8, 2], [6632, 9, 5], [6651, 0, 8], [6745, 3, 5], [8246, 3, 5], [8325, 0, 6], [8519, 7, 3], [8522, 8, 2], [9009, 7, 2], [9015, 7, 2], [9024, 7, 2], [9280, 8, 5], [9530, 9, 8], [9587, 9, 4], [9620, 9, 5], [9634, 0, 2], [9638, 9, 7], [9679, 6, 4], [9692, 9, 4], [9698, 6, 5], [9729, 5, 6], [9770, 5, 0], [9891, 9, 4], [9904, 2, 4]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YslOlt9_IAbM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}