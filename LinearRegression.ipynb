{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "LinearRegression.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HIsu1231/AI_INOVATION_SQUARE/blob/master/LinearRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A26DQ7FIdG3j"
      },
      "source": [
        "#1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIpvihPWdG3l"
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaeqpZEudG3p"
      },
      "source": [
        "x_data = np.array([1.0,2.0,3.0,4.0,5.0]).reshape(5,1)\n",
        "t_data = np.array([2.0,3.0,4.0,5.0,6.0]).reshape(5,1)\n",
        "n = len(x_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndSv7FpOdG3t"
      },
      "source": [
        "W = np.random.rand(1,1)\n",
        "b = np.random.rand(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyD4im2SdG3w"
      },
      "source": [
        "def numerical_derivative(f,x):\n",
        "    delta_x = 1e-4\n",
        "    grad = np.zeros_like(x)\n",
        "    \n",
        "    it = np.nditer(x, flags = ['multi_index'], op_flags = ['readwrite'])\n",
        "    \n",
        "    while not it.finished:\n",
        "        idx = it.multi_index\n",
        "        \n",
        "        tmp_val = x[idx]\n",
        "        x[idx] = float(tmp_val) + delta_x\n",
        "        fx1 = f(x)   #f(x+delta_x)\n",
        "        \n",
        "        x[idx] = tmp_val - delta_x\n",
        "        fx2 = f(x)\n",
        "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
        "        \n",
        "        x[idx] = tmp_val\n",
        "        it.iternext()\n",
        "    \n",
        "    return grad "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtOozBTCdG3z"
      },
      "source": [
        "def loss_func(x,t):\n",
        "    y = np.dot(x,W) + b\n",
        "    return (np.sum((t-y)**2))/n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PZHcU-odG37"
      },
      "source": [
        "def predict(x):\n",
        "    y = np.dot(x,W) + b\n",
        "    return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qib0WJP7dG3_"
      },
      "source": [
        "learning_rate = 1e-2\n",
        "\n",
        "f = lambda x: loss_func(x_data, t_data)\n",
        "\n",
        "print(\"initial loss value = \", loss_func(x_data, t_data), \"initial W = \", W, \"\\n\", \", b =\",b)\n",
        "\n",
        "for step in range(10001):\n",
        "    W -= learning_rate * numerical_derivative(f,W)\n",
        "    \n",
        "    b -= learning_rate * numerical_derivative(f,b)\n",
        "    \n",
        "    if (step%1000 == 0):\n",
        "        print(\"step = \", step, \"loss value = \", loss_func(x_data,t_data), \"W = \",W,\" b = \",b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7Y7Uz6-dG4E"
      },
      "source": [
        "predict(np.array([43]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vH2cPACBdG4L"
      },
      "source": [
        "#2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I404QQoAdG4M"
      },
      "source": [
        "def numerical_derivative(f,x):\n",
        "    delta_x = 1e-4\n",
        "    grad = np.zeros_like(x)\n",
        "    \n",
        "    it = np.nditer(x, flags = ['multi_index'], op_flags = ['readwrite'])\n",
        "    \n",
        "    while not it.finished:\n",
        "        idx = it.multi_index\n",
        "        \n",
        "        tmp_val = x[idx]\n",
        "        x[idx] = float(tmp_val) + delta_x\n",
        "        fx1 = f(x)   #f(x+delta_x)\n",
        "        \n",
        "        x[idx] = tmp_val - delta_x\n",
        "        fx2 = f(x)\n",
        "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
        "        \n",
        "        x[idx] = tmp_val\n",
        "        it.iternext()\n",
        "    \n",
        "    return grad "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRUbJ8l0dG4S"
      },
      "source": [
        "loaded_data = np.loadtxt('./../(200221)data-01.csv', delimiter=',', dtype=np.float32)\n",
        "\n",
        "x_data = loaded_data[:, 0:-1]\n",
        "t_data = loaded_data[:,[-1]]\n",
        "\n",
        "W = np.random.rand(3,1)\n",
        "b = np.random.rand(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTR2KDI8dG4V"
      },
      "source": [
        "def loss_func(x,t):\n",
        "    y = np.dot(x,W)+b\n",
        "    return (np.sum((t-y)**2))/(len(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTST16undG4Z"
      },
      "source": [
        "def predict(x):\n",
        "    y = np.dot(x,W) + b\n",
        "    return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Axm2vJ6YdG4c"
      },
      "source": [
        "learning_rate = 1e-5\n",
        "\n",
        "f = lambda x: loss_func(x_data,t_data)\n",
        "\n",
        "for step in range(40001):\n",
        "    \n",
        "    W -= learning_rate*numerical_derivative(f,W)\n",
        "    b -= learning_rate*numerical_derivative(f,b)\n",
        "    \n",
        "    if (step%400 == 0):\n",
        "        print(\"step = \", step, \"loss value = \",loss_func(x_data,t_data), \"W = \",W, \"b = \",b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcc7F-ZndG4g"
      },
      "source": [
        "#3, #4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zK8OVD7KdG4g"
      },
      "source": [
        "def numerical_derivative(f,x):\n",
        "    delta_x = 1e-4\n",
        "    grad = np.zeros_like(x)\n",
        "    \n",
        "    it = np.nditer(x, flags = ['multi_index'], op_flags = ['readwrite'])\n",
        "    \n",
        "    while not it.finished:\n",
        "        idx = it.multi_index\n",
        "        \n",
        "        tmp_val = x[idx]\n",
        "        x[idx] = float(tmp_val) + delta_x\n",
        "        fx1 = f(x)   #f(x+delta_x)\n",
        "        \n",
        "        x[idx] = tmp_val - delta_x\n",
        "        fx2 = f(x)\n",
        "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
        "        \n",
        "        x[idx] = tmp_val\n",
        "        it.iternext()\n",
        "    \n",
        "    return grad "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJUFzmyfdG4m"
      },
      "source": [
        "loaded_data = np.loadtxt(\"./../(200302)sps.csv\", delimiter=',', dtype=np.float32)\n",
        "\n",
        "x_data = loaded_data[:, 1:]\n",
        "t_data = loaded_data[:, [0]]\n",
        "\n",
        "print(\"x_data.shape = \",x_data.shape, \", t_data.shape = \", t_data.shape)\n",
        "\n",
        "W = np.random.rand(len(x_data[1]),1)\n",
        "b = np.random.rand(1)\n",
        "\n",
        "print(\"W.shape = \", W.shape, \", b.shape = \", b.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GgGmojMdG4q"
      },
      "source": [
        "def loss_func(x,t):\n",
        "    y = np.dot(x,W) + b\n",
        "    return np.sum((t-y)**2)/len(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmsd6AtxdG4t"
      },
      "source": [
        "def predict(x):\n",
        "    return np.dot(x,W) + b  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhrHDYYFdG4x"
      },
      "source": [
        "learning_rate = 1e-5\n",
        "\n",
        "f = lambda x: loss_func(x_data,t_data)\n",
        "\n",
        "loss_val_list = []\n",
        "\n",
        "for step in range(40001):\n",
        "    W -= learning_rate*numerical_derivative(f,W)\n",
        "    b -= learning_rate*numerical_derivative(f,b)\n",
        "    \n",
        "    if (step % 1000 == 0):\n",
        "        print(\"step = \", step, \", loss value = \", loss_func(x_data,t_data))\n",
        "        loss_val_list.append(loss_func(x_data, t_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SD718rPdG4z"
      },
      "source": [
        "test_data = np.array([[4,4,4,4],[-3,0,9,-1],[-7,-9,-2,8],\n",
        "                      [1,-2,3,-2],[19,-12,0,-76],[2001,-1,109,31],[-1,102,-200,1000]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9M3Glzt7dG42"
      },
      "source": [
        "for i in test_data:\n",
        "    print(\"predicted value = \",predict(i),\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xanGtEuVdG45"
      },
      "source": [
        "plt.title('Loss Value Trend')\n",
        "plt.xlabel('epochs ( X 1000)')\n",
        "plt.ylabel('loss value')\n",
        "plt.grid()\n",
        "\n",
        "plt.plot(loss_val_list)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHQEly1MdG48"
      },
      "source": [
        "#5, #6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIQOYrindG49"
      },
      "source": [
        "# 수치미분\n",
        "\n",
        "def numerical_derivative(f, x):\n",
        "    delta_x = 1e-4 # 0.0001\n",
        "    grad = np.zeros_like(x)\n",
        "    \n",
        "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
        "    \n",
        "    while not it.finished:\n",
        "        idx = it.multi_index        \n",
        "        tmp_val = x[idx]\n",
        "        x[idx] = float(tmp_val) + delta_x\n",
        "        fx1 = f(x) # f(x+delta_x)\n",
        "        \n",
        "        x[idx] = tmp_val - delta_x \n",
        "        fx2 = f(x) # f(x-delta_x)\n",
        "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
        "        \n",
        "        x[idx] = tmp_val \n",
        "        it.iternext()   \n",
        "        \n",
        "    return grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUY8qGSrdG5A"
      },
      "source": [
        "class LinearRegressionTest:\n",
        "    \n",
        "    def __init__(self):\n",
        "        print(\"LinearRegressionTest Object is created\")\n",
        "        \n",
        "    def get_W_b(self):\n",
        "        return self.W, self.b\n",
        "    \n",
        "    def loss_func(self, xdata, tdata):\n",
        "        y = np.dot(xdata, self.W) + self.b\n",
        "        return np.sum((y-tdata)**2)/len(xdata)\n",
        "    \n",
        "    def predict(self,test_data):\n",
        "        return np.dot(test_data,self.w) + self.b\n",
        "    \n",
        "    def train(self, xdata, tdata, learning_rate, iteration_count):\n",
        "        self.W = np.random.rand(xdata.shape[-1],1)\n",
        "        self.b= np.random.rand(1)\n",
        "        \n",
        "        f = lambda x: self.loss_func(xdata,tdata)\n",
        "        \n",
        "        for step in range(iteration_count):\n",
        "            \n",
        "            self.W -= learning_rate * numerical_derivative(f,self.W)\n",
        "            self.b -= learning_rate * numerical_derivative(f,self.b)\n",
        "            \n",
        "            if(step%int(iteration_count*0.05) == 0):\n",
        "                print(\"step = \", step, \"loss value = \", self.loss_func(xdata,tdata))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yr6VPfdZdG5E"
      },
      "source": [
        "try:\n",
        "    \n",
        "    loaded_data = np.loadtxt(\"통합문서1.xlsx\", delimiter=',', dtype=np.float32)\n",
        "    \n",
        "    x_data = loaded_data[:,1:]\n",
        "    t_data = loaded_data[:,[0]]\n",
        "    \n",
        "except FileNotFoundError as err:\n",
        "        print(str(err))\n",
        "except Exception as err:\n",
        "        print(str(err))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKukuLIAdG5I"
      },
      "source": [
        "obj1 = LinearRegressionTest()\n",
        "\n",
        "obj1.train(x_data, t_data, 1e-3, 20001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csPQuThDdG5M"
      },
      "source": [
        "#5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akd5aok6dG5N",
        "outputId": "c48dd60c-7de3-4ae1-ed56-138e9fc57abf"
      },
      "source": [
        "try:\n",
        "    training_data = np.loadtxt(\"./../../통합 문서1.xlsx\", delimiter = ',', dtype = np.float32)\n",
        "    x_data = training_data[:, 1:]\n",
        "    t_data = training_data[:, [0]]\n",
        "    \n",
        "except FileNotFoundError as err:\n",
        "        print(str(err))\n",
        "except Exception as err:\n",
        "        print(str(err))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'cp949' codec can't decode byte 0xe1 in position 16: illegal multibyte sequence\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsUVw4sOdG5R"
      },
      "source": [
        "class LinearRegressionTest:\n",
        "    \n",
        "    def __init__(self, xdata, tdata, learning_rate, iteration_count):\n",
        "        print(\"The object is created\")\n",
        "        \n",
        "        self.xdata = xdata\n",
        "        self.tdata = tdata\n",
        "        \n",
        "        self.learning_rate = learning_rate\n",
        "        self.iteration_count = iteration_count\n",
        "        \n",
        "        self.W = np.random.rand(self.xdata.shape[1],1)\n",
        "        self.b = np.random.rand(1)\n",
        "        \n",
        "    def get_W_b(self):\n",
        "        return self.W, self.b\n",
        "    \n",
        "    def loss_val(self):\n",
        "        y = np.dot(self.xdata,self.W) + self.b\n",
        "        return np.sum((y-self.tdata)**2)/len(self.xdata)\n",
        "    \n",
        "    \n",
        "    def predict(self,test_data):\n",
        "        y = np.dot(test_data,self.W) +sefl.b\n",
        "        return y\n",
        "    \n",
        "    def train(self):\n",
        "        \n",
        "        f = lambda x: self.loss_val()\n",
        "        \n",
        "        for step in range(self.iteration_count):\n",
        "            self.W -= self.learning_rate * numerical_derivative(f, self.W)\n",
        "            self.b -= self.learning_rate * numerical_derivative(f, self.b)\n",
        "            \n",
        "            if(step % int(self.iteration_count*0.5)==0):\n",
        "                print(\"step = \",step,\"loss value = \",self.loss_val(),\"W = \",self.W, \"b = \",self.b)        \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fO_L9kuSdG5T"
      },
      "source": [
        "obj = LinearRegressionTest(x_data, t_data, 1e-5, 100001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMlyi6OLdG5V"
      },
      "source": [
        "obj.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ro_ZVyqcdG5Y",
        "outputId": "8c3e52de-5c59-4aad-ebb9-1faf44d41c43"
      },
      "source": [
        "training_data = np.loadtxt(\"./../(200302)sps.csv\", delimiter=',',dtype=np.float)\n",
        "x_data = training_data[:, 1:]\n",
        "t_data = training_data[:,[0]]\n",
        "\n",
        "print(\"x_data.shape = \",x_data.shape, \"t_data = \", t_data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_data.shape =  (50, 4) t_data =  (50, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKgZqfS-dG5d"
      },
      "source": [
        "class LinearRegressionTest:\n",
        "    def __init__(self):\n",
        "        print(\"The object is created!\")\n",
        "        \n",
        "    def get_W_b(self,W,b):\n",
        "        return self.W, self.b\n",
        "    \n",
        "    def loss_func(self,xdata,tdata):\n",
        "        y = np.dot(xdata,self.W) + self.b\n",
        "        return np.sum((y-tdata)**2)/len(xdata)\n",
        "    \n",
        "    def predict(self,test_data):\n",
        "        y = np.dot(test_data, self.W) + self.b\n",
        "        return y\n",
        "    \n",
        "    def train(self, xdata, tdata, learning_rate, iteration_count):\n",
        "        self.W = np.random.rand(len(xdata[1]),1)\n",
        "        self.b = np.random.rand(1)\n",
        "        \n",
        "        self.loss_val_list = []\n",
        "\n",
        "        f = lambda x:self.loss_func(xdata,tdata)\n",
        "        \n",
        "        for i in range(iteration_count):\n",
        "            self.W -= learning_rate*numerical_derivative(f,self.W)\n",
        "            self.b -= learning_rate*numerical_derivative(f,self.b)\n",
        "            if(i%int(iteration_count*0.05) == 0):\n",
        "                print(\"Step = \", i,\"loss value = \",self.loss_func(xdata,tdata))\n",
        "                self.loss_val_list.append(self.loss_func(xdata,tdata))\n",
        "                \n",
        "    def loss_val(self):\n",
        "        plt.plot(self.loss_val_list)\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_Yp1ixGdG5g",
        "outputId": "9decbb49-576e-4d4f-d7aa-c55528b3c019"
      },
      "source": [
        "obj = LinearRegressionTest()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The object is created!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxfLpmzudG5j",
        "outputId": "718d94b3-304e-47fa-af5b-e3ca8034450a"
      },
      "source": [
        "obj.train(x_data, t_data, 1e-5, 100001)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step =  0 loss value =  54.42912610053548\n",
            "Step =  5000 loss value =  7.721656195712311\n",
            "Step =  10000 loss value =  1.8144866606531187\n",
            "Step =  15000 loss value =  0.5763503797973036\n",
            "Step =  20000 loss value =  0.29381125692903204\n",
            "Step =  25000 loss value =  0.21567337461375974\n",
            "Step =  30000 loss value =  0.18336620373479626\n",
            "Step =  35000 loss value =  0.16261039642816036\n",
            "Step =  40000 loss value =  0.14577235549550743\n",
            "Step =  45000 loss value =  0.13103170300022607\n",
            "Step =  50000 loss value =  0.11786100471676289\n",
            "Step =  55000 loss value =  0.10603197896787817\n",
            "Step =  60000 loss value =  0.09539417015368819\n",
            "Step =  65000 loss value =  0.08582451696713013\n",
            "Step =  70000 loss value =  0.07721506581925079\n",
            "Step =  75000 loss value =  0.0694693141841163\n",
            "Step =  80000 loss value =  0.06250058022439309\n",
            "Step =  85000 loss value =  0.0562309091131882\n",
            "Step =  90000 loss value =  0.05059017311276983\n",
            "Step =  95000 loss value =  0.04551528088118113\n",
            "Step =  100000 loss value =  0.0409494703748297\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujC_gxHldG5l",
        "outputId": "a6f10b31-49a8-4d61-b51c-f9b5c4a2dc22"
      },
      "source": [
        "obj.loss_val()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VlzNZrWdG5n"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}