{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorflow_MNIST.ipynb",
      "provenance": [],
      "mount_file_id": "1fBy5JdwDY9CP2f9xtUfEi8z8QrltqtLg",
      "authorship_tag": "ABX9TyOCOQxzqMfy8wyFYn+K4WA5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HIsu1231/AI_INOVATION_SQUARE/blob/master/Tensorflow_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-A8flvVgwTH",
        "outputId": "faf983e0-6a17-43fa-ff3a-fd3fcaf79111"
      },
      "source": [
        "!pip uninstall tensorflow"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.3.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow-2.3.0.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGJ-73wyg6nV",
        "outputId": "96f65d34-2f63-4808-aa30-5ff87b07b1af"
      },
      "source": [
        "!pip install tensorflow==1.15"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 41kB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.34.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.18.5)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.12.4)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.12.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.36.1)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 47.5MB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.3.0)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 35.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.15) (50.3.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.4.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7542 sha256=d82aa9a1382da9684babaf9c31ee229175174b42c08eb3c1e37524f4d9651971\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast, tensorboard, keras-applications, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdkadPKUg9dI"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow.examples.tutorials.mnist import input_data\r\n",
        "import numpy as np\r\n",
        "from datetime import datetime"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnMMS2JJhFrQ",
        "outputId": "2690578e-027b-46a0-d080-82378b7b60bd"
      },
      "source": [
        "mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)\r\n",
        "\r\n",
        "print(\"\")\r\n",
        "print(\"train.num = \", mnist.train.num_examples,\r\n",
        "      \", test.num = \", mnist.test.num_examples,\r\n",
        "      \", validation.num = \", mnist.validation.num_examples)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-7-a730d1576a85>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "\n",
            "train.num =  55000 , test.num =  10000 , validation.num =  5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHzubM2xiJHD"
      },
      "source": [
        "###shape 및 type(mnist)확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpX0CL5Rh19z",
        "outputId": "df2b51d8-f394-47b2-8ab3-f9a2eeea08ef"
      },
      "source": [
        "#images: 이미지 데이터셋\r\n",
        "#labels: 데이터셋\r\n",
        "#num_examples: 데이터 갯수 ( len(mnist.train.images) = mnist.train.num_examples )\r\n",
        "#next_batch: 데이터셋으로부터 필요한 만큼의 데이터를 반환하는 함수\r\n",
        "\r\n",
        "print(\"type(mnist) = \", type(mnist),\r\n",
        "      \", type(mnist.train.images) = \", type(mnist.train.images),\r\n",
        "      \", type(mnist.train.labels) = \", type(mnist.train.labels))\r\n",
        "\r\n",
        "print(\"\\ntrain image shape = \", np.shape(mnist.train.images))\r\n",
        "print(\"train label shape = \", np.shape(mnist.train.labels))\r\n",
        "print(\"test image shape = \", np.shape(mnist.test.images))\r\n",
        "print(\"test label shape = \", np.shape(mnist.test.labels))\r\n",
        "\r\n",
        "print(\"\\ntrain image shape = \", mnist.train.images.shape)\r\n",
        "print(\"test image shape = \", mnist.test.images.shape)\r\n",
        "print(\"validation image shape = \", mnist.validation.images.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "type(mnist) =  <class 'tensorflow.contrib.learn.python.learn.datasets.base.Datasets'> , type(mnist.train.images) =  <class 'numpy.ndarray'> , type(mnist.train.labels) =  <class 'numpy.ndarray'>\n",
            "\n",
            "train image shape =  (55000, 784)\n",
            "train label shape =  (55000, 10)\n",
            "test image shape =  (10000, 784)\n",
            "test label shape =  (10000, 10)\n",
            "\n",
            "train image shape =  (55000, 784)\n",
            "test image shape =  (10000, 784)\n",
            "validation image shape =  (5000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6I2vjsYi0lW"
      },
      "source": [
        "###train data 정규화 및 label의 one-hot encoding 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtyMKh9biwcH",
        "outputId": "0915c146-db94-43e6-b5b4-16888fd2932f"
      },
      "source": [
        "print(\"정규화 확인\")\r\n",
        "print(\"=======================================================\")\r\n",
        "print(\"len(mnist.train.images[0] = \", len(mnist.train.images[0]))\r\n",
        "print(mnist.train.images[0])\r\n",
        "print(\"\\n One-hot Encoding 확인\")\r\n",
        "print(\"=======================================================\")\r\n",
        "print(\"len(mnist.train.labels[0] = \", len(mnist.train.labels[0]) )\r\n",
        "print(mnist.train.labels[0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "정규화 확인\n",
            "=======================================================\n",
            "len(mnist.train.images[0] =  784\n",
            "[0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.3803922  0.37647063 0.3019608\n",
            " 0.46274513 0.2392157  0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.3529412\n",
            " 0.5411765  0.9215687  0.9215687  0.9215687  0.9215687  0.9215687\n",
            " 0.9215687  0.9843138  0.9843138  0.9725491  0.9960785  0.9607844\n",
            " 0.9215687  0.74509805 0.08235294 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.54901963 0.9843138  0.9960785  0.9960785\n",
            " 0.9960785  0.9960785  0.9960785  0.9960785  0.9960785  0.9960785\n",
            " 0.9960785  0.9960785  0.9960785  0.9960785  0.9960785  0.9960785\n",
            " 0.7411765  0.09019608 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.8862746  0.9960785  0.81568635 0.7803922  0.7803922  0.7803922\n",
            " 0.7803922  0.54509807 0.2392157  0.2392157  0.2392157  0.2392157\n",
            " 0.2392157  0.5019608  0.8705883  0.9960785  0.9960785  0.7411765\n",
            " 0.08235294 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.14901961 0.32156864\n",
            " 0.0509804  0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.13333334 0.8352942  0.9960785  0.9960785  0.45098042 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.32941177\n",
            " 0.9960785  0.9960785  0.9176471  0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.32941177 0.9960785  0.9960785\n",
            " 0.9176471  0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.4156863  0.6156863  0.9960785  0.9960785  0.95294124 0.20000002\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.09803922\n",
            " 0.45882356 0.8941177  0.8941177  0.8941177  0.9921569  0.9960785\n",
            " 0.9960785  0.9960785  0.9960785  0.94117653 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.26666668 0.4666667  0.86274517 0.9960785  0.9960785\n",
            " 0.9960785  0.9960785  0.9960785  0.9960785  0.9960785  0.9960785\n",
            " 0.9960785  0.5568628  0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.14509805 0.73333335 0.9921569\n",
            " 0.9960785  0.9960785  0.9960785  0.8745099  0.8078432  0.8078432\n",
            " 0.29411766 0.26666668 0.8431373  0.9960785  0.9960785  0.45882356\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.4431373  0.8588236  0.9960785  0.9490197  0.89019614 0.45098042\n",
            " 0.34901962 0.12156864 0.         0.         0.         0.\n",
            " 0.7843138  0.9960785  0.9450981  0.16078432 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.6627451  0.9960785\n",
            " 0.6901961  0.24313727 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.18823531 0.9058824  0.9960785\n",
            " 0.9176471  0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.07058824 0.48627454 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.32941177 0.9960785  0.9960785  0.6509804  0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.54509807\n",
            " 0.9960785  0.9333334  0.22352943 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.8235295  0.9803922  0.9960785  0.65882355\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.9490197  0.9960785  0.93725497 0.22352943 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.34901962 0.9843138  0.9450981\n",
            " 0.3372549  0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.01960784 0.8078432  0.96470594 0.6156863  0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.01568628 0.45882356\n",
            " 0.27058825 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n",
            "\n",
            " One-hot Encoding 확인\n",
            "=======================================================\n",
            "len(mnist.train.labels[0] =  10\n",
            "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_ZCXaehj56T"
      },
      "source": [
        "###학습 코드 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RZ3m7CesFKC"
      },
      "source": [
        "input_nodes = mnist.train.images.shape[1]\r\n",
        "hidden_nodes = 100\r\n",
        "output_nodes = mnist.train.labels.shape[1]\r\n",
        "\r\n",
        "learning_rate = 1e-1\r\n",
        "epochs = 100\r\n",
        "batch_size = 100"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIBS1-uFtRTP"
      },
      "source": [
        "X = tf.placeholder(tf.float32, [None, input_nodes])\r\n",
        "T = tf.placeholder(tf.float32, [None, output_nodes])\r\n",
        "\r\n",
        "W2 = tf.Variable(tf.random_normal([input_nodes, hidden_nodes]))\r\n",
        "b2 = tf.Variable(tf.random_normal([hidden_nodes]))\r\n",
        "\r\n",
        "W3 = tf.Variable(tf.random_normal([hidden_nodes, output_nodes]))\r\n",
        "b3 = tf.Variable(tf.random_normal([output_nodes]))"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wf4Q69r0tmrE"
      },
      "source": [
        "z2 = tf.matmul(X,W2) + b2\r\n",
        "a2 = tf.nn.relu(z2)\r\n",
        "\r\n",
        "z3 = tf.matmul(a2,W3) + b3 #logtis\r\n",
        "y = a3 = tf.nn.softmax(z3)\r\n",
        "\r\n",
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels = T, logits = z3))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2PI3AKzt8Bw"
      },
      "source": [
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\r\n",
        "\r\n",
        "train = optimizer.minimize(loss)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUaA_MBiuFbo"
      },
      "source": [
        "predicted = tf.cast(tf.equal(tf.argmax(y,1), tf.argmax(T,1)), dtype=tf.float32)\r\n",
        "\r\n",
        "accuracy = tf.reduce_mean(predicted)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6Q-JG-ov-fb",
        "outputId": "c4c9d8e2-8bc8-4224-c935-7608daad3ae0"
      },
      "source": [
        "with tf.Session() as sess:\r\n",
        "\r\n",
        "    sess.run(tf.global_variables_initializer())\r\n",
        "\r\n",
        "    start_time = datetime.now()\r\n",
        "\r\n",
        "    for i in range(epochs):\r\n",
        "\r\n",
        "        total_batch = int(mnist.train.num_examples / batch_size)\r\n",
        "\r\n",
        "        for step in range(total_batch):\r\n",
        "            \r\n",
        "            batch_x_data, batch_t_data = mnist.train.next_batch(batch_size)\r\n",
        "\r\n",
        "            loss_val, _ = sess.run([loss, train], feed_dict={X: batch_x_data, T: batch_t_data})\r\n",
        "\r\n",
        "            if step % 100 == 0:\r\n",
        "\r\n",
        "                print(\"epochs = \", i, \", step = \", step, \", loss value = \", loss_val)\r\n",
        "\r\n",
        "    end_time = datetime.now()\r\n",
        "\r\n",
        "    print(\"\\nElapsed time = \", end_time - start_time)\r\n",
        "\r\n",
        "    test_x_data = mnist.test.images\r\n",
        "    test_t_data = mnist.test.labels\r\n",
        "\r\n",
        "    accuracy_val = sess.run([accuracy], feed_dict = {X: test_x_data, T: test_t_data})\r\n",
        "\r\n",
        "    print(\"\\nAccuracy = \", accuracy_val)\r\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epochs =  0 , step =  0 , loss value =  98.24877\n",
            "epochs =  0 , step =  100 , loss value =  3.2143955\n",
            "epochs =  0 , step =  200 , loss value =  3.4059877\n",
            "epochs =  0 , step =  300 , loss value =  2.9474237\n",
            "epochs =  0 , step =  400 , loss value =  2.8254287\n",
            "epochs =  0 , step =  500 , loss value =  1.2397637\n",
            "epochs =  1 , step =  0 , loss value =  1.1695458\n",
            "epochs =  1 , step =  100 , loss value =  0.95285684\n",
            "epochs =  1 , step =  200 , loss value =  0.92777777\n",
            "epochs =  1 , step =  300 , loss value =  1.9913636\n",
            "epochs =  1 , step =  400 , loss value =  1.7682613\n",
            "epochs =  1 , step =  500 , loss value =  0.9779609\n",
            "epochs =  2 , step =  0 , loss value =  1.3366776\n",
            "epochs =  2 , step =  100 , loss value =  0.67298096\n",
            "epochs =  2 , step =  200 , loss value =  0.5553812\n",
            "epochs =  2 , step =  300 , loss value =  0.51295424\n",
            "epochs =  2 , step =  400 , loss value =  1.0390077\n",
            "epochs =  2 , step =  500 , loss value =  0.5268208\n",
            "epochs =  3 , step =  0 , loss value =  0.5006404\n",
            "epochs =  3 , step =  100 , loss value =  0.5260308\n",
            "epochs =  3 , step =  200 , loss value =  0.5611447\n",
            "epochs =  3 , step =  300 , loss value =  0.291985\n",
            "epochs =  3 , step =  400 , loss value =  0.5593544\n",
            "epochs =  3 , step =  500 , loss value =  0.49199554\n",
            "epochs =  4 , step =  0 , loss value =  0.7766936\n",
            "epochs =  4 , step =  100 , loss value =  0.16332285\n",
            "epochs =  4 , step =  200 , loss value =  0.2126095\n",
            "epochs =  4 , step =  300 , loss value =  0.34533787\n",
            "epochs =  4 , step =  400 , loss value =  0.38294914\n",
            "epochs =  4 , step =  500 , loss value =  0.5574069\n",
            "epochs =  5 , step =  0 , loss value =  0.6128164\n",
            "epochs =  5 , step =  100 , loss value =  0.29927883\n",
            "epochs =  5 , step =  200 , loss value =  0.2893816\n",
            "epochs =  5 , step =  300 , loss value =  0.39374748\n",
            "epochs =  5 , step =  400 , loss value =  0.306609\n",
            "epochs =  5 , step =  500 , loss value =  0.31558788\n",
            "epochs =  6 , step =  0 , loss value =  0.26265326\n",
            "epochs =  6 , step =  100 , loss value =  0.15393291\n",
            "epochs =  6 , step =  200 , loss value =  0.43148884\n",
            "epochs =  6 , step =  300 , loss value =  0.4218851\n",
            "epochs =  6 , step =  400 , loss value =  0.5845136\n",
            "epochs =  6 , step =  500 , loss value =  0.34713662\n",
            "epochs =  7 , step =  0 , loss value =  0.30034962\n",
            "epochs =  7 , step =  100 , loss value =  0.32931557\n",
            "epochs =  7 , step =  200 , loss value =  0.47337928\n",
            "epochs =  7 , step =  300 , loss value =  0.41148865\n",
            "epochs =  7 , step =  400 , loss value =  0.39999488\n",
            "epochs =  7 , step =  500 , loss value =  0.37615004\n",
            "epochs =  8 , step =  0 , loss value =  0.4939933\n",
            "epochs =  8 , step =  100 , loss value =  0.27553582\n",
            "epochs =  8 , step =  200 , loss value =  0.22681835\n",
            "epochs =  8 , step =  300 , loss value =  0.25131077\n",
            "epochs =  8 , step =  400 , loss value =  0.35649\n",
            "epochs =  8 , step =  500 , loss value =  0.21535513\n",
            "epochs =  9 , step =  0 , loss value =  0.089966066\n",
            "epochs =  9 , step =  100 , loss value =  0.48699826\n",
            "epochs =  9 , step =  200 , loss value =  0.17392197\n",
            "epochs =  9 , step =  300 , loss value =  0.31362632\n",
            "epochs =  9 , step =  400 , loss value =  0.22094181\n",
            "epochs =  9 , step =  500 , loss value =  0.32649186\n",
            "epochs =  10 , step =  0 , loss value =  0.16086945\n",
            "epochs =  10 , step =  100 , loss value =  0.35913864\n",
            "epochs =  10 , step =  200 , loss value =  0.20095056\n",
            "epochs =  10 , step =  300 , loss value =  0.23040375\n",
            "epochs =  10 , step =  400 , loss value =  0.39210936\n",
            "epochs =  10 , step =  500 , loss value =  0.29118243\n",
            "epochs =  11 , step =  0 , loss value =  0.29522005\n",
            "epochs =  11 , step =  100 , loss value =  0.15287015\n",
            "epochs =  11 , step =  200 , loss value =  0.5212745\n",
            "epochs =  11 , step =  300 , loss value =  0.21579976\n",
            "epochs =  11 , step =  400 , loss value =  0.14239956\n",
            "epochs =  11 , step =  500 , loss value =  0.36652535\n",
            "epochs =  12 , step =  0 , loss value =  0.29661763\n",
            "epochs =  12 , step =  100 , loss value =  0.23632398\n",
            "epochs =  12 , step =  200 , loss value =  0.16016045\n",
            "epochs =  12 , step =  300 , loss value =  0.2516655\n",
            "epochs =  12 , step =  400 , loss value =  0.30202284\n",
            "epochs =  12 , step =  500 , loss value =  0.20310539\n",
            "epochs =  13 , step =  0 , loss value =  0.32286933\n",
            "epochs =  13 , step =  100 , loss value =  0.24914102\n",
            "epochs =  13 , step =  200 , loss value =  0.3249931\n",
            "epochs =  13 , step =  300 , loss value =  0.39755917\n",
            "epochs =  13 , step =  400 , loss value =  0.24035034\n",
            "epochs =  13 , step =  500 , loss value =  0.24229841\n",
            "epochs =  14 , step =  0 , loss value =  0.4533608\n",
            "epochs =  14 , step =  100 , loss value =  0.403609\n",
            "epochs =  14 , step =  200 , loss value =  0.18555117\n",
            "epochs =  14 , step =  300 , loss value =  0.6031775\n",
            "epochs =  14 , step =  400 , loss value =  0.3326202\n",
            "epochs =  14 , step =  500 , loss value =  0.16215652\n",
            "epochs =  15 , step =  0 , loss value =  0.31367844\n",
            "epochs =  15 , step =  100 , loss value =  0.16524167\n",
            "epochs =  15 , step =  200 , loss value =  0.3591302\n",
            "epochs =  15 , step =  300 , loss value =  0.34190765\n",
            "epochs =  15 , step =  400 , loss value =  0.25037\n",
            "epochs =  15 , step =  500 , loss value =  0.1957332\n",
            "epochs =  16 , step =  0 , loss value =  0.23527947\n",
            "epochs =  16 , step =  100 , loss value =  0.1872787\n",
            "epochs =  16 , step =  200 , loss value =  0.33042076\n",
            "epochs =  16 , step =  300 , loss value =  0.22975491\n",
            "epochs =  16 , step =  400 , loss value =  0.24266945\n",
            "epochs =  16 , step =  500 , loss value =  0.40000084\n",
            "epochs =  17 , step =  0 , loss value =  0.42043668\n",
            "epochs =  17 , step =  100 , loss value =  0.31095788\n",
            "epochs =  17 , step =  200 , loss value =  0.0947638\n",
            "epochs =  17 , step =  300 , loss value =  0.15770803\n",
            "epochs =  17 , step =  400 , loss value =  0.14457639\n",
            "epochs =  17 , step =  500 , loss value =  0.22421025\n",
            "epochs =  18 , step =  0 , loss value =  0.2163334\n",
            "epochs =  18 , step =  100 , loss value =  0.20861746\n",
            "epochs =  18 , step =  200 , loss value =  0.26343545\n",
            "epochs =  18 , step =  300 , loss value =  0.15636392\n",
            "epochs =  18 , step =  400 , loss value =  0.1096422\n",
            "epochs =  18 , step =  500 , loss value =  0.19564545\n",
            "epochs =  19 , step =  0 , loss value =  0.109974116\n",
            "epochs =  19 , step =  100 , loss value =  0.4067713\n",
            "epochs =  19 , step =  200 , loss value =  0.45636308\n",
            "epochs =  19 , step =  300 , loss value =  0.21057944\n",
            "epochs =  19 , step =  400 , loss value =  0.18544605\n",
            "epochs =  19 , step =  500 , loss value =  0.20077822\n",
            "epochs =  20 , step =  0 , loss value =  0.19990961\n",
            "epochs =  20 , step =  100 , loss value =  0.21889235\n",
            "epochs =  20 , step =  200 , loss value =  0.087401554\n",
            "epochs =  20 , step =  300 , loss value =  0.17905943\n",
            "epochs =  20 , step =  400 , loss value =  0.18954013\n",
            "epochs =  20 , step =  500 , loss value =  0.27719605\n",
            "epochs =  21 , step =  0 , loss value =  0.16715497\n",
            "epochs =  21 , step =  100 , loss value =  0.10346235\n",
            "epochs =  21 , step =  200 , loss value =  0.30294678\n",
            "epochs =  21 , step =  300 , loss value =  0.20476475\n",
            "epochs =  21 , step =  400 , loss value =  0.13578516\n",
            "epochs =  21 , step =  500 , loss value =  0.23563471\n",
            "epochs =  22 , step =  0 , loss value =  0.2183745\n",
            "epochs =  22 , step =  100 , loss value =  0.134171\n",
            "epochs =  22 , step =  200 , loss value =  0.1890709\n",
            "epochs =  22 , step =  300 , loss value =  0.07988792\n",
            "epochs =  22 , step =  400 , loss value =  0.230416\n",
            "epochs =  22 , step =  500 , loss value =  0.1366205\n",
            "epochs =  23 , step =  0 , loss value =  0.15201217\n",
            "epochs =  23 , step =  100 , loss value =  0.15193081\n",
            "epochs =  23 , step =  200 , loss value =  0.1560223\n",
            "epochs =  23 , step =  300 , loss value =  0.049599696\n",
            "epochs =  23 , step =  400 , loss value =  0.14238168\n",
            "epochs =  23 , step =  500 , loss value =  0.11206344\n",
            "epochs =  24 , step =  0 , loss value =  0.13002163\n",
            "epochs =  24 , step =  100 , loss value =  0.22677544\n",
            "epochs =  24 , step =  200 , loss value =  0.19241104\n",
            "epochs =  24 , step =  300 , loss value =  0.19056389\n",
            "epochs =  24 , step =  400 , loss value =  0.17864716\n",
            "epochs =  24 , step =  500 , loss value =  0.23714843\n",
            "epochs =  25 , step =  0 , loss value =  0.31640342\n",
            "epochs =  25 , step =  100 , loss value =  0.154067\n",
            "epochs =  25 , step =  200 , loss value =  0.18229623\n",
            "epochs =  25 , step =  300 , loss value =  0.111386664\n",
            "epochs =  25 , step =  400 , loss value =  0.19285426\n",
            "epochs =  25 , step =  500 , loss value =  0.20003325\n",
            "epochs =  26 , step =  0 , loss value =  0.20911437\n",
            "epochs =  26 , step =  100 , loss value =  0.34262988\n",
            "epochs =  26 , step =  200 , loss value =  0.17449959\n",
            "epochs =  26 , step =  300 , loss value =  0.20195983\n",
            "epochs =  26 , step =  400 , loss value =  0.29467466\n",
            "epochs =  26 , step =  500 , loss value =  0.11978322\n",
            "epochs =  27 , step =  0 , loss value =  0.14303146\n",
            "epochs =  27 , step =  100 , loss value =  0.17367403\n",
            "epochs =  27 , step =  200 , loss value =  0.27863955\n",
            "epochs =  27 , step =  300 , loss value =  0.15302986\n",
            "epochs =  27 , step =  400 , loss value =  0.040188007\n",
            "epochs =  27 , step =  500 , loss value =  0.20844607\n",
            "epochs =  28 , step =  0 , loss value =  0.23087887\n",
            "epochs =  28 , step =  100 , loss value =  0.23061486\n",
            "epochs =  28 , step =  200 , loss value =  0.15657471\n",
            "epochs =  28 , step =  300 , loss value =  0.23339087\n",
            "epochs =  28 , step =  400 , loss value =  0.13090609\n",
            "epochs =  28 , step =  500 , loss value =  0.07754109\n",
            "epochs =  29 , step =  0 , loss value =  0.1520339\n",
            "epochs =  29 , step =  100 , loss value =  0.44030547\n",
            "epochs =  29 , step =  200 , loss value =  0.20183752\n",
            "epochs =  29 , step =  300 , loss value =  0.17645264\n",
            "epochs =  29 , step =  400 , loss value =  0.16251682\n",
            "epochs =  29 , step =  500 , loss value =  0.1595\n",
            "epochs =  30 , step =  0 , loss value =  0.1276081\n",
            "epochs =  30 , step =  100 , loss value =  0.27755442\n",
            "epochs =  30 , step =  200 , loss value =  0.34695712\n",
            "epochs =  30 , step =  300 , loss value =  0.16223297\n",
            "epochs =  30 , step =  400 , loss value =  0.28080916\n",
            "epochs =  30 , step =  500 , loss value =  0.08365873\n",
            "epochs =  31 , step =  0 , loss value =  0.12925884\n",
            "epochs =  31 , step =  100 , loss value =  0.14744972\n",
            "epochs =  31 , step =  200 , loss value =  0.16015673\n",
            "epochs =  31 , step =  300 , loss value =  0.29844552\n",
            "epochs =  31 , step =  400 , loss value =  0.28349182\n",
            "epochs =  31 , step =  500 , loss value =  0.109784134\n",
            "epochs =  32 , step =  0 , loss value =  0.38073844\n",
            "epochs =  32 , step =  100 , loss value =  0.18693052\n",
            "epochs =  32 , step =  200 , loss value =  0.08596164\n",
            "epochs =  32 , step =  300 , loss value =  0.17229015\n",
            "epochs =  32 , step =  400 , loss value =  0.13756007\n",
            "epochs =  32 , step =  500 , loss value =  0.07417615\n",
            "epochs =  33 , step =  0 , loss value =  0.2856935\n",
            "epochs =  33 , step =  100 , loss value =  0.20554043\n",
            "epochs =  33 , step =  200 , loss value =  0.16224998\n",
            "epochs =  33 , step =  300 , loss value =  0.12245077\n",
            "epochs =  33 , step =  400 , loss value =  0.2088461\n",
            "epochs =  33 , step =  500 , loss value =  0.092969015\n",
            "epochs =  34 , step =  0 , loss value =  0.17178759\n",
            "epochs =  34 , step =  100 , loss value =  0.09280573\n",
            "epochs =  34 , step =  200 , loss value =  0.20026428\n",
            "epochs =  34 , step =  300 , loss value =  0.17827679\n",
            "epochs =  34 , step =  400 , loss value =  0.11174137\n",
            "epochs =  34 , step =  500 , loss value =  0.19865875\n",
            "epochs =  35 , step =  0 , loss value =  0.0972262\n",
            "epochs =  35 , step =  100 , loss value =  0.052192472\n",
            "epochs =  35 , step =  200 , loss value =  0.19503164\n",
            "epochs =  35 , step =  300 , loss value =  0.34573913\n",
            "epochs =  35 , step =  400 , loss value =  0.08462361\n",
            "epochs =  35 , step =  500 , loss value =  0.1597878\n",
            "epochs =  36 , step =  0 , loss value =  0.24015544\n",
            "epochs =  36 , step =  100 , loss value =  0.3066592\n",
            "epochs =  36 , step =  200 , loss value =  0.10325298\n",
            "epochs =  36 , step =  300 , loss value =  0.20656794\n",
            "epochs =  36 , step =  400 , loss value =  0.2840999\n",
            "epochs =  36 , step =  500 , loss value =  0.07481757\n",
            "epochs =  37 , step =  0 , loss value =  0.135428\n",
            "epochs =  37 , step =  100 , loss value =  0.1352558\n",
            "epochs =  37 , step =  200 , loss value =  0.21398073\n",
            "epochs =  37 , step =  300 , loss value =  0.18618473\n",
            "epochs =  37 , step =  400 , loss value =  0.19959274\n",
            "epochs =  37 , step =  500 , loss value =  0.13940299\n",
            "epochs =  38 , step =  0 , loss value =  0.120741434\n",
            "epochs =  38 , step =  100 , loss value =  0.18849745\n",
            "epochs =  38 , step =  200 , loss value =  0.28304663\n",
            "epochs =  38 , step =  300 , loss value =  0.12017956\n",
            "epochs =  38 , step =  400 , loss value =  0.09154315\n",
            "epochs =  38 , step =  500 , loss value =  0.15662459\n",
            "epochs =  39 , step =  0 , loss value =  0.05320497\n",
            "epochs =  39 , step =  100 , loss value =  0.13966548\n",
            "epochs =  39 , step =  200 , loss value =  0.21285042\n",
            "epochs =  39 , step =  300 , loss value =  0.22218171\n",
            "epochs =  39 , step =  400 , loss value =  0.14479621\n",
            "epochs =  39 , step =  500 , loss value =  0.1621431\n",
            "epochs =  40 , step =  0 , loss value =  0.18926503\n",
            "epochs =  40 , step =  100 , loss value =  0.15986763\n",
            "epochs =  40 , step =  200 , loss value =  0.11876686\n",
            "epochs =  40 , step =  300 , loss value =  0.09037974\n",
            "epochs =  40 , step =  400 , loss value =  0.20237827\n",
            "epochs =  40 , step =  500 , loss value =  0.09367136\n",
            "epochs =  41 , step =  0 , loss value =  0.10635467\n",
            "epochs =  41 , step =  100 , loss value =  0.0648249\n",
            "epochs =  41 , step =  200 , loss value =  0.11735301\n",
            "epochs =  41 , step =  300 , loss value =  0.20500655\n",
            "epochs =  41 , step =  400 , loss value =  0.32181394\n",
            "epochs =  41 , step =  500 , loss value =  0.18849236\n",
            "epochs =  42 , step =  0 , loss value =  0.15035513\n",
            "epochs =  42 , step =  100 , loss value =  0.061746288\n",
            "epochs =  42 , step =  200 , loss value =  0.050307322\n",
            "epochs =  42 , step =  300 , loss value =  0.14209741\n",
            "epochs =  42 , step =  400 , loss value =  0.112778775\n",
            "epochs =  42 , step =  500 , loss value =  0.11966994\n",
            "epochs =  43 , step =  0 , loss value =  0.056042857\n",
            "epochs =  43 , step =  100 , loss value =  0.12378113\n",
            "epochs =  43 , step =  200 , loss value =  0.12106742\n",
            "epochs =  43 , step =  300 , loss value =  0.12458381\n",
            "epochs =  43 , step =  400 , loss value =  0.17479095\n",
            "epochs =  43 , step =  500 , loss value =  0.18423969\n",
            "epochs =  44 , step =  0 , loss value =  0.17961018\n",
            "epochs =  44 , step =  100 , loss value =  0.06899517\n",
            "epochs =  44 , step =  200 , loss value =  0.1265655\n",
            "epochs =  44 , step =  300 , loss value =  0.21203054\n",
            "epochs =  44 , step =  400 , loss value =  0.33868226\n",
            "epochs =  44 , step =  500 , loss value =  0.105118625\n",
            "epochs =  45 , step =  0 , loss value =  0.20679644\n",
            "epochs =  45 , step =  100 , loss value =  0.10554511\n",
            "epochs =  45 , step =  200 , loss value =  0.16763188\n",
            "epochs =  45 , step =  300 , loss value =  0.098126374\n",
            "epochs =  45 , step =  400 , loss value =  0.032588348\n",
            "epochs =  45 , step =  500 , loss value =  0.28032982\n",
            "epochs =  46 , step =  0 , loss value =  0.17264463\n",
            "epochs =  46 , step =  100 , loss value =  0.2178542\n",
            "epochs =  46 , step =  200 , loss value =  0.17502378\n",
            "epochs =  46 , step =  300 , loss value =  0.39748478\n",
            "epochs =  46 , step =  400 , loss value =  0.06692022\n",
            "epochs =  46 , step =  500 , loss value =  0.29152507\n",
            "epochs =  47 , step =  0 , loss value =  0.1175998\n",
            "epochs =  47 , step =  100 , loss value =  0.14366324\n",
            "epochs =  47 , step =  200 , loss value =  0.086069435\n",
            "epochs =  47 , step =  300 , loss value =  0.21143033\n",
            "epochs =  47 , step =  400 , loss value =  0.38779017\n",
            "epochs =  47 , step =  500 , loss value =  0.26211056\n",
            "epochs =  48 , step =  0 , loss value =  0.104136504\n",
            "epochs =  48 , step =  100 , loss value =  0.09490834\n",
            "epochs =  48 , step =  200 , loss value =  0.07787935\n",
            "epochs =  48 , step =  300 , loss value =  0.09064282\n",
            "epochs =  48 , step =  400 , loss value =  0.056145027\n",
            "epochs =  48 , step =  500 , loss value =  0.17600259\n",
            "epochs =  49 , step =  0 , loss value =  0.13882619\n",
            "epochs =  49 , step =  100 , loss value =  0.07832913\n",
            "epochs =  49 , step =  200 , loss value =  0.1690692\n",
            "epochs =  49 , step =  300 , loss value =  0.041463565\n",
            "epochs =  49 , step =  400 , loss value =  0.07991109\n",
            "epochs =  49 , step =  500 , loss value =  0.11819216\n",
            "epochs =  50 , step =  0 , loss value =  0.100915775\n",
            "epochs =  50 , step =  100 , loss value =  0.21919598\n",
            "epochs =  50 , step =  200 , loss value =  0.17199054\n",
            "epochs =  50 , step =  300 , loss value =  0.104743786\n",
            "epochs =  50 , step =  400 , loss value =  0.09518726\n",
            "epochs =  50 , step =  500 , loss value =  0.15713617\n",
            "epochs =  51 , step =  0 , loss value =  0.13085854\n",
            "epochs =  51 , step =  100 , loss value =  0.063538596\n",
            "epochs =  51 , step =  200 , loss value =  0.05881197\n",
            "epochs =  51 , step =  300 , loss value =  0.29289693\n",
            "epochs =  51 , step =  400 , loss value =  0.25321257\n",
            "epochs =  51 , step =  500 , loss value =  0.073095195\n",
            "epochs =  52 , step =  0 , loss value =  0.04536785\n",
            "epochs =  52 , step =  100 , loss value =  0.12962462\n",
            "epochs =  52 , step =  200 , loss value =  0.17610331\n",
            "epochs =  52 , step =  300 , loss value =  0.20874111\n",
            "epochs =  52 , step =  400 , loss value =  0.2670151\n",
            "epochs =  52 , step =  500 , loss value =  0.17091084\n",
            "epochs =  53 , step =  0 , loss value =  0.0648135\n",
            "epochs =  53 , step =  100 , loss value =  0.09623065\n",
            "epochs =  53 , step =  200 , loss value =  0.0659612\n",
            "epochs =  53 , step =  300 , loss value =  0.1596547\n",
            "epochs =  53 , step =  400 , loss value =  0.16691901\n",
            "epochs =  53 , step =  500 , loss value =  0.10719214\n",
            "epochs =  54 , step =  0 , loss value =  0.108342215\n",
            "epochs =  54 , step =  100 , loss value =  0.1813229\n",
            "epochs =  54 , step =  200 , loss value =  0.13854957\n",
            "epochs =  54 , step =  300 , loss value =  0.06501689\n",
            "epochs =  54 , step =  400 , loss value =  0.12170615\n",
            "epochs =  54 , step =  500 , loss value =  0.029183032\n",
            "epochs =  55 , step =  0 , loss value =  0.09970968\n",
            "epochs =  55 , step =  100 , loss value =  0.20464033\n",
            "epochs =  55 , step =  200 , loss value =  0.026323546\n",
            "epochs =  55 , step =  300 , loss value =  0.10639065\n",
            "epochs =  55 , step =  400 , loss value =  0.11658583\n",
            "epochs =  55 , step =  500 , loss value =  0.081991166\n",
            "epochs =  56 , step =  0 , loss value =  0.02116587\n",
            "epochs =  56 , step =  100 , loss value =  0.124961525\n",
            "epochs =  56 , step =  200 , loss value =  0.23142557\n",
            "epochs =  56 , step =  300 , loss value =  0.19955622\n",
            "epochs =  56 , step =  400 , loss value =  0.104439214\n",
            "epochs =  56 , step =  500 , loss value =  0.19569057\n",
            "epochs =  57 , step =  0 , loss value =  0.03511361\n",
            "epochs =  57 , step =  100 , loss value =  0.12870774\n",
            "epochs =  57 , step =  200 , loss value =  0.08425354\n",
            "epochs =  57 , step =  300 , loss value =  0.18064322\n",
            "epochs =  57 , step =  400 , loss value =  0.061612282\n",
            "epochs =  57 , step =  500 , loss value =  0.061552122\n",
            "epochs =  58 , step =  0 , loss value =  0.18396091\n",
            "epochs =  58 , step =  100 , loss value =  0.12351511\n",
            "epochs =  58 , step =  200 , loss value =  0.10349645\n",
            "epochs =  58 , step =  300 , loss value =  0.06536116\n",
            "epochs =  58 , step =  400 , loss value =  0.051693693\n",
            "epochs =  58 , step =  500 , loss value =  0.0840275\n",
            "epochs =  59 , step =  0 , loss value =  0.07257128\n",
            "epochs =  59 , step =  100 , loss value =  0.16076235\n",
            "epochs =  59 , step =  200 , loss value =  0.23919483\n",
            "epochs =  59 , step =  300 , loss value =  0.08264218\n",
            "epochs =  59 , step =  400 , loss value =  0.031985227\n",
            "epochs =  59 , step =  500 , loss value =  0.09632895\n",
            "epochs =  60 , step =  0 , loss value =  0.06467276\n",
            "epochs =  60 , step =  100 , loss value =  0.19653118\n",
            "epochs =  60 , step =  200 , loss value =  0.14695624\n",
            "epochs =  60 , step =  300 , loss value =  0.04859095\n",
            "epochs =  60 , step =  400 , loss value =  0.14206839\n",
            "epochs =  60 , step =  500 , loss value =  0.08400378\n",
            "epochs =  61 , step =  0 , loss value =  0.09511025\n",
            "epochs =  61 , step =  100 , loss value =  0.075213216\n",
            "epochs =  61 , step =  200 , loss value =  0.09357364\n",
            "epochs =  61 , step =  300 , loss value =  0.23953304\n",
            "epochs =  61 , step =  400 , loss value =  0.05610898\n",
            "epochs =  61 , step =  500 , loss value =  0.38314235\n",
            "epochs =  62 , step =  0 , loss value =  0.12348067\n",
            "epochs =  62 , step =  100 , loss value =  0.120353125\n",
            "epochs =  62 , step =  200 , loss value =  0.09872883\n",
            "epochs =  62 , step =  300 , loss value =  0.047645673\n",
            "epochs =  62 , step =  400 , loss value =  0.08420545\n",
            "epochs =  62 , step =  500 , loss value =  0.19041866\n",
            "epochs =  63 , step =  0 , loss value =  0.05257743\n",
            "epochs =  63 , step =  100 , loss value =  0.10537876\n",
            "epochs =  63 , step =  200 , loss value =  0.20641409\n",
            "epochs =  63 , step =  300 , loss value =  0.10150036\n",
            "epochs =  63 , step =  400 , loss value =  0.17209405\n",
            "epochs =  63 , step =  500 , loss value =  0.13410209\n",
            "epochs =  64 , step =  0 , loss value =  0.1265164\n",
            "epochs =  64 , step =  100 , loss value =  0.21790189\n",
            "epochs =  64 , step =  200 , loss value =  0.026832564\n",
            "epochs =  64 , step =  300 , loss value =  0.19582257\n",
            "epochs =  64 , step =  400 , loss value =  0.05213378\n",
            "epochs =  64 , step =  500 , loss value =  0.13952957\n",
            "epochs =  65 , step =  0 , loss value =  0.08307017\n",
            "epochs =  65 , step =  100 , loss value =  0.26632023\n",
            "epochs =  65 , step =  200 , loss value =  0.116264746\n",
            "epochs =  65 , step =  300 , loss value =  0.17277704\n",
            "epochs =  65 , step =  400 , loss value =  0.13463967\n",
            "epochs =  65 , step =  500 , loss value =  0.12642376\n",
            "epochs =  66 , step =  0 , loss value =  0.18048881\n",
            "epochs =  66 , step =  100 , loss value =  0.09425718\n",
            "epochs =  66 , step =  200 , loss value =  0.13490093\n",
            "epochs =  66 , step =  300 , loss value =  0.114833504\n",
            "epochs =  66 , step =  400 , loss value =  0.06704815\n",
            "epochs =  66 , step =  500 , loss value =  0.13508053\n",
            "epochs =  67 , step =  0 , loss value =  0.10038774\n",
            "epochs =  67 , step =  100 , loss value =  0.14070259\n",
            "epochs =  67 , step =  200 , loss value =  0.040625535\n",
            "epochs =  67 , step =  300 , loss value =  0.13922402\n",
            "epochs =  67 , step =  400 , loss value =  0.09736787\n",
            "epochs =  67 , step =  500 , loss value =  0.11344535\n",
            "epochs =  68 , step =  0 , loss value =  0.13350944\n",
            "epochs =  68 , step =  100 , loss value =  0.10810083\n",
            "epochs =  68 , step =  200 , loss value =  0.14064372\n",
            "epochs =  68 , step =  300 , loss value =  0.07723079\n",
            "epochs =  68 , step =  400 , loss value =  0.17392232\n",
            "epochs =  68 , step =  500 , loss value =  0.046996456\n",
            "epochs =  69 , step =  0 , loss value =  0.05885763\n",
            "epochs =  69 , step =  100 , loss value =  0.16434938\n",
            "epochs =  69 , step =  200 , loss value =  0.04312912\n",
            "epochs =  69 , step =  300 , loss value =  0.152497\n",
            "epochs =  69 , step =  400 , loss value =  0.09242292\n",
            "epochs =  69 , step =  500 , loss value =  0.037709814\n",
            "epochs =  70 , step =  0 , loss value =  0.07076862\n",
            "epochs =  70 , step =  100 , loss value =  0.23313592\n",
            "epochs =  70 , step =  200 , loss value =  0.10881488\n",
            "epochs =  70 , step =  300 , loss value =  0.08110982\n",
            "epochs =  70 , step =  400 , loss value =  0.1034094\n",
            "epochs =  70 , step =  500 , loss value =  0.17705101\n",
            "epochs =  71 , step =  0 , loss value =  0.18632676\n",
            "epochs =  71 , step =  100 , loss value =  0.09276543\n",
            "epochs =  71 , step =  200 , loss value =  0.080600284\n",
            "epochs =  71 , step =  300 , loss value =  0.03394626\n",
            "epochs =  71 , step =  400 , loss value =  0.102997415\n",
            "epochs =  71 , step =  500 , loss value =  0.26452416\n",
            "epochs =  72 , step =  0 , loss value =  0.08861214\n",
            "epochs =  72 , step =  100 , loss value =  0.122070454\n",
            "epochs =  72 , step =  200 , loss value =  0.17544006\n",
            "epochs =  72 , step =  300 , loss value =  0.119931184\n",
            "epochs =  72 , step =  400 , loss value =  0.14223522\n",
            "epochs =  72 , step =  500 , loss value =  0.34789616\n",
            "epochs =  73 , step =  0 , loss value =  0.06558217\n",
            "epochs =  73 , step =  100 , loss value =  0.10476252\n",
            "epochs =  73 , step =  200 , loss value =  0.19101186\n",
            "epochs =  73 , step =  300 , loss value =  0.058464337\n",
            "epochs =  73 , step =  400 , loss value =  0.021179311\n",
            "epochs =  73 , step =  500 , loss value =  0.036399502\n",
            "epochs =  74 , step =  0 , loss value =  0.08458934\n",
            "epochs =  74 , step =  100 , loss value =  0.14956614\n",
            "epochs =  74 , step =  200 , loss value =  0.13248943\n",
            "epochs =  74 , step =  300 , loss value =  0.2195089\n",
            "epochs =  74 , step =  400 , loss value =  0.12459663\n",
            "epochs =  74 , step =  500 , loss value =  0.033928197\n",
            "epochs =  75 , step =  0 , loss value =  0.05317357\n",
            "epochs =  75 , step =  100 , loss value =  0.12770216\n",
            "epochs =  75 , step =  200 , loss value =  0.12699641\n",
            "epochs =  75 , step =  300 , loss value =  0.072043926\n",
            "epochs =  75 , step =  400 , loss value =  0.11416687\n",
            "epochs =  75 , step =  500 , loss value =  0.28878495\n",
            "epochs =  76 , step =  0 , loss value =  0.032871556\n",
            "epochs =  76 , step =  100 , loss value =  0.06851125\n",
            "epochs =  76 , step =  200 , loss value =  0.06957624\n",
            "epochs =  76 , step =  300 , loss value =  0.115464576\n",
            "epochs =  76 , step =  400 , loss value =  0.074171394\n",
            "epochs =  76 , step =  500 , loss value =  0.14724872\n",
            "epochs =  77 , step =  0 , loss value =  0.08134237\n",
            "epochs =  77 , step =  100 , loss value =  0.071116626\n",
            "epochs =  77 , step =  200 , loss value =  0.07515402\n",
            "epochs =  77 , step =  300 , loss value =  0.10212031\n",
            "epochs =  77 , step =  400 , loss value =  0.16628884\n",
            "epochs =  77 , step =  500 , loss value =  0.102152236\n",
            "epochs =  78 , step =  0 , loss value =  0.29043338\n",
            "epochs =  78 , step =  100 , loss value =  0.03976068\n",
            "epochs =  78 , step =  200 , loss value =  0.062012043\n",
            "epochs =  78 , step =  300 , loss value =  0.24064921\n",
            "epochs =  78 , step =  400 , loss value =  0.09186396\n",
            "epochs =  78 , step =  500 , loss value =  0.088129826\n",
            "epochs =  79 , step =  0 , loss value =  0.061512068\n",
            "epochs =  79 , step =  100 , loss value =  0.06809085\n",
            "epochs =  79 , step =  200 , loss value =  0.07139186\n",
            "epochs =  79 , step =  300 , loss value =  0.113447815\n",
            "epochs =  79 , step =  400 , loss value =  0.086913064\n",
            "epochs =  79 , step =  500 , loss value =  0.16901863\n",
            "epochs =  80 , step =  0 , loss value =  0.061436664\n",
            "epochs =  80 , step =  100 , loss value =  0.09311479\n",
            "epochs =  80 , step =  200 , loss value =  0.09927637\n",
            "epochs =  80 , step =  300 , loss value =  0.18312673\n",
            "epochs =  80 , step =  400 , loss value =  0.05473501\n",
            "epochs =  80 , step =  500 , loss value =  0.040203467\n",
            "epochs =  81 , step =  0 , loss value =  0.05894978\n",
            "epochs =  81 , step =  100 , loss value =  0.07960115\n",
            "epochs =  81 , step =  200 , loss value =  0.032125894\n",
            "epochs =  81 , step =  300 , loss value =  0.083920695\n",
            "epochs =  81 , step =  400 , loss value =  0.11300823\n",
            "epochs =  81 , step =  500 , loss value =  0.08752766\n",
            "epochs =  82 , step =  0 , loss value =  0.074971616\n",
            "epochs =  82 , step =  100 , loss value =  0.09708826\n",
            "epochs =  82 , step =  200 , loss value =  0.026939603\n",
            "epochs =  82 , step =  300 , loss value =  0.058080863\n",
            "epochs =  82 , step =  400 , loss value =  0.062119633\n",
            "epochs =  82 , step =  500 , loss value =  0.04914769\n",
            "epochs =  83 , step =  0 , loss value =  0.07156739\n",
            "epochs =  83 , step =  100 , loss value =  0.065375775\n",
            "epochs =  83 , step =  200 , loss value =  0.115635835\n",
            "epochs =  83 , step =  300 , loss value =  0.10612836\n",
            "epochs =  83 , step =  400 , loss value =  0.13507664\n",
            "epochs =  83 , step =  500 , loss value =  0.11366105\n",
            "epochs =  84 , step =  0 , loss value =  0.0738909\n",
            "epochs =  84 , step =  100 , loss value =  0.07305599\n",
            "epochs =  84 , step =  200 , loss value =  0.17228112\n",
            "epochs =  84 , step =  300 , loss value =  0.05811729\n",
            "epochs =  84 , step =  400 , loss value =  0.117150575\n",
            "epochs =  84 , step =  500 , loss value =  0.07227238\n",
            "epochs =  85 , step =  0 , loss value =  0.10847864\n",
            "epochs =  85 , step =  100 , loss value =  0.07405747\n",
            "epochs =  85 , step =  200 , loss value =  0.11594133\n",
            "epochs =  85 , step =  300 , loss value =  0.0312876\n",
            "epochs =  85 , step =  400 , loss value =  0.08221251\n",
            "epochs =  85 , step =  500 , loss value =  0.19688134\n",
            "epochs =  86 , step =  0 , loss value =  0.06334254\n",
            "epochs =  86 , step =  100 , loss value =  0.032636255\n",
            "epochs =  86 , step =  200 , loss value =  0.046617404\n",
            "epochs =  86 , step =  300 , loss value =  0.09436831\n",
            "epochs =  86 , step =  400 , loss value =  0.061606124\n",
            "epochs =  86 , step =  500 , loss value =  0.019926818\n",
            "epochs =  87 , step =  0 , loss value =  0.113901846\n",
            "epochs =  87 , step =  100 , loss value =  0.07950426\n",
            "epochs =  87 , step =  200 , loss value =  0.064997055\n",
            "epochs =  87 , step =  300 , loss value =  0.031727325\n",
            "epochs =  87 , step =  400 , loss value =  0.12571493\n",
            "epochs =  87 , step =  500 , loss value =  0.15904042\n",
            "epochs =  88 , step =  0 , loss value =  0.07139601\n",
            "epochs =  88 , step =  100 , loss value =  0.15276062\n",
            "epochs =  88 , step =  200 , loss value =  0.20904867\n",
            "epochs =  88 , step =  300 , loss value =  0.03970014\n",
            "epochs =  88 , step =  400 , loss value =  0.037300307\n",
            "epochs =  88 , step =  500 , loss value =  0.094385765\n",
            "epochs =  89 , step =  0 , loss value =  0.0551904\n",
            "epochs =  89 , step =  100 , loss value =  0.15410991\n",
            "epochs =  89 , step =  200 , loss value =  0.030411165\n",
            "epochs =  89 , step =  300 , loss value =  0.031175172\n",
            "epochs =  89 , step =  400 , loss value =  0.13264605\n",
            "epochs =  89 , step =  500 , loss value =  0.078164265\n",
            "epochs =  90 , step =  0 , loss value =  0.062396564\n",
            "epochs =  90 , step =  100 , loss value =  0.09682822\n",
            "epochs =  90 , step =  200 , loss value =  0.050436568\n",
            "epochs =  90 , step =  300 , loss value =  0.023695225\n",
            "epochs =  90 , step =  400 , loss value =  0.0823834\n",
            "epochs =  90 , step =  500 , loss value =  0.15651166\n",
            "epochs =  91 , step =  0 , loss value =  0.06265752\n",
            "epochs =  91 , step =  100 , loss value =  0.090649575\n",
            "epochs =  91 , step =  200 , loss value =  0.029663092\n",
            "epochs =  91 , step =  300 , loss value =  0.06452877\n",
            "epochs =  91 , step =  400 , loss value =  0.14776623\n",
            "epochs =  91 , step =  500 , loss value =  0.06944759\n",
            "epochs =  92 , step =  0 , loss value =  0.12684953\n",
            "epochs =  92 , step =  100 , loss value =  0.11223353\n",
            "epochs =  92 , step =  200 , loss value =  0.05804605\n",
            "epochs =  92 , step =  300 , loss value =  0.13024768\n",
            "epochs =  92 , step =  400 , loss value =  0.13406244\n",
            "epochs =  92 , step =  500 , loss value =  0.09195791\n",
            "epochs =  93 , step =  0 , loss value =  0.12287473\n",
            "epochs =  93 , step =  100 , loss value =  0.116987936\n",
            "epochs =  93 , step =  200 , loss value =  0.07894717\n",
            "epochs =  93 , step =  300 , loss value =  0.11900271\n",
            "epochs =  93 , step =  400 , loss value =  0.07843843\n",
            "epochs =  93 , step =  500 , loss value =  0.04544296\n",
            "epochs =  94 , step =  0 , loss value =  0.034428116\n",
            "epochs =  94 , step =  100 , loss value =  0.037645888\n",
            "epochs =  94 , step =  200 , loss value =  0.04306906\n",
            "epochs =  94 , step =  300 , loss value =  0.26448718\n",
            "epochs =  94 , step =  400 , loss value =  0.07000749\n",
            "epochs =  94 , step =  500 , loss value =  0.042211667\n",
            "epochs =  95 , step =  0 , loss value =  0.06595889\n",
            "epochs =  95 , step =  100 , loss value =  0.0158341\n",
            "epochs =  95 , step =  200 , loss value =  0.05596899\n",
            "epochs =  95 , step =  300 , loss value =  0.0452346\n",
            "epochs =  95 , step =  400 , loss value =  0.19125256\n",
            "epochs =  95 , step =  500 , loss value =  0.04626197\n",
            "epochs =  96 , step =  0 , loss value =  0.029968603\n",
            "epochs =  96 , step =  100 , loss value =  0.11522604\n",
            "epochs =  96 , step =  200 , loss value =  0.06671327\n",
            "epochs =  96 , step =  300 , loss value =  0.08058806\n",
            "epochs =  96 , step =  400 , loss value =  0.038215972\n",
            "epochs =  96 , step =  500 , loss value =  0.052699003\n",
            "epochs =  97 , step =  0 , loss value =  0.102141745\n",
            "epochs =  97 , step =  100 , loss value =  0.042525347\n",
            "epochs =  97 , step =  200 , loss value =  0.12492445\n",
            "epochs =  97 , step =  300 , loss value =  0.107474595\n",
            "epochs =  97 , step =  400 , loss value =  0.052560534\n",
            "epochs =  97 , step =  500 , loss value =  0.046164684\n",
            "epochs =  98 , step =  0 , loss value =  0.055660687\n",
            "epochs =  98 , step =  100 , loss value =  0.102814436\n",
            "epochs =  98 , step =  200 , loss value =  0.14374593\n",
            "epochs =  98 , step =  300 , loss value =  0.02485677\n",
            "epochs =  98 , step =  400 , loss value =  0.0719668\n",
            "epochs =  98 , step =  500 , loss value =  0.13878474\n",
            "epochs =  99 , step =  0 , loss value =  0.109562024\n",
            "epochs =  99 , step =  100 , loss value =  0.11229186\n",
            "epochs =  99 , step =  200 , loss value =  0.03983743\n",
            "epochs =  99 , step =  300 , loss value =  0.096533425\n",
            "epochs =  99 , step =  400 , loss value =  0.14136258\n",
            "epochs =  99 , step =  500 , loss value =  0.059387874\n",
            "\n",
            "Elapsed time =  0:02:00.062719\n",
            "\n",
            "Accuracy =  [0.9496]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kakYNCFuxqeP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}