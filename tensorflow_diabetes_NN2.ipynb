{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflow_NN2_diabetes.ipynb",
      "provenance": [],
      "mount_file_id": "1dMYJ9-AGi3-slaQFvnQJiAhKcwc9vYrX",
      "authorship_tag": "ABX9TyP18Juu2G0KskpbZaY4REh+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HIsu1231/AI_INOVATION_SQUARE/blob/master/tensorflow_diabetes_NN2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rd1VcU60lgB",
        "outputId": "68cb5cc4-d50f-46be-d0fd-c30aab75e748"
      },
      "source": [
        "!pip uninstall tensorflow"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.3.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow-2.3.0.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhRhXY430p86",
        "outputId": "2f7088ad-b707-4a60-ed9a-b91ffa862ba9"
      },
      "source": [
        "!pip install tensorflow==1.15"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 26kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.18.5)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 41.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.34.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.12.1)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 43.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.12.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.10.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.36.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (50.3.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.4.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7542 sha256=6e50a9860c10f811f00f08fc763a80a03196e4c18fe72e330cc7e269bdf7e637\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast, tensorflow-estimator, keras-applications, tensorboard, tensorflow\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkGW1b260sGH"
      },
      "source": [
        "import numpy as np\r\n",
        "import tensorflow as tf"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3klud3l0wNA"
      },
      "source": [
        "class DataGeneration():\r\n",
        "    \r\n",
        "    def __init__(self, file_path, seperation_rate, target_position):\r\n",
        "        \r\n",
        "        self.file_path = file_path\r\n",
        "\r\n",
        "        self.seperation_rate = seperation_rate\r\n",
        "\r\n",
        "        if target_position == -1 or target_position == 0:\r\n",
        "            self.target_position = target_position\r\n",
        "        else:\r\n",
        "            str_err = 'target_position must be -1 or 0'\r\n",
        "            raise Exception(str_err)\r\n",
        "\r\n",
        "    def __display_target_distribution(self, data, str_of_kind):\r\n",
        "\r\n",
        "        target_data = data[:, self.target_position]\r\n",
        "\r\n",
        "        unique, counts = np.unique(target_data, return_counts=True)\r\n",
        "\r\n",
        "        unique_target = []\r\n",
        "\r\n",
        "        print(\"=================================================================================================\")\r\n",
        "        for i in range(len(unique)):\r\n",
        "            print(\"[DataGeneration] unique number of \" + str_of_kind + \" = \", unique[i], \", count = \", counts[i])\r\n",
        "            unique_target.append(unique[i])\r\n",
        "\r\n",
        "            print(\"[DataGeneration] unique number of \" + str_of_kind + \" = \", unique_target[i], \", ratio = \", np.round(100 * len(unique_target) / len(target_data),2) ,'%')\r\n",
        "        print(\"=================================================================================================\")\r\n",
        "\r\n",
        "    def generate(self):\r\n",
        "\r\n",
        "        try:\r\n",
        "            loaded_data = np.loadtxt(self.file_path, delimiter=',')\r\n",
        "\r\n",
        "        except Exception as err:\r\n",
        "          print(\"[DataGeneration::generate()] \", str(err))\r\n",
        "          raise Exception(str(err))\r\n",
        "\r\n",
        "        print(\"loaded_data.shape = \", loaded_data.shape)\r\n",
        "\r\n",
        "        self.__display_target_distribution(loaded_data, 'original data')\r\n",
        "\r\n",
        "        total_data_num = len(loaded_data)\r\n",
        "        test_data_num = int(total_data_num * self.seperation_rate)\r\n",
        "\r\n",
        "        np.random.shuffle(loaded_data)\r\n",
        "\r\n",
        "        test_data = loaded_data[0:test_data_num]\r\n",
        "        training_data = loaded_data[test_data_num: ]\r\n",
        "\r\n",
        "        self.__display_target_distribution(training_data, \"training data\")\r\n",
        "        self.__display_target_distribution(test_data, \"test data\")\r\n",
        "\r\n",
        "        return training_data, test_data"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slZbF3-m3VcV",
        "outputId": "68ebe5c6-8900-4705-8eee-d0f1169b4876"
      },
      "source": [
        "file_path = './drive/MyDrive/AI_INOVATION_SQUARE/data/(200309)diabetes.csv'\r\n",
        "seperation_rate = 0.2\r\n",
        "target_position = -1\r\n",
        "\r\n",
        "data_obj = DataGeneration(file_path, seperation_rate, target_position)\r\n",
        "\r\n",
        "(training_data, test_data) = data_obj.generate()\r\n",
        "\r\n",
        "print(\"training_data.shape = \", training_data.shape)\r\n",
        "print(\"test_data.shape = \", test_data.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loaded_data.shape =  (759, 9)\n",
            "=================================================================================================\n",
            "[DataGeneration] unique number of original data =  0.0 , count =  263\n",
            "[DataGeneration] unique number of original data =  0.0 , ratio =  0.13 %\n",
            "[DataGeneration] unique number of original data =  1.0 , count =  496\n",
            "[DataGeneration] unique number of original data =  1.0 , ratio =  0.26 %\n",
            "=================================================================================================\n",
            "=================================================================================================\n",
            "[DataGeneration] unique number of training data =  0.0 , count =  213\n",
            "[DataGeneration] unique number of training data =  0.0 , ratio =  0.16 %\n",
            "[DataGeneration] unique number of training data =  1.0 , count =  395\n",
            "[DataGeneration] unique number of training data =  1.0 , ratio =  0.33 %\n",
            "=================================================================================================\n",
            "=================================================================================================\n",
            "[DataGeneration] unique number of test data =  0.0 , count =  50\n",
            "[DataGeneration] unique number of test data =  0.0 , ratio =  0.66 %\n",
            "[DataGeneration] unique number of test data =  1.0 , count =  101\n",
            "[DataGeneration] unique number of test data =  1.0 , ratio =  1.32 %\n",
            "=================================================================================================\n",
            "training_data.shape =  (608, 9)\n",
            "test_data.shape =  (151, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qor5Q35N3wL9",
        "outputId": "03774745-81df-469c-b689-7a52e4b41fb6"
      },
      "source": [
        "training_x_data = training_data[:, 0:-1]\r\n",
        "training_t_data = training_data[:, [-1]]\r\n",
        "\r\n",
        "print(\"training_x_data.shape = \", training_x_data.shape)\r\n",
        "print(\"training_t_data.shape = \", training_t_data.shape)\r\n",
        "\r\n",
        "test_x_data = test_data[:, 0:-1]\r\n",
        "test_t_data = test_data[:, [-1]]\r\n",
        "\r\n",
        "print(\"test_x_data.shape = \", test_x_data.shape)\r\n",
        "print(\"test_t_data.shape = \", test_t_data.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training_x_data.shape =  (608, 8)\n",
            "training_t_data.shape =  (608, 1)\n",
            "test_x_data.shape =  (151, 8)\n",
            "test_t_data.shape =  (151, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zki93tSN4UwY"
      },
      "source": [
        "input_nodes = training_x_data.shape[1]\r\n",
        "hidden1_nodes = 4\r\n",
        "hidden2_nodes = 4\r\n",
        "output_nodes = 1\r\n",
        "\r\n",
        "X = tf.placeholder(tf.float32, [None,input_nodes])\r\n",
        "T = tf.placeholder(tf.float32, [None,output_nodes])\r\n",
        "\r\n",
        "W2 = tf.Variable(tf.random_normal([input_nodes,hidden1_nodes]))\r\n",
        "b2 = tf.Variable(tf.random_normal([hidden1_nodes]))\r\n",
        "\r\n",
        "W3 = tf.Variable(tf.random_normal([hidden1_nodes, hidden2_nodes]))\r\n",
        "b3 = tf.Variable(tf.random_normal([hidden2_nodes]))\r\n",
        "\r\n",
        "W4 = tf.Variable(tf.random_normal([hidden2_nodes, output_nodes]))\r\n",
        "b4 = tf.Variable(tf.random_normal([output_nodes]))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-IM_M7E406N"
      },
      "source": [
        "z2 = tf.matmul(X,W2) + b2\r\n",
        "a2 = tf.sigmoid(z2)\r\n",
        "\r\n",
        "z3 = tf.matmul(a2,W3) + b3\r\n",
        "a3 = tf.sigmoid(z3)\r\n",
        "\r\n",
        "z4 = tf.matmul(a3,W4) + b4\r\n",
        "y = tf.sigmoid(z4)\r\n",
        "\r\n",
        "loss = -tf.reduce_mean(T * tf.log(y) + (1-T) * tf.log(1-y))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2zaC1cD5r2Q"
      },
      "source": [
        "learning_rate = 1e-1\r\n",
        "\r\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\r\n",
        "\r\n",
        "train = optimizer.minimize(loss)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DgbQTHd5y8Z"
      },
      "source": [
        "predicted = tf.cast(y > 0.5, tf.float32)\r\n",
        "\r\n",
        "accuracy = tf.reduce_mean(tf.cast(tf.equal(T,predicted),tf.float32))"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUMGbeN86HkV",
        "outputId": "064bf648-0406-4262-93c2-1fd9cd32efbf"
      },
      "source": [
        "with tf.Session() as sess:\r\n",
        "\r\n",
        "    sess.run(tf.global_variables_initializer())\r\n",
        "\r\n",
        "    for i in range(20001):\r\n",
        "\r\n",
        "        loss_val, _ = sess.run([loss, train], feed_dict={X: training_x_data, T: training_t_data})\r\n",
        "\r\n",
        "        if i % 1000 == 0:\r\n",
        "            print(\"i = \", i, \", loss value = \", loss_val)\r\n",
        "\r\n",
        "    y_val, predicted_val, accuracy_val = sess.run([y, predicted, accuracy], feed_dict={X: test_x_data, T: test_t_data})\r\n",
        "\r\n",
        "    print(\"\\ny_val.shape = \", y_val.shape, \", predicted_val.shape = \", predicted_val.shape)\r\n",
        "    print(\"\\nAccuracy = \", accuracy_val)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i =  0 , loss value =  0.7892712\n",
            "i =  1000 , loss value =  0.6438896\n",
            "i =  2000 , loss value =  0.59321153\n",
            "i =  3000 , loss value =  0.4906034\n",
            "i =  4000 , loss value =  0.46600562\n",
            "i =  5000 , loss value =  0.46019584\n",
            "i =  6000 , loss value =  0.45754823\n",
            "i =  7000 , loss value =  0.45574358\n",
            "i =  8000 , loss value =  0.45417395\n",
            "i =  9000 , loss value =  0.45258704\n",
            "i =  10000 , loss value =  0.4508401\n",
            "i =  11000 , loss value =  0.44882092\n",
            "i =  12000 , loss value =  0.4464018\n",
            "i =  13000 , loss value =  0.44340125\n",
            "i =  14000 , loss value =  0.43963823\n",
            "i =  15000 , loss value =  0.43523145\n",
            "i =  16000 , loss value =  0.4308088\n",
            "i =  17000 , loss value =  0.42698082\n",
            "i =  18000 , loss value =  0.42384398\n",
            "i =  19000 , loss value =  0.42124513\n",
            "i =  20000 , loss value =  0.41905442\n",
            "\n",
            "y_val.shape =  (151, 1) , predicted_val.shape =  (151, 1)\n",
            "\n",
            "Accuracy =  0.78807944\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SAO-5Q8693p"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}