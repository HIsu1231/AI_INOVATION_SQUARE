{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN1_BackPropagation_MNIST_Validation0.2(index_label_prediction_list).ipynb",
      "provenance": [],
      "mount_file_id": "1Q7edVTj7TrXrKjua7MXGOomhDf6PGQrn",
      "authorship_tag": "ABX9TyMGHpuqsHPf+HJE8Zo9uF2k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HIsu1231/AI_INOVATION_SQUARE/blob/master/NN1_BackPropagation_MNIST_Validation0_2(index_label_prediction_list).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p40VYjyCo7kP"
      },
      "source": [
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from datetime import datetime"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkHZio4RpA7g"
      },
      "source": [
        "def sigmoid(z):\r\n",
        "    return 1 / (1 + np.exp(-z))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXEtemO3pFKX"
      },
      "source": [
        "class DataGeneration():\r\n",
        "\r\n",
        "  def __init__(self, file_path, seperation_rate, target_position):\r\n",
        "\r\n",
        "    self.file_path = file_path\r\n",
        "\r\n",
        "    self.seperation_rate = seperation_rate\r\n",
        "\r\n",
        "    if (target_position == -1 or target_position == 0):\r\n",
        "      self.target_position = target_position\r\n",
        "    else:\r\n",
        "      err_str = 'target position must be -1 or 0'\r\n",
        "      raise Exception(err_str)\r\n",
        "\r\n",
        "  def __display_target_distribution(self, data, str_of_kind):\r\n",
        "\r\n",
        "    target_data = data[:, self.target_position]\r\n",
        "\r\n",
        "    unique, counts = np.unique(target_data, return_counts = True)\r\n",
        "\r\n",
        "    unique_target = []\r\n",
        "\r\n",
        "    print(\"==============================================================================================\")\r\n",
        "    for i in range(len(unique)):\r\n",
        "        print(\"[DataGeneration] unique number of\" + str_of_kind + \" = \", unique[i], \", count = \", counts[i])\r\n",
        "        unique_target.append(unique[i])\r\n",
        "    \r\n",
        "    for i in range(len(unique_target)):\r\n",
        "        print(\"[DataGeneration] unique number of\" + str_of_kind + \" = \", unique_target[i], \", ratio = \", np.round(100 * counts[i] / len(target_data),2), '%')\r\n",
        "    print(\"==============================================================================================\")\r\n",
        "\r\n",
        "  def generate(self):\r\n",
        "\r\n",
        "    try:\r\n",
        "      loaded_data = np.loadtxt(self.file_path, delimiter=',', dtype=np.float32)\r\n",
        "    \r\n",
        "    except Exception as err:\r\n",
        "      print('[DataGeneration::generate()] ', str(err))\r\n",
        "      raise Exception(str(err))\r\n",
        "\r\n",
        "    self.__display_target_distribution(loaded_data, 'original_data')\r\n",
        "\r\n",
        "    total_data_num = len(loaded_data)\r\n",
        "    validation_data_num = int(len(loaded_data) * self.seperation_rate)\r\n",
        "\r\n",
        "    np.random.shuffle(loaded_data)\r\n",
        "\r\n",
        "    validation_data = loaded_data[0:validation_data_num]\r\n",
        "    training_data = loaded_data[validation_data_num: ]\r\n",
        "\r\n",
        "    self.__display_target_distribution(training_data, 'training_data')\r\n",
        "    self.__display_target_distribution(validation_data, 'validation_data')\r\n",
        "\r\n",
        "    return training_data, validation_data"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74gTOHG1vxgi"
      },
      "source": [
        "class NeuralNetwork():\r\n",
        "\r\n",
        "  def __init__(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\r\n",
        "\r\n",
        "    self.W2 = np.random.randn(input_nodes, hidden_nodes) / np.sqrt(input_nodes / 2)\r\n",
        "    self.b2 = np.random.rand(hidden_nodes)\r\n",
        "\r\n",
        "    self.W3 = np.random.randn(hidden_nodes, output_nodes) / np.sqrt(hidden_nodes / 2)\r\n",
        "    self.b3 = np.random.rand(output_nodes)\r\n",
        "\r\n",
        "    self.learning_rate = learning_rate\r\n",
        "\r\n",
        "  def feed_forward(self):\r\n",
        "\r\n",
        "    delta = 1e-7\r\n",
        "\r\n",
        "    self.z1 = self.input_data\r\n",
        "    self.a1 = self.input_data\r\n",
        "\r\n",
        "    self.z2 = np.dot(self.a1, self.W2) + self.b2\r\n",
        "    self.a2 = sigmoid(self.z2)\r\n",
        "\r\n",
        "    self.z3 = np.dot(self.a2, self.W3) + self.b3\r\n",
        "    self.a3 = sigmoid(self.z3)\r\n",
        "\r\n",
        "    return -np.sum(self.target_data * np.log(self.a3 + delta) + (1 - self.target_data) * np.log((1 - self.a3) + delta))\r\n",
        "\r\n",
        "  def loss_val(self):\r\n",
        "\r\n",
        "    delta = 1e-7\r\n",
        "\r\n",
        "    self.z1 = self.input_data\r\n",
        "    self.a1 = self.input_data\r\n",
        "\r\n",
        "    self.z2 = np.dot(self.a1, self.W2) + self.b2\r\n",
        "    self.a2 = sigmoid(self.z2)\r\n",
        "\r\n",
        "    self.z3 = np.dot(self.a2, self.W3) + self.b3\r\n",
        "    self.a3 = sigmoid(self.z3)\r\n",
        "\r\n",
        "    return -np.sum(self.target_data * np.log(self.a3 + delta) + (1 - self.target_data) * np.log((1 - self.a3) + delta))\r\n",
        "\r\n",
        "  def accuracy(self, test_input_data, test_target_data):\r\n",
        "\r\n",
        "    matched_list = []\r\n",
        "\r\n",
        "    temp_list = []\r\n",
        "    index_label_prediction_list = []\r\n",
        "\r\n",
        "    for i in range(len(test_input_data)):\r\n",
        "\r\n",
        "      label = int(test_target_data[i])\r\n",
        "\r\n",
        "      data = test_input_data[i] / 255.0 * 0.99 + 0.01\r\n",
        "      predicted_num = self.predict(np.array(data,ndmin=2))\r\n",
        "\r\n",
        "      if label == predicted_num:\r\n",
        "        matched_list.append(i)\r\n",
        "      \r\n",
        "      else:\r\n",
        "        temp_list.append(i)\r\n",
        "        temp_list.append(label)\r\n",
        "        temp_list.append(predicted_num)\r\n",
        "\r\n",
        "        index_label_prediction_list.append(temp_list)\r\n",
        "\r\n",
        "        temp_list = []\r\n",
        "    \r\n",
        "    accuracy_val = len(matched_list) / len(test_input_data)\r\n",
        "\r\n",
        "    return accuracy_val, index_label_prediction_list\r\n",
        "    \r\n",
        "  def train(self, input_data, target_data):\r\n",
        "\r\n",
        "    self.input_data = input_data\r\n",
        "    self.target_data = target_data\r\n",
        "\r\n",
        "    loss_val = self.feed_forward()\r\n",
        "\r\n",
        "    loss_3 = (self.a3 - self.target_data) * self.a3 * (1 - self.a3)\r\n",
        "    loss_2 = np.dot(loss_3,self.W3.T) * self.a2 * (1 - self.a2)\r\n",
        "\r\n",
        "    self.W3 = self.W3 - self.learning_rate * np.dot(self.a2.T,loss_3)\r\n",
        "    self.b3 = self.b3 - self.learning_rate * loss_3\r\n",
        "\r\n",
        "    self.W2 = self.W2 - self.learning_rate * np.dot(self.a1.T,loss_2)\r\n",
        "    self.b2 = self.b2 - self.learning_rate * loss_2\r\n",
        "\r\n",
        "  def predict(self, input_data):\r\n",
        "\r\n",
        "    z2 = np.dot(input_data, self.W2) + self.b2\r\n",
        "    a2 = sigmoid(z2)\r\n",
        "\r\n",
        "    z3 = np.dot(a2, self.W3) + self.b3\r\n",
        "    a3 = sigmoid(z3)\r\n",
        "\r\n",
        "    predicted_num = np.argmax(a3)\r\n",
        "\r\n",
        "    return predicted_num\r\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Djd3j2_qB1pI",
        "outputId": "bd5dd842-e09a-4475-d68a-b831e62124ef"
      },
      "source": [
        "file_path = './drive/MyDrive/AI_INOVATION_SQUARE/data/mnist_train.csv'\r\n",
        "seperation_rate = 0.2\r\n",
        "target_position = 0\r\n",
        "\r\n",
        "data_obj = DataGeneration(file_path, seperation_rate, target_position)\r\n",
        "\r\n",
        "(training_data, validation_data) = data_obj.generate()\r\n",
        "\r\n",
        "print(\"training_data.shape = \", training_data.shape)\r\n",
        "print(\"validation_data.shape = \", validation_data.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==============================================================================================\n",
            "[DataGeneration] unique number oforiginal_data =  0.0 , count =  5923\n",
            "[DataGeneration] unique number oforiginal_data =  1.0 , count =  6742\n",
            "[DataGeneration] unique number oforiginal_data =  2.0 , count =  5958\n",
            "[DataGeneration] unique number oforiginal_data =  3.0 , count =  6131\n",
            "[DataGeneration] unique number oforiginal_data =  4.0 , count =  5842\n",
            "[DataGeneration] unique number oforiginal_data =  5.0 , count =  5421\n",
            "[DataGeneration] unique number oforiginal_data =  6.0 , count =  5918\n",
            "[DataGeneration] unique number oforiginal_data =  7.0 , count =  6265\n",
            "[DataGeneration] unique number oforiginal_data =  8.0 , count =  5851\n",
            "[DataGeneration] unique number oforiginal_data =  9.0 , count =  5949\n",
            "[DataGeneration] unique number oforiginal_data =  0.0 , ratio =  9.87 %\n",
            "[DataGeneration] unique number oforiginal_data =  1.0 , ratio =  11.24 %\n",
            "[DataGeneration] unique number oforiginal_data =  2.0 , ratio =  9.93 %\n",
            "[DataGeneration] unique number oforiginal_data =  3.0 , ratio =  10.22 %\n",
            "[DataGeneration] unique number oforiginal_data =  4.0 , ratio =  9.74 %\n",
            "[DataGeneration] unique number oforiginal_data =  5.0 , ratio =  9.04 %\n",
            "[DataGeneration] unique number oforiginal_data =  6.0 , ratio =  9.86 %\n",
            "[DataGeneration] unique number oforiginal_data =  7.0 , ratio =  10.44 %\n",
            "[DataGeneration] unique number oforiginal_data =  8.0 , ratio =  9.75 %\n",
            "[DataGeneration] unique number oforiginal_data =  9.0 , ratio =  9.91 %\n",
            "==============================================================================================\n",
            "==============================================================================================\n",
            "[DataGeneration] unique number oftraining_data =  0.0 , count =  4716\n",
            "[DataGeneration] unique number oftraining_data =  1.0 , count =  5406\n",
            "[DataGeneration] unique number oftraining_data =  2.0 , count =  4747\n",
            "[DataGeneration] unique number oftraining_data =  3.0 , count =  4889\n",
            "[DataGeneration] unique number oftraining_data =  4.0 , count =  4678\n",
            "[DataGeneration] unique number oftraining_data =  5.0 , count =  4351\n",
            "[DataGeneration] unique number oftraining_data =  6.0 , count =  4724\n",
            "[DataGeneration] unique number oftraining_data =  7.0 , count =  5043\n",
            "[DataGeneration] unique number oftraining_data =  8.0 , count =  4679\n",
            "[DataGeneration] unique number oftraining_data =  9.0 , count =  4767\n",
            "[DataGeneration] unique number oftraining_data =  0.0 , ratio =  9.82 %\n",
            "[DataGeneration] unique number oftraining_data =  1.0 , ratio =  11.26 %\n",
            "[DataGeneration] unique number oftraining_data =  2.0 , ratio =  9.89 %\n",
            "[DataGeneration] unique number oftraining_data =  3.0 , ratio =  10.19 %\n",
            "[DataGeneration] unique number oftraining_data =  4.0 , ratio =  9.75 %\n",
            "[DataGeneration] unique number oftraining_data =  5.0 , ratio =  9.06 %\n",
            "[DataGeneration] unique number oftraining_data =  6.0 , ratio =  9.84 %\n",
            "[DataGeneration] unique number oftraining_data =  7.0 , ratio =  10.51 %\n",
            "[DataGeneration] unique number oftraining_data =  8.0 , ratio =  9.75 %\n",
            "[DataGeneration] unique number oftraining_data =  9.0 , ratio =  9.93 %\n",
            "==============================================================================================\n",
            "==============================================================================================\n",
            "[DataGeneration] unique number ofvalidation_data =  0.0 , count =  1207\n",
            "[DataGeneration] unique number ofvalidation_data =  1.0 , count =  1336\n",
            "[DataGeneration] unique number ofvalidation_data =  2.0 , count =  1211\n",
            "[DataGeneration] unique number ofvalidation_data =  3.0 , count =  1242\n",
            "[DataGeneration] unique number ofvalidation_data =  4.0 , count =  1164\n",
            "[DataGeneration] unique number ofvalidation_data =  5.0 , count =  1070\n",
            "[DataGeneration] unique number ofvalidation_data =  6.0 , count =  1194\n",
            "[DataGeneration] unique number ofvalidation_data =  7.0 , count =  1222\n",
            "[DataGeneration] unique number ofvalidation_data =  8.0 , count =  1172\n",
            "[DataGeneration] unique number ofvalidation_data =  9.0 , count =  1182\n",
            "[DataGeneration] unique number ofvalidation_data =  0.0 , ratio =  10.06 %\n",
            "[DataGeneration] unique number ofvalidation_data =  1.0 , ratio =  11.13 %\n",
            "[DataGeneration] unique number ofvalidation_data =  2.0 , ratio =  10.09 %\n",
            "[DataGeneration] unique number ofvalidation_data =  3.0 , ratio =  10.35 %\n",
            "[DataGeneration] unique number ofvalidation_data =  4.0 , ratio =  9.7 %\n",
            "[DataGeneration] unique number ofvalidation_data =  5.0 , ratio =  8.92 %\n",
            "[DataGeneration] unique number ofvalidation_data =  6.0 , ratio =  9.95 %\n",
            "[DataGeneration] unique number ofvalidation_data =  7.0 , ratio =  10.18 %\n",
            "[DataGeneration] unique number ofvalidation_data =  8.0 , ratio =  9.77 %\n",
            "[DataGeneration] unique number ofvalidation_data =  9.0 , ratio =  9.85 %\n",
            "==============================================================================================\n",
            "training_data.shape =  (48000, 785)\n",
            "validation_data.shape =  (12000, 785)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vulZYdSFC2cR",
        "outputId": "9a623289-da29-4a00-c267-cc3f0db219d9"
      },
      "source": [
        "#hyper_paramter\r\n",
        "\r\n",
        "i_nodes = training_data.shape[1] - 1\r\n",
        "h_nodes = 100\r\n",
        "o_nodes = 10\r\n",
        "epochs = 20\r\n",
        "lr = 0.1\r\n",
        "\r\n",
        "loss_val_list = []\r\n",
        "\r\n",
        "training_accuracy_list = []\r\n",
        "validation_accuracy_list = []\r\n",
        "\r\n",
        "index_label_prediction_list = []\r\n",
        "\r\n",
        "nn = NeuralNetwork(i_nodes, h_nodes, o_nodes, lr)\r\n",
        "\r\n",
        "start_time = datetime.now()\r\n",
        "\r\n",
        "for i in range(epochs):\r\n",
        "    for step in range(len(training_data)):\r\n",
        "\r\n",
        "      input_data = (training_data[step,1: ] / 255.0 * 0.99) + 0.01\r\n",
        "\r\n",
        "      target_data = np.zeros(o_nodes) + 0.01\r\n",
        "      target_data[int(training_data[step,0])] = 0.99\r\n",
        "\r\n",
        "      nn.train(np.array(input_data,ndmin=2), np.array(target_data,ndmin=2))\r\n",
        "\r\n",
        "      if step % 1000 == 0:\r\n",
        "        print(\"epochs = \", i, \", step = \", step, \", loss value = \", nn.loss_val())\r\n",
        "\r\n",
        "      #손실값 저장 per step\r\n",
        "      loss_val_list.append(nn.loss_val())\r\n",
        "    \r\n",
        "    #정확도 계산 및 저장 per epochs\r\n",
        "    (training_accuracy, index_label_prediction_list) = nn.accuracy(training_data[:,1: ], training_data[:,0])\r\n",
        "    (validation_accuracy, index_label_prediction_list) = nn.accuracy(validation_data[:, 1:], validation_data[:,0])\r\n",
        "\r\n",
        "    print(\"\\n current epochs = \", i, \", current training accuracy = \", 100 * np.round(training_accuracy,3),'%')\r\n",
        "    print(\"current epochs = \", i, \", current validation accuracy = \", 100 * np.round(validation_accuracy,3),'%\\n')\r\n",
        "\r\n",
        "    training_accuracy_list.append(training_accuracy)\r\n",
        "    validation_accuracy_list.append(validation_accuracy)\r\n",
        "\r\n",
        "end_time = datetime.now()\r\n",
        "print(\"\\nElpased time = \", end_time - start_time)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epochs =  0 , step =  0 , loss value =  7.174138623568299\n",
            "epochs =  0 , step =  1000 , loss value =  1.1530475054206706\n",
            "epochs =  0 , step =  2000 , loss value =  1.0848477968533699\n",
            "epochs =  0 , step =  3000 , loss value =  0.7532519528281487\n",
            "epochs =  0 , step =  4000 , loss value =  1.1324910803704846\n",
            "epochs =  0 , step =  5000 , loss value =  0.7252920882387033\n",
            "epochs =  0 , step =  6000 , loss value =  1.0959139730149021\n",
            "epochs =  0 , step =  7000 , loss value =  2.0120165761046365\n",
            "epochs =  0 , step =  8000 , loss value =  1.1815897777811106\n",
            "epochs =  0 , step =  9000 , loss value =  0.7212795712508419\n",
            "epochs =  0 , step =  10000 , loss value =  0.7225978431414907\n",
            "epochs =  0 , step =  11000 , loss value =  0.6810338543876435\n",
            "epochs =  0 , step =  12000 , loss value =  0.8961787329947548\n",
            "epochs =  0 , step =  13000 , loss value =  0.8536602113810733\n",
            "epochs =  0 , step =  14000 , loss value =  1.0067040862209644\n",
            "epochs =  0 , step =  15000 , loss value =  1.1577167834498896\n",
            "epochs =  0 , step =  16000 , loss value =  0.6878450756055512\n",
            "epochs =  0 , step =  17000 , loss value =  1.0964230339291634\n",
            "epochs =  0 , step =  18000 , loss value =  2.9245356877829822\n",
            "epochs =  0 , step =  19000 , loss value =  0.6403124147750451\n",
            "epochs =  0 , step =  20000 , loss value =  0.7292675498398915\n",
            "epochs =  0 , step =  21000 , loss value =  0.7804388365302735\n",
            "epochs =  0 , step =  22000 , loss value =  0.9640612405506281\n",
            "epochs =  0 , step =  23000 , loss value =  0.7414766471430283\n",
            "epochs =  0 , step =  24000 , loss value =  0.6809484580911138\n",
            "epochs =  0 , step =  25000 , loss value =  0.7589958527294202\n",
            "epochs =  0 , step =  26000 , loss value =  0.753630135089127\n",
            "epochs =  0 , step =  27000 , loss value =  1.0619337587017628\n",
            "epochs =  0 , step =  28000 , loss value =  1.2559264913141288\n",
            "epochs =  0 , step =  29000 , loss value =  0.7145107851671884\n",
            "epochs =  0 , step =  30000 , loss value =  0.6807795802656341\n",
            "epochs =  0 , step =  31000 , loss value =  0.6907104491125738\n",
            "epochs =  0 , step =  32000 , loss value =  0.7162640242797415\n",
            "epochs =  0 , step =  33000 , loss value =  0.8116669678292245\n",
            "epochs =  0 , step =  34000 , loss value =  0.966155418128028\n",
            "epochs =  0 , step =  35000 , loss value =  0.7474440006505886\n",
            "epochs =  0 , step =  36000 , loss value =  0.7171247860354998\n",
            "epochs =  0 , step =  37000 , loss value =  0.7153622413536777\n",
            "epochs =  0 , step =  38000 , loss value =  0.8023862081579447\n",
            "epochs =  0 , step =  39000 , loss value =  0.8269017106236818\n",
            "epochs =  0 , step =  40000 , loss value =  0.6842486471514007\n",
            "epochs =  0 , step =  41000 , loss value =  0.7174447953113015\n",
            "epochs =  0 , step =  42000 , loss value =  1.1210469539986627\n",
            "epochs =  0 , step =  43000 , loss value =  0.9563737719973068\n",
            "epochs =  0 , step =  44000 , loss value =  0.7438517295688701\n",
            "epochs =  0 , step =  45000 , loss value =  0.7751146531783831\n",
            "epochs =  0 , step =  46000 , loss value =  0.7596108941466787\n",
            "epochs =  0 , step =  47000 , loss value =  0.7124716240634607\n",
            "\n",
            " current epochs =  0 , current training accuracy =  93.8 %\n",
            "current epochs =  0 , current validation accuracy =  93.5 %\n",
            "\n",
            "epochs =  1 , step =  0 , loss value =  0.6993699621925455\n",
            "epochs =  1 , step =  1000 , loss value =  0.8238655184535435\n",
            "epochs =  1 , step =  2000 , loss value =  0.8058708691039382\n",
            "epochs =  1 , step =  3000 , loss value =  0.8015427237627729\n",
            "epochs =  1 , step =  4000 , loss value =  1.1088218188947325\n",
            "epochs =  1 , step =  5000 , loss value =  0.6843434797235999\n",
            "epochs =  1 , step =  6000 , loss value =  0.9442183150735662\n",
            "epochs =  1 , step =  7000 , loss value =  1.4936748519721599\n",
            "epochs =  1 , step =  8000 , loss value =  0.9668729809836607\n",
            "epochs =  1 , step =  9000 , loss value =  0.8898211333642656\n",
            "epochs =  1 , step =  10000 , loss value =  0.8397929728426357\n",
            "epochs =  1 , step =  11000 , loss value =  0.7619956606359006\n",
            "epochs =  1 , step =  12000 , loss value =  0.7049796654314416\n",
            "epochs =  1 , step =  13000 , loss value =  0.7184267473057943\n",
            "epochs =  1 , step =  14000 , loss value =  0.8591709394545725\n",
            "epochs =  1 , step =  15000 , loss value =  1.0532883174039358\n",
            "epochs =  1 , step =  16000 , loss value =  0.7253225166082301\n",
            "epochs =  1 , step =  17000 , loss value =  1.1170960661713587\n",
            "epochs =  1 , step =  18000 , loss value =  1.6956721484693311\n",
            "epochs =  1 , step =  19000 , loss value =  0.7278536746477415\n",
            "epochs =  1 , step =  20000 , loss value =  0.7331191751579699\n",
            "epochs =  1 , step =  21000 , loss value =  0.7904855513409462\n",
            "epochs =  1 , step =  22000 , loss value =  0.9188499759163378\n",
            "epochs =  1 , step =  23000 , loss value =  0.8385842642826219\n",
            "epochs =  1 , step =  24000 , loss value =  0.7183686029071579\n",
            "epochs =  1 , step =  25000 , loss value =  0.8043793478611446\n",
            "epochs =  1 , step =  26000 , loss value =  0.7908755994782736\n",
            "epochs =  1 , step =  27000 , loss value =  0.8333984197197625\n",
            "epochs =  1 , step =  28000 , loss value =  1.0657221779423671\n",
            "epochs =  1 , step =  29000 , loss value =  0.7724683441517619\n",
            "epochs =  1 , step =  30000 , loss value =  0.7120589160364209\n",
            "epochs =  1 , step =  31000 , loss value =  0.7311523192446745\n",
            "epochs =  1 , step =  32000 , loss value =  0.782953111765747\n",
            "epochs =  1 , step =  33000 , loss value =  0.8288823758139209\n",
            "epochs =  1 , step =  34000 , loss value =  0.9290983430557049\n",
            "epochs =  1 , step =  35000 , loss value =  0.7313212114642613\n",
            "epochs =  1 , step =  36000 , loss value =  0.7679681715901296\n",
            "epochs =  1 , step =  37000 , loss value =  0.7532476482088512\n",
            "epochs =  1 , step =  38000 , loss value =  0.8483275408000194\n",
            "epochs =  1 , step =  39000 , loss value =  0.7443687366484717\n",
            "epochs =  1 , step =  40000 , loss value =  0.7264261761676083\n",
            "epochs =  1 , step =  41000 , loss value =  0.7249168525039009\n",
            "epochs =  1 , step =  42000 , loss value =  0.9642896118764359\n",
            "epochs =  1 , step =  43000 , loss value =  0.880379066794981\n",
            "epochs =  1 , step =  44000 , loss value =  0.75309444322266\n",
            "epochs =  1 , step =  45000 , loss value =  0.8087808347665175\n",
            "epochs =  1 , step =  46000 , loss value =  0.7768409404631159\n",
            "epochs =  1 , step =  47000 , loss value =  0.7402918424740143\n",
            "\n",
            " current epochs =  1 , current training accuracy =  95.7 %\n",
            "current epochs =  1 , current validation accuracy =  95.19999999999999 %\n",
            "\n",
            "epochs =  2 , step =  0 , loss value =  0.7272173931670991\n",
            "epochs =  2 , step =  1000 , loss value =  0.8516964649164924\n",
            "epochs =  2 , step =  2000 , loss value =  0.7690330570071429\n",
            "epochs =  2 , step =  3000 , loss value =  0.8347821135264966\n",
            "epochs =  2 , step =  4000 , loss value =  0.999685611619324\n",
            "epochs =  2 , step =  5000 , loss value =  0.6872661189072743\n",
            "epochs =  2 , step =  6000 , loss value =  0.9123265341418284\n",
            "epochs =  2 , step =  7000 , loss value =  1.260662004299756\n",
            "epochs =  2 , step =  8000 , loss value =  0.9037874750784198\n",
            "epochs =  2 , step =  9000 , loss value =  0.945171013199045\n",
            "epochs =  2 , step =  10000 , loss value =  0.8781429975178061\n",
            "epochs =  2 , step =  11000 , loss value =  0.7793457329759326\n",
            "epochs =  2 , step =  12000 , loss value =  0.6834284144529478\n",
            "epochs =  2 , step =  13000 , loss value =  0.7132361684754324\n",
            "epochs =  2 , step =  14000 , loss value =  0.8491717764948679\n",
            "epochs =  2 , step =  15000 , loss value =  0.9164326865872111\n",
            "epochs =  2 , step =  16000 , loss value =  0.7450620738800511\n",
            "epochs =  2 , step =  17000 , loss value =  1.014937643524535\n",
            "epochs =  2 , step =  18000 , loss value =  1.2952852482796002\n",
            "epochs =  2 , step =  19000 , loss value =  0.7402202177718694\n",
            "epochs =  2 , step =  20000 , loss value =  0.7269066365577594\n",
            "epochs =  2 , step =  21000 , loss value =  0.7834293652510824\n",
            "epochs =  2 , step =  22000 , loss value =  0.8953073472676345\n",
            "epochs =  2 , step =  23000 , loss value =  0.8819477018584303\n",
            "epochs =  2 , step =  24000 , loss value =  0.7452481960623782\n",
            "epochs =  2 , step =  25000 , loss value =  0.8180093845602273\n",
            "epochs =  2 , step =  26000 , loss value =  0.7891080443299359\n",
            "epochs =  2 , step =  27000 , loss value =  0.8219815409488022\n",
            "epochs =  2 , step =  28000 , loss value =  0.9689082234622143\n",
            "epochs =  2 , step =  29000 , loss value =  0.7843999891251849\n",
            "epochs =  2 , step =  30000 , loss value =  0.7298340994534491\n",
            "epochs =  2 , step =  31000 , loss value =  0.7331004868835311\n",
            "epochs =  2 , step =  32000 , loss value =  0.8080271144521982\n",
            "epochs =  2 , step =  33000 , loss value =  0.8094583312782211\n",
            "epochs =  2 , step =  34000 , loss value =  0.8834250854944982\n",
            "epochs =  2 , step =  35000 , loss value =  0.7546295881545956\n",
            "epochs =  2 , step =  36000 , loss value =  0.789872591057432\n",
            "epochs =  2 , step =  37000 , loss value =  0.7707543537767404\n",
            "epochs =  2 , step =  38000 , loss value =  0.8441978320864787\n",
            "epochs =  2 , step =  39000 , loss value =  0.7347687346192701\n",
            "epochs =  2 , step =  40000 , loss value =  0.7723105283317023\n",
            "epochs =  2 , step =  41000 , loss value =  0.748719502744901\n",
            "epochs =  2 , step =  42000 , loss value =  0.9463881973868404\n",
            "epochs =  2 , step =  43000 , loss value =  0.8645752599576142\n",
            "epochs =  2 , step =  44000 , loss value =  0.7539873883140292\n",
            "epochs =  2 , step =  45000 , loss value =  0.8111979154113595\n",
            "epochs =  2 , step =  46000 , loss value =  0.7918708013247406\n",
            "epochs =  2 , step =  47000 , loss value =  0.7615619536962249\n",
            "\n",
            " current epochs =  2 , current training accuracy =  96.6 %\n",
            "current epochs =  2 , current validation accuracy =  95.89999999999999 %\n",
            "\n",
            "epochs =  3 , step =  0 , loss value =  0.7392702600149224\n",
            "epochs =  3 , step =  1000 , loss value =  0.8703442727493651\n",
            "epochs =  3 , step =  2000 , loss value =  0.7467868468481185\n",
            "epochs =  3 , step =  3000 , loss value =  0.8505519867043102\n",
            "epochs =  3 , step =  4000 , loss value =  0.888586225120173\n",
            "epochs =  3 , step =  5000 , loss value =  0.7046403254538914\n",
            "epochs =  3 , step =  6000 , loss value =  0.8791924522491239\n",
            "epochs =  3 , step =  7000 , loss value =  1.1692277648248148\n",
            "epochs =  3 , step =  8000 , loss value =  0.9053853375578641\n",
            "epochs =  3 , step =  9000 , loss value =  0.9813029029892153\n",
            "epochs =  3 , step =  10000 , loss value =  0.9113646883777462\n",
            "epochs =  3 , step =  11000 , loss value =  0.7891656271566704\n",
            "epochs =  3 , step =  12000 , loss value =  0.6876473706026998\n",
            "epochs =  3 , step =  13000 , loss value =  0.7296554798875389\n",
            "epochs =  3 , step =  14000 , loss value =  0.850057408991847\n",
            "epochs =  3 , step =  15000 , loss value =  0.8757897104936944\n",
            "epochs =  3 , step =  16000 , loss value =  0.7728000868079553\n",
            "epochs =  3 , step =  17000 , loss value =  0.9403699294595769\n",
            "epochs =  3 , step =  18000 , loss value =  1.1441498337117382\n",
            "epochs =  3 , step =  19000 , loss value =  0.7430067798540787\n",
            "epochs =  3 , step =  20000 , loss value =  0.7324259013971488\n",
            "epochs =  3 , step =  21000 , loss value =  0.7908280652822269\n",
            "epochs =  3 , step =  22000 , loss value =  0.8735930358816841\n",
            "epochs =  3 , step =  23000 , loss value =  0.8936827047872209\n",
            "epochs =  3 , step =  24000 , loss value =  0.7556490074374266\n",
            "epochs =  3 , step =  25000 , loss value =  0.8356549479357094\n",
            "epochs =  3 , step =  26000 , loss value =  0.7882445542209069\n",
            "epochs =  3 , step =  27000 , loss value =  0.8247917079078114\n",
            "epochs =  3 , step =  28000 , loss value =  0.898045246236564\n",
            "epochs =  3 , step =  29000 , loss value =  0.792757526942016\n",
            "epochs =  3 , step =  30000 , loss value =  0.7336037004766155\n",
            "epochs =  3 , step =  31000 , loss value =  0.7338306111717359\n",
            "epochs =  3 , step =  32000 , loss value =  0.835112648044655\n",
            "epochs =  3 , step =  33000 , loss value =  0.8193490056695312\n",
            "epochs =  3 , step =  34000 , loss value =  0.8535627971186549\n",
            "epochs =  3 , step =  35000 , loss value =  0.7758925034399013\n",
            "epochs =  3 , step =  36000 , loss value =  0.7986401407351919\n",
            "epochs =  3 , step =  37000 , loss value =  0.7674517809338351\n",
            "epochs =  3 , step =  38000 , loss value =  0.8427513364836234\n",
            "epochs =  3 , step =  39000 , loss value =  0.7389690860679226\n",
            "epochs =  3 , step =  40000 , loss value =  0.7973323814317227\n",
            "epochs =  3 , step =  41000 , loss value =  0.7679024879591297\n",
            "epochs =  3 , step =  42000 , loss value =  0.950488521651978\n",
            "epochs =  3 , step =  43000 , loss value =  0.8782327891980598\n",
            "epochs =  3 , step =  44000 , loss value =  0.7664355805426261\n",
            "epochs =  3 , step =  45000 , loss value =  0.8190163472933462\n",
            "epochs =  3 , step =  46000 , loss value =  0.8137246668131674\n",
            "epochs =  3 , step =  47000 , loss value =  0.793095467761615\n",
            "\n",
            " current epochs =  3 , current training accuracy =  97.1 %\n",
            "current epochs =  3 , current validation accuracy =  96.1 %\n",
            "\n",
            "epochs =  4 , step =  0 , loss value =  0.7483298596986814\n",
            "epochs =  4 , step =  1000 , loss value =  0.8917665142929294\n",
            "epochs =  4 , step =  2000 , loss value =  0.7492084595715174\n",
            "epochs =  4 , step =  3000 , loss value =  0.8639915972567496\n",
            "epochs =  4 , step =  4000 , loss value =  0.8552152920235353\n",
            "epochs =  4 , step =  5000 , loss value =  0.7276373871863379\n",
            "epochs =  4 , step =  6000 , loss value =  0.8637617985288891\n",
            "epochs =  4 , step =  7000 , loss value =  1.1206504324551103\n",
            "epochs =  4 , step =  8000 , loss value =  0.9311792900958369\n",
            "epochs =  4 , step =  9000 , loss value =  1.00723625350431\n",
            "epochs =  4 , step =  10000 , loss value =  0.9524396728943938\n",
            "epochs =  4 , step =  11000 , loss value =  0.7966806876142324\n",
            "epochs =  4 , step =  12000 , loss value =  0.6956066256084562\n",
            "epochs =  4 , step =  13000 , loss value =  0.7470703304817988\n",
            "epochs =  4 , step =  14000 , loss value =  0.8561110836769461\n",
            "epochs =  4 , step =  15000 , loss value =  0.8885611821474915\n",
            "epochs =  4 , step =  16000 , loss value =  0.7999001993675878\n",
            "epochs =  4 , step =  17000 , loss value =  0.9141737563436382\n",
            "epochs =  4 , step =  18000 , loss value =  1.0538274927582045\n",
            "epochs =  4 , step =  19000 , loss value =  0.749641791214132\n",
            "epochs =  4 , step =  20000 , loss value =  0.7378721794808608\n",
            "epochs =  4 , step =  21000 , loss value =  0.8013124962280445\n",
            "epochs =  4 , step =  22000 , loss value =  0.8431772254143218\n",
            "epochs =  4 , step =  23000 , loss value =  0.9435572983539745\n",
            "epochs =  4 , step =  24000 , loss value =  0.7632890157839634\n",
            "epochs =  4 , step =  25000 , loss value =  0.8556676609953554\n",
            "epochs =  4 , step =  26000 , loss value =  0.7916166980901166\n",
            "epochs =  4 , step =  27000 , loss value =  0.8423109220948158\n",
            "epochs =  4 , step =  28000 , loss value =  0.8619732637115929\n",
            "epochs =  4 , step =  29000 , loss value =  0.804264338636435\n",
            "epochs =  4 , step =  30000 , loss value =  0.7365035062579532\n",
            "epochs =  4 , step =  31000 , loss value =  0.7314348281936107\n",
            "epochs =  4 , step =  32000 , loss value =  0.8646728968804143\n",
            "epochs =  4 , step =  33000 , loss value =  0.8397454014775569\n",
            "epochs =  4 , step =  34000 , loss value =  0.8342314369785963\n",
            "epochs =  4 , step =  35000 , loss value =  0.7775140124651656\n",
            "epochs =  4 , step =  36000 , loss value =  0.8050928442912259\n",
            "epochs =  4 , step =  37000 , loss value =  0.7645663497588525\n",
            "epochs =  4 , step =  38000 , loss value =  0.8428017069067915\n",
            "epochs =  4 , step =  39000 , loss value =  0.7513364513283203\n",
            "epochs =  4 , step =  40000 , loss value =  0.8252927998985635\n",
            "epochs =  4 , step =  41000 , loss value =  0.7801048584768788\n",
            "epochs =  4 , step =  42000 , loss value =  0.9636993847847802\n",
            "epochs =  4 , step =  43000 , loss value =  0.8962524670394323\n",
            "epochs =  4 , step =  44000 , loss value =  0.7736454972123538\n",
            "epochs =  4 , step =  45000 , loss value =  0.8249955260075409\n",
            "epochs =  4 , step =  46000 , loss value =  0.8397116567843349\n",
            "epochs =  4 , step =  47000 , loss value =  0.8217751865311137\n",
            "\n",
            " current epochs =  4 , current training accuracy =  97.6 %\n",
            "current epochs =  4 , current validation accuracy =  96.39999999999999 %\n",
            "\n",
            "epochs =  5 , step =  0 , loss value =  0.762175095842626\n",
            "epochs =  5 , step =  1000 , loss value =  0.9116500083305658\n",
            "epochs =  5 , step =  2000 , loss value =  0.7584884758035783\n",
            "epochs =  5 , step =  3000 , loss value =  0.8817163729923537\n",
            "epochs =  5 , step =  4000 , loss value =  0.8474058986849256\n",
            "epochs =  5 , step =  5000 , loss value =  0.746782073037934\n",
            "epochs =  5 , step =  6000 , loss value =  0.8644607131014861\n",
            "epochs =  5 , step =  7000 , loss value =  1.0865076228765016\n",
            "epochs =  5 , step =  8000 , loss value =  0.9458308575967183\n",
            "epochs =  5 , step =  9000 , loss value =  1.025670891240584\n",
            "epochs =  5 , step =  10000 , loss value =  0.9899298745792919\n",
            "epochs =  5 , step =  11000 , loss value =  0.8044079339633925\n",
            "epochs =  5 , step =  12000 , loss value =  0.7027709077531828\n",
            "epochs =  5 , step =  13000 , loss value =  0.7583315327197728\n",
            "epochs =  5 , step =  14000 , loss value =  0.8739440467243523\n",
            "epochs =  5 , step =  15000 , loss value =  0.896311855372381\n",
            "epochs =  5 , step =  16000 , loss value =  0.8263413903498019\n",
            "epochs =  5 , step =  17000 , loss value =  0.897567563098315\n",
            "epochs =  5 , step =  18000 , loss value =  1.0258828300675917\n",
            "epochs =  5 , step =  19000 , loss value =  0.7637271291265044\n",
            "epochs =  5 , step =  20000 , loss value =  0.7451164482248945\n",
            "epochs =  5 , step =  21000 , loss value =  0.8086914697861448\n",
            "epochs =  5 , step =  22000 , loss value =  0.8205743936685349\n",
            "epochs =  5 , step =  23000 , loss value =  0.9751713611479897\n",
            "epochs =  5 , step =  24000 , loss value =  0.7747762902366735\n",
            "epochs =  5 , step =  25000 , loss value =  0.8768870528388724\n",
            "epochs =  5 , step =  26000 , loss value =  0.7996316931628407\n",
            "epochs =  5 , step =  27000 , loss value =  0.8672529751336145\n",
            "epochs =  5 , step =  28000 , loss value =  0.8283153780578193\n",
            "epochs =  5 , step =  29000 , loss value =  0.8231076014627456\n",
            "epochs =  5 , step =  30000 , loss value =  0.7426076586561935\n",
            "epochs =  5 , step =  31000 , loss value =  0.7326989288084158\n",
            "epochs =  5 , step =  32000 , loss value =  0.8956861017490813\n",
            "epochs =  5 , step =  33000 , loss value =  0.8626011653995296\n",
            "epochs =  5 , step =  34000 , loss value =  0.8244212928666463\n",
            "epochs =  5 , step =  35000 , loss value =  0.7773604666817195\n",
            "epochs =  5 , step =  36000 , loss value =  0.8168264817823865\n",
            "epochs =  5 , step =  37000 , loss value =  0.7669122743027896\n",
            "epochs =  5 , step =  38000 , loss value =  0.8477692714681191\n",
            "epochs =  5 , step =  39000 , loss value =  0.7649659821030138\n",
            "epochs =  5 , step =  40000 , loss value =  0.8583184141325121\n",
            "epochs =  5 , step =  41000 , loss value =  0.7948549775892049\n",
            "epochs =  5 , step =  42000 , loss value =  0.9798827368533399\n",
            "epochs =  5 , step =  43000 , loss value =  0.9057919612607923\n",
            "epochs =  5 , step =  44000 , loss value =  0.7806610960254173\n",
            "epochs =  5 , step =  45000 , loss value =  0.8316568153527367\n",
            "epochs =  5 , step =  46000 , loss value =  0.8673156192073874\n",
            "epochs =  5 , step =  47000 , loss value =  0.8483039335371176\n",
            "\n",
            " current epochs =  5 , current training accuracy =  97.89999999999999 %\n",
            "current epochs =  5 , current validation accuracy =  96.7 %\n",
            "\n",
            "epochs =  6 , step =  0 , loss value =  0.7783881893610624\n",
            "epochs =  6 , step =  1000 , loss value =  0.9343166650940264\n",
            "epochs =  6 , step =  2000 , loss value =  0.7730023156487315\n",
            "epochs =  6 , step =  3000 , loss value =  0.9070915279932451\n",
            "epochs =  6 , step =  4000 , loss value =  0.844420054106056\n",
            "epochs =  6 , step =  5000 , loss value =  0.7653164321488456\n",
            "epochs =  6 , step =  6000 , loss value =  0.870727621307306\n",
            "epochs =  6 , step =  7000 , loss value =  1.0631197771279057\n",
            "epochs =  6 , step =  8000 , loss value =  0.9502143928036262\n",
            "epochs =  6 , step =  9000 , loss value =  1.0402241676226311\n",
            "epochs =  6 , step =  10000 , loss value =  1.022711468874561\n",
            "epochs =  6 , step =  11000 , loss value =  0.813477954129106\n",
            "epochs =  6 , step =  12000 , loss value =  0.7099961526162722\n",
            "epochs =  6 , step =  13000 , loss value =  0.7666992997423132\n",
            "epochs =  6 , step =  14000 , loss value =  0.8935701019017243\n",
            "epochs =  6 , step =  15000 , loss value =  0.8956047054867717\n",
            "epochs =  6 , step =  16000 , loss value =  0.8487771713030705\n",
            "epochs =  6 , step =  17000 , loss value =  0.8879614491842938\n",
            "epochs =  6 , step =  18000 , loss value =  1.0125493373023255\n",
            "epochs =  6 , step =  19000 , loss value =  0.782598293530218\n",
            "epochs =  6 , step =  20000 , loss value =  0.7547123624544283\n",
            "epochs =  6 , step =  21000 , loss value =  0.8105566516286141\n",
            "epochs =  6 , step =  22000 , loss value =  0.8103937867656607\n",
            "epochs =  6 , step =  23000 , loss value =  0.9840594411297288\n",
            "epochs =  6 , step =  24000 , loss value =  0.787942184937205\n",
            "epochs =  6 , step =  25000 , loss value =  0.8979468300658735\n",
            "epochs =  6 , step =  26000 , loss value =  0.8086536428239451\n",
            "epochs =  6 , step =  27000 , loss value =  0.892556989839328\n",
            "epochs =  6 , step =  28000 , loss value =  0.8124700684038759\n",
            "epochs =  6 , step =  29000 , loss value =  0.8450744983274785\n",
            "epochs =  6 , step =  30000 , loss value =  0.7522510275300669\n",
            "epochs =  6 , step =  31000 , loss value =  0.7374915266573138\n",
            "epochs =  6 , step =  32000 , loss value =  0.9275766245591341\n",
            "epochs =  6 , step =  33000 , loss value =  0.8849336358217426\n",
            "epochs =  6 , step =  34000 , loss value =  0.820402197390899\n",
            "epochs =  6 , step =  35000 , loss value =  0.7886513150489693\n",
            "epochs =  6 , step =  36000 , loss value =  0.8285073259469762\n",
            "epochs =  6 , step =  37000 , loss value =  0.771691889917424\n",
            "epochs =  6 , step =  38000 , loss value =  0.8566739084068873\n",
            "epochs =  6 , step =  39000 , loss value =  0.7801346017889396\n",
            "epochs =  6 , step =  40000 , loss value =  0.8813025549730242\n",
            "epochs =  6 , step =  41000 , loss value =  0.8117738051493327\n",
            "epochs =  6 , step =  42000 , loss value =  0.9920530182411028\n",
            "epochs =  6 , step =  43000 , loss value =  0.9131113453703732\n",
            "epochs =  6 , step =  44000 , loss value =  0.7879818190617958\n",
            "epochs =  6 , step =  45000 , loss value =  0.8412025531695982\n",
            "epochs =  6 , step =  46000 , loss value =  0.8932567585857861\n",
            "epochs =  6 , step =  47000 , loss value =  0.8774405707143625\n",
            "\n",
            " current epochs =  6 , current training accuracy =  98.2 %\n",
            "current epochs =  6 , current validation accuracy =  96.8 %\n",
            "\n",
            "epochs =  7 , step =  0 , loss value =  0.7929310929765353\n",
            "epochs =  7 , step =  1000 , loss value =  0.957070619107701\n",
            "epochs =  7 , step =  2000 , loss value =  0.7899966133217536\n",
            "epochs =  7 , step =  3000 , loss value =  0.932030393758533\n",
            "epochs =  7 , step =  4000 , loss value =  0.8457146404120259\n",
            "epochs =  7 , step =  5000 , loss value =  0.7826806187700814\n",
            "epochs =  7 , step =  6000 , loss value =  0.8851787834962991\n",
            "epochs =  7 , step =  7000 , loss value =  1.0521734172243469\n",
            "epochs =  7 , step =  8000 , loss value =  0.9534527130883709\n",
            "epochs =  7 , step =  9000 , loss value =  1.049407690723827\n",
            "epochs =  7 , step =  10000 , loss value =  1.0530333752178231\n",
            "epochs =  7 , step =  11000 , loss value =  0.8228916353850151\n",
            "epochs =  7 , step =  12000 , loss value =  0.7166217473478761\n",
            "epochs =  7 , step =  13000 , loss value =  0.7728807412921401\n",
            "epochs =  7 , step =  14000 , loss value =  0.9112049291740216\n",
            "epochs =  7 , step =  15000 , loss value =  0.901226284818263\n",
            "epochs =  7 , step =  16000 , loss value =  0.8697139442291233\n",
            "epochs =  7 , step =  17000 , loss value =  0.8846253512121384\n",
            "epochs =  7 , step =  18000 , loss value =  1.002612543519199\n",
            "epochs =  7 , step =  19000 , loss value =  0.8005877035995445\n",
            "epochs =  7 , step =  20000 , loss value =  0.7663286108687096\n",
            "epochs =  7 , step =  21000 , loss value =  0.8129058623545646\n",
            "epochs =  7 , step =  22000 , loss value =  0.8119325341004759\n",
            "epochs =  7 , step =  23000 , loss value =  0.9884620193890777\n",
            "epochs =  7 , step =  24000 , loss value =  0.7998180457959808\n",
            "epochs =  7 , step =  25000 , loss value =  0.9155538148174919\n",
            "epochs =  7 , step =  26000 , loss value =  0.8192658565479664\n",
            "epochs =  7 , step =  27000 , loss value =  0.9138953259365238\n",
            "epochs =  7 , step =  28000 , loss value =  0.8101315993482572\n",
            "epochs =  7 , step =  29000 , loss value =  0.8683020164665273\n",
            "epochs =  7 , step =  30000 , loss value =  0.7629532257394922\n",
            "epochs =  7 , step =  31000 , loss value =  0.74269727014062\n",
            "epochs =  7 , step =  32000 , loss value =  0.9548416085231094\n",
            "epochs =  7 , step =  33000 , loss value =  0.907040350726677\n",
            "epochs =  7 , step =  34000 , loss value =  0.8204782317394681\n",
            "epochs =  7 , step =  35000 , loss value =  0.8043680913151133\n",
            "epochs =  7 , step =  36000 , loss value =  0.8400563835563666\n",
            "epochs =  7 , step =  37000 , loss value =  0.7782726106826616\n",
            "epochs =  7 , step =  38000 , loss value =  0.8684015113737267\n",
            "epochs =  7 , step =  39000 , loss value =  0.7971125423656422\n",
            "epochs =  7 , step =  40000 , loss value =  0.8991868150059956\n",
            "epochs =  7 , step =  41000 , loss value =  0.8299354993930627\n",
            "epochs =  7 , step =  42000 , loss value =  0.9986067813429099\n",
            "epochs =  7 , step =  43000 , loss value =  0.9209844307730088\n",
            "epochs =  7 , step =  44000 , loss value =  0.7972339865125678\n",
            "epochs =  7 , step =  45000 , loss value =  0.8479668305301067\n",
            "epochs =  7 , step =  46000 , loss value =  0.9180537397938957\n",
            "epochs =  7 , step =  47000 , loss value =  0.9112964729577857\n",
            "\n",
            " current epochs =  7 , current training accuracy =  98.3 %\n",
            "current epochs =  7 , current validation accuracy =  97.0 %\n",
            "\n",
            "epochs =  8 , step =  0 , loss value =  0.8017682900055356\n",
            "epochs =  8 , step =  1000 , loss value =  0.9779865771052747\n",
            "epochs =  8 , step =  2000 , loss value =  0.8079980979260941\n",
            "epochs =  8 , step =  3000 , loss value =  0.9537851305941479\n",
            "epochs =  8 , step =  4000 , loss value =  0.8512097984673453\n",
            "epochs =  8 , step =  5000 , loss value =  0.7967409970522737\n",
            "epochs =  8 , step =  6000 , loss value =  0.9063564188646006\n",
            "epochs =  8 , step =  7000 , loss value =  1.0460612980394424\n",
            "epochs =  8 , step =  8000 , loss value =  0.9577847963385824\n",
            "epochs =  8 , step =  9000 , loss value =  1.0533549152334865\n",
            "epochs =  8 , step =  10000 , loss value =  1.0782715186509944\n",
            "epochs =  8 , step =  11000 , loss value =  0.8336891862978004\n",
            "epochs =  8 , step =  12000 , loss value =  0.7233638064404125\n",
            "epochs =  8 , step =  13000 , loss value =  0.7810023520883965\n",
            "epochs =  8 , step =  14000 , loss value =  0.9282598966914732\n",
            "epochs =  8 , step =  15000 , loss value =  0.9126155541000258\n",
            "epochs =  8 , step =  16000 , loss value =  0.8890002243363637\n",
            "epochs =  8 , step =  17000 , loss value =  0.8875454138443916\n",
            "epochs =  8 , step =  18000 , loss value =  0.995621633272983\n",
            "epochs =  8 , step =  19000 , loss value =  0.8174121440087746\n",
            "epochs =  8 , step =  20000 , loss value =  0.7774583557878437\n",
            "epochs =  8 , step =  21000 , loss value =  0.8274963270222098\n",
            "epochs =  8 , step =  22000 , loss value =  0.8179171018934996\n",
            "epochs =  8 , step =  23000 , loss value =  0.9924652768889044\n",
            "epochs =  8 , step =  24000 , loss value =  0.8099549347527343\n",
            "epochs =  8 , step =  25000 , loss value =  0.9297871686522154\n",
            "epochs =  8 , step =  26000 , loss value =  0.8320444712155521\n",
            "epochs =  8 , step =  27000 , loss value =  0.9307816952291795\n",
            "epochs =  8 , step =  28000 , loss value =  0.8103719524466823\n",
            "epochs =  8 , step =  29000 , loss value =  0.8885472613378471\n",
            "epochs =  8 , step =  30000 , loss value =  0.7725789054711497\n",
            "epochs =  8 , step =  31000 , loss value =  0.747112311976881\n",
            "epochs =  8 , step =  32000 , loss value =  0.9771010707314194\n",
            "epochs =  8 , step =  33000 , loss value =  0.9313814053586967\n",
            "epochs =  8 , step =  34000 , loss value =  0.8248049547259442\n",
            "epochs =  8 , step =  35000 , loss value =  0.8194200205629667\n",
            "epochs =  8 , step =  36000 , loss value =  0.8534794241782636\n",
            "epochs =  8 , step =  37000 , loss value =  0.7846362720413267\n",
            "epochs =  8 , step =  38000 , loss value =  0.8811565208854333\n",
            "epochs =  8 , step =  39000 , loss value =  0.8155061449893807\n",
            "epochs =  8 , step =  40000 , loss value =  0.9164276601608603\n",
            "epochs =  8 , step =  41000 , loss value =  0.8483852653571254\n",
            "epochs =  8 , step =  42000 , loss value =  1.0035921920271187\n",
            "epochs =  8 , step =  43000 , loss value =  0.9280294333945086\n",
            "epochs =  8 , step =  44000 , loss value =  0.806769590023039\n",
            "epochs =  8 , step =  45000 , loss value =  0.8530301053310178\n",
            "epochs =  8 , step =  46000 , loss value =  0.9404520772145233\n",
            "epochs =  8 , step =  47000 , loss value =  0.9486459150854551\n",
            "\n",
            " current epochs =  8 , current training accuracy =  98.5 %\n",
            "current epochs =  8 , current validation accuracy =  97.1 %\n",
            "\n",
            "epochs =  9 , step =  0 , loss value =  0.8059508430384856\n",
            "epochs =  9 , step =  1000 , loss value =  0.9961160326488772\n",
            "epochs =  9 , step =  2000 , loss value =  0.8249925594753644\n",
            "epochs =  9 , step =  3000 , loss value =  0.9728365640831711\n",
            "epochs =  9 , step =  4000 , loss value =  0.8591142988093571\n",
            "epochs =  9 , step =  5000 , loss value =  0.807709296610563\n",
            "epochs =  9 , step =  6000 , loss value =  0.9267453632715823\n",
            "epochs =  9 , step =  7000 , loss value =  1.0403400727024845\n",
            "epochs =  9 , step =  8000 , loss value =  0.9631970682157706\n",
            "epochs =  9 , step =  9000 , loss value =  1.0553972731350727\n",
            "epochs =  9 , step =  10000 , loss value =  1.0939741076135652\n",
            "epochs =  9 , step =  11000 , loss value =  0.8452150149890881\n",
            "epochs =  9 , step =  12000 , loss value =  0.7308820680791581\n",
            "epochs =  9 , step =  13000 , loss value =  0.7914076331958309\n",
            "epochs =  9 , step =  14000 , loss value =  0.9453655668219567\n",
            "epochs =  9 , step =  15000 , loss value =  0.9231440313243432\n",
            "epochs =  9 , step =  16000 , loss value =  0.9070207483812579\n",
            "epochs =  9 , step =  17000 , loss value =  0.8944853664807405\n",
            "epochs =  9 , step =  18000 , loss value =  0.9943431705920039\n",
            "epochs =  9 , step =  19000 , loss value =  0.833379716935283\n",
            "epochs =  9 , step =  20000 , loss value =  0.7887360121999444\n",
            "epochs =  9 , step =  21000 , loss value =  0.8526257329650784\n",
            "epochs =  9 , step =  22000 , loss value =  0.8264394960504116\n",
            "epochs =  9 , step =  23000 , loss value =  0.9934665409517771\n",
            "epochs =  9 , step =  24000 , loss value =  0.8188687795136971\n",
            "epochs =  9 , step =  25000 , loss value =  0.9432894421187147\n",
            "epochs =  9 , step =  26000 , loss value =  0.848043994974727\n",
            "epochs =  9 , step =  27000 , loss value =  0.9454947524956516\n",
            "epochs =  9 , step =  28000 , loss value =  0.8126314138983247\n",
            "epochs =  9 , step =  29000 , loss value =  0.9049219925085625\n",
            "epochs =  9 , step =  30000 , loss value =  0.7805006095323739\n",
            "epochs =  9 , step =  31000 , loss value =  0.7517866334791166\n",
            "epochs =  9 , step =  32000 , loss value =  0.9948941431321803\n",
            "epochs =  9 , step =  33000 , loss value =  0.9552375913311775\n",
            "epochs =  9 , step =  34000 , loss value =  0.8312142606844805\n",
            "epochs =  9 , step =  35000 , loss value =  0.8322477332656344\n",
            "epochs =  9 , step =  36000 , loss value =  0.8676700566861119\n",
            "epochs =  9 , step =  37000 , loss value =  0.793381753736161\n",
            "epochs =  9 , step =  38000 , loss value =  0.892899401086868\n",
            "epochs =  9 , step =  39000 , loss value =  0.8336451767894443\n",
            "epochs =  9 , step =  40000 , loss value =  0.9332093155115924\n",
            "epochs =  9 , step =  41000 , loss value =  0.8664355994916152\n",
            "epochs =  9 , step =  42000 , loss value =  1.0066494869170308\n",
            "epochs =  9 , step =  43000 , loss value =  0.9313795062491814\n",
            "epochs =  9 , step =  44000 , loss value =  0.8147464960868998\n",
            "epochs =  9 , step =  45000 , loss value =  0.8587206813526675\n",
            "epochs =  9 , step =  46000 , loss value =  0.9599212130542666\n",
            "epochs =  9 , step =  47000 , loss value =  0.9839332466328152\n",
            "\n",
            " current epochs =  9 , current training accuracy =  98.6 %\n",
            "current epochs =  9 , current validation accuracy =  97.1 %\n",
            "\n",
            "epochs =  10 , step =  0 , loss value =  0.8082931444581966\n",
            "epochs =  10 , step =  1000 , loss value =  1.0119510922494508\n",
            "epochs =  10 , step =  2000 , loss value =  0.8422669326938577\n",
            "epochs =  10 , step =  3000 , loss value =  0.9889955166919605\n",
            "epochs =  10 , step =  4000 , loss value =  0.866876771068585\n",
            "epochs =  10 , step =  5000 , loss value =  0.8174525833089347\n",
            "epochs =  10 , step =  6000 , loss value =  0.9432253045412271\n",
            "epochs =  10 , step =  7000 , loss value =  1.0359541515558772\n",
            "epochs =  10 , step =  8000 , loss value =  0.9705621741525239\n",
            "epochs =  10 , step =  9000 , loss value =  1.0575856481035248\n",
            "epochs =  10 , step =  10000 , loss value =  1.1029501908736397\n",
            "epochs =  10 , step =  11000 , loss value =  0.8558690962773176\n",
            "epochs =  10 , step =  12000 , loss value =  0.7407202072496945\n",
            "epochs =  10 , step =  13000 , loss value =  0.8041923485561344\n",
            "epochs =  10 , step =  14000 , loss value =  0.9611084104751644\n",
            "epochs =  10 , step =  15000 , loss value =  0.9265726853071133\n",
            "epochs =  10 , step =  16000 , loss value =  0.923235367712455\n",
            "epochs =  10 , step =  17000 , loss value =  0.9043314826817076\n",
            "epochs =  10 , step =  18000 , loss value =  1.000769225194717\n",
            "epochs =  10 , step =  19000 , loss value =  0.8490193250650626\n",
            "epochs =  10 , step =  20000 , loss value =  0.7997785271305923\n",
            "epochs =  10 , step =  21000 , loss value =  0.8843626688275761\n",
            "epochs =  10 , step =  22000 , loss value =  0.8384196367684693\n",
            "epochs =  10 , step =  23000 , loss value =  0.985623354500863\n",
            "epochs =  10 , step =  24000 , loss value =  0.827298272114116\n",
            "epochs =  10 , step =  25000 , loss value =  0.9561174947733648\n",
            "epochs =  10 , step =  26000 , loss value =  0.8673828961205292\n",
            "epochs =  10 , step =  27000 , loss value =  0.9585738370040735\n",
            "epochs =  10 , step =  28000 , loss value =  0.8173557958317578\n",
            "epochs =  10 , step =  29000 , loss value =  0.9179011312786256\n",
            "epochs =  10 , step =  30000 , loss value =  0.7884557121465874\n",
            "epochs =  10 , step =  31000 , loss value =  0.757834657573547\n",
            "epochs =  10 , step =  32000 , loss value =  1.0082806801369286\n",
            "epochs =  10 , step =  33000 , loss value =  0.9756937803314376\n",
            "epochs =  10 , step =  34000 , loss value =  0.8361451807523892\n",
            "epochs =  10 , step =  35000 , loss value =  0.8418057940360195\n",
            "epochs =  10 , step =  36000 , loss value =  0.8795204655192004\n",
            "epochs =  10 , step =  37000 , loss value =  0.8039318886562554\n",
            "epochs =  10 , step =  38000 , loss value =  0.9030793707126406\n",
            "epochs =  10 , step =  39000 , loss value =  0.8508501177391112\n",
            "epochs =  10 , step =  40000 , loss value =  0.9538894427009348\n",
            "epochs =  10 , step =  41000 , loss value =  0.8824378194723114\n",
            "epochs =  10 , step =  42000 , loss value =  1.00594974533994\n",
            "epochs =  10 , step =  43000 , loss value =  0.9300056033339223\n",
            "epochs =  10 , step =  44000 , loss value =  0.8219789450063872\n",
            "epochs =  10 , step =  45000 , loss value =  0.866106962442694\n",
            "epochs =  10 , step =  46000 , loss value =  0.9765122633248409\n",
            "epochs =  10 , step =  47000 , loss value =  1.010947310458377\n",
            "\n",
            " current epochs =  10 , current training accuracy =  98.7 %\n",
            "current epochs =  10 , current validation accuracy =  97.2 %\n",
            "\n",
            "epochs =  11 , step =  0 , loss value =  0.8131083046353939\n",
            "epochs =  11 , step =  1000 , loss value =  1.024143692057145\n",
            "epochs =  11 , step =  2000 , loss value =  0.858932252726327\n",
            "epochs =  11 , step =  3000 , loss value =  1.0028427752384315\n",
            "epochs =  11 , step =  4000 , loss value =  0.87307103975557\n",
            "epochs =  11 , step =  5000 , loss value =  0.8267299842670676\n",
            "epochs =  11 , step =  6000 , loss value =  0.9549092583326602\n",
            "epochs =  11 , step =  7000 , loss value =  1.0381187692848264\n",
            "epochs =  11 , step =  8000 , loss value =  0.9809379615218036\n",
            "epochs =  11 , step =  9000 , loss value =  1.061413086024708\n",
            "epochs =  11 , step =  10000 , loss value =  1.1100091106844014\n",
            "epochs =  11 , step =  11000 , loss value =  0.8647831712725313\n",
            "epochs =  11 , step =  12000 , loss value =  0.7513156018985068\n",
            "epochs =  11 , step =  13000 , loss value =  0.8190502556421458\n",
            "epochs =  11 , step =  14000 , loss value =  0.9743651078066269\n",
            "epochs =  11 , step =  15000 , loss value =  0.9269364627781728\n",
            "epochs =  11 , step =  16000 , loss value =  0.9370001649255059\n",
            "epochs =  11 , step =  17000 , loss value =  0.9154141303599411\n",
            "epochs =  11 , step =  18000 , loss value =  1.0107488958106843\n",
            "epochs =  11 , step =  19000 , loss value =  0.8634418610939131\n",
            "epochs =  11 , step =  20000 , loss value =  0.8104106019561129\n",
            "epochs =  11 , step =  21000 , loss value =  0.9100198538975928\n",
            "epochs =  11 , step =  22000 , loss value =  0.852832642932444\n",
            "epochs =  11 , step =  23000 , loss value =  0.9701832214720896\n",
            "epochs =  11 , step =  24000 , loss value =  0.8356599984394039\n",
            "epochs =  11 , step =  25000 , loss value =  0.967659936541206\n",
            "epochs =  11 , step =  26000 , loss value =  0.8873580623413356\n",
            "epochs =  11 , step =  27000 , loss value =  0.96843069947739\n",
            "epochs =  11 , step =  28000 , loss value =  0.822853094622277\n",
            "epochs =  11 , step =  29000 , loss value =  0.9297259514959455\n",
            "epochs =  11 , step =  30000 , loss value =  0.7973898810987912\n",
            "epochs =  11 , step =  31000 , loss value =  0.7650639647421974\n",
            "epochs =  11 , step =  32000 , loss value =  1.0172373725162513\n",
            "epochs =  11 , step =  33000 , loss value =  0.9925151396194939\n",
            "epochs =  11 , step =  34000 , loss value =  0.8404510826310232\n",
            "epochs =  11 , step =  35000 , loss value =  0.8478689231568705\n",
            "epochs =  11 , step =  36000 , loss value =  0.8875804693463727\n",
            "epochs =  11 , step =  37000 , loss value =  0.8170278666121475\n",
            "epochs =  11 , step =  38000 , loss value =  0.91217036926027\n",
            "epochs =  11 , step =  39000 , loss value =  0.8667726138759662\n",
            "epochs =  11 , step =  40000 , loss value =  0.9830834655866942\n",
            "epochs =  11 , step =  41000 , loss value =  0.89731630616558\n",
            "epochs =  11 , step =  42000 , loss value =  1.0064796577287602\n",
            "epochs =  11 , step =  43000 , loss value =  0.928722092365608\n",
            "epochs =  11 , step =  44000 , loss value =  0.8309007589607151\n",
            "epochs =  11 , step =  45000 , loss value =  0.8736485433593405\n",
            "epochs =  11 , step =  46000 , loss value =  0.9920587324856943\n",
            "epochs =  11 , step =  47000 , loss value =  1.0293574320135535\n",
            "\n",
            " current epochs =  11 , current training accuracy =  98.8 %\n",
            "current epochs =  11 , current validation accuracy =  97.3 %\n",
            "\n",
            "epochs =  12 , step =  0 , loss value =  0.8208575740154684\n",
            "epochs =  12 , step =  1000 , loss value =  1.0341690634793128\n",
            "epochs =  12 , step =  2000 , loss value =  0.8741236595543793\n",
            "epochs =  12 , step =  3000 , loss value =  1.015566795431119\n",
            "epochs =  12 , step =  4000 , loss value =  0.8788087581240033\n",
            "epochs =  12 , step =  5000 , loss value =  0.8359683680193393\n",
            "epochs =  12 , step =  6000 , loss value =  0.9618785787561868\n",
            "epochs =  12 , step =  7000 , loss value =  1.0462776853988531\n",
            "epochs =  12 , step =  8000 , loss value =  0.9941362571050074\n",
            "epochs =  12 , step =  9000 , loss value =  1.0678815179877024\n",
            "epochs =  12 , step =  10000 , loss value =  1.1173842042601185\n",
            "epochs =  12 , step =  11000 , loss value =  0.8725761489998853\n",
            "epochs =  12 , step =  12000 , loss value =  0.7612429001351311\n",
            "epochs =  12 , step =  13000 , loss value =  0.83374308946901\n",
            "epochs =  12 , step =  14000 , loss value =  0.9856529061562691\n",
            "epochs =  12 , step =  15000 , loss value =  0.9296515739640607\n",
            "epochs =  12 , step =  16000 , loss value =  0.9488884302948729\n",
            "epochs =  12 , step =  17000 , loss value =  0.9269401172570015\n",
            "epochs =  12 , step =  18000 , loss value =  1.0191394977390966\n",
            "epochs =  12 , step =  19000 , loss value =  0.8758940268879077\n",
            "epochs =  12 , step =  20000 , loss value =  0.8207212705246404\n",
            "epochs =  12 , step =  21000 , loss value =  0.9217668079260908\n",
            "epochs =  12 , step =  22000 , loss value =  0.8680058629516909\n",
            "epochs =  12 , step =  23000 , loss value =  0.9547855920887529\n",
            "epochs =  12 , step =  24000 , loss value =  0.8443921539786909\n",
            "epochs =  12 , step =  25000 , loss value =  0.9781154389547114\n",
            "epochs =  12 , step =  26000 , loss value =  0.9066777137649275\n",
            "epochs =  12 , step =  27000 , loss value =  0.9751360312638557\n",
            "epochs =  12 , step =  28000 , loss value =  0.8288857011217922\n",
            "epochs =  12 , step =  29000 , loss value =  0.9415741038999388\n",
            "epochs =  12 , step =  30000 , loss value =  0.8073297520281006\n",
            "epochs =  12 , step =  31000 , loss value =  0.7730217960932817\n",
            "epochs =  12 , step =  32000 , loss value =  1.0236101144690648\n",
            "epochs =  12 , step =  33000 , loss value =  1.0068298930490651\n",
            "epochs =  12 , step =  34000 , loss value =  0.8451141706996451\n",
            "epochs =  12 , step =  35000 , loss value =  0.852746100504744\n",
            "epochs =  12 , step =  36000 , loss value =  0.8925809756131919\n",
            "epochs =  12 , step =  37000 , loss value =  0.8322100428222351\n",
            "epochs =  12 , step =  38000 , loss value =  0.9207151388724383\n",
            "epochs =  12 , step =  39000 , loss value =  0.8822201021797529\n",
            "epochs =  12 , step =  40000 , loss value =  1.0153995536008638\n",
            "epochs =  12 , step =  41000 , loss value =  0.9118477226614177\n",
            "epochs =  12 , step =  42000 , loss value =  1.0112755610778374\n",
            "epochs =  12 , step =  43000 , loss value =  0.9307610576459074\n",
            "epochs =  12 , step =  44000 , loss value =  0.8414215892200512\n",
            "epochs =  12 , step =  45000 , loss value =  0.8800503364165407\n",
            "epochs =  12 , step =  46000 , loss value =  1.0078516273856684\n",
            "epochs =  12 , step =  47000 , loss value =  1.0403549953331308\n",
            "\n",
            " current epochs =  12 , current training accuracy =  98.8 %\n",
            "current epochs =  12 , current validation accuracy =  97.39999999999999 %\n",
            "\n",
            "epochs =  13 , step =  0 , loss value =  0.8301455405488349\n",
            "epochs =  13 , step =  1000 , loss value =  1.0439678941094193\n",
            "epochs =  13 , step =  2000 , loss value =  0.8890810151265569\n",
            "epochs =  13 , step =  3000 , loss value =  1.0267886974639941\n",
            "epochs =  13 , step =  4000 , loss value =  0.8853554231835998\n",
            "epochs =  13 , step =  5000 , loss value =  0.845327920383737\n",
            "epochs =  13 , step =  6000 , loss value =  0.9671787868214109\n",
            "epochs =  13 , step =  7000 , loss value =  1.0521518445602707\n",
            "epochs =  13 , step =  8000 , loss value =  1.0079542934465573\n",
            "epochs =  13 , step =  9000 , loss value =  1.0762744917493856\n",
            "epochs =  13 , step =  10000 , loss value =  1.1248053896196144\n",
            "epochs =  13 , step =  11000 , loss value =  0.8807797686139438\n",
            "epochs =  13 , step =  12000 , loss value =  0.7693804303547064\n",
            "epochs =  13 , step =  13000 , loss value =  0.8468219706376332\n",
            "epochs =  13 , step =  14000 , loss value =  0.9966504469844973\n",
            "epochs =  13 , step =  15000 , loss value =  0.9305183467439836\n",
            "epochs =  13 , step =  16000 , loss value =  0.9596161115095705\n",
            "epochs =  13 , step =  17000 , loss value =  0.9385223018066791\n",
            "epochs =  13 , step =  18000 , loss value =  1.0211019571750461\n",
            "epochs =  13 , step =  19000 , loss value =  0.88710857142618\n",
            "epochs =  13 , step =  20000 , loss value =  0.8309983112393875\n",
            "epochs =  13 , step =  21000 , loss value =  0.93789772994384\n",
            "epochs =  13 , step =  22000 , loss value =  0.8829539379880729\n",
            "epochs =  13 , step =  23000 , loss value =  0.943001499715459\n",
            "epochs =  13 , step =  24000 , loss value =  0.8532463548970358\n",
            "epochs =  13 , step =  25000 , loss value =  0.9886418593746998\n",
            "epochs =  13 , step =  26000 , loss value =  0.9246984359748824\n",
            "epochs =  13 , step =  27000 , loss value =  0.9824389991571421\n",
            "epochs =  13 , step =  28000 , loss value =  0.8352479232705528\n",
            "epochs =  13 , step =  29000 , loss value =  0.951995784318731\n",
            "epochs =  13 , step =  30000 , loss value =  0.8176280155289084\n",
            "epochs =  13 , step =  31000 , loss value =  0.7817246549048934\n",
            "epochs =  13 , step =  32000 , loss value =  1.0286314174290454\n",
            "epochs =  13 , step =  33000 , loss value =  1.0194217571732997\n",
            "epochs =  13 , step =  34000 , loss value =  0.8505543023603117\n",
            "epochs =  13 , step =  35000 , loss value =  0.8580924341248484\n",
            "epochs =  13 , step =  36000 , loss value =  0.8964405604052202\n",
            "epochs =  13 , step =  37000 , loss value =  0.8475989082351847\n",
            "epochs =  13 , step =  38000 , loss value =  0.9293034366697078\n",
            "epochs =  13 , step =  39000 , loss value =  0.8980588640103936\n",
            "epochs =  13 , step =  40000 , loss value =  1.041307120778631\n",
            "epochs =  13 , step =  41000 , loss value =  0.9258381218367996\n",
            "epochs =  13 , step =  42000 , loss value =  1.017836767089254\n",
            "epochs =  13 , step =  43000 , loss value =  0.9340215641998542\n",
            "epochs =  13 , step =  44000 , loss value =  0.8502591836902262\n",
            "epochs =  13 , step =  45000 , loss value =  0.8863796321428357\n",
            "epochs =  13 , step =  46000 , loss value =  1.024234999897755\n",
            "epochs =  13 , step =  47000 , loss value =  1.0467183745878959\n",
            "\n",
            " current epochs =  13 , current training accuracy =  98.9 %\n",
            "current epochs =  13 , current validation accuracy =  97.39999999999999 %\n",
            "\n",
            "epochs =  14 , step =  0 , loss value =  0.8393223680945073\n",
            "epochs =  14 , step =  1000 , loss value =  1.0541081855371937\n",
            "epochs =  14 , step =  2000 , loss value =  0.9053644279787268\n",
            "epochs =  14 , step =  3000 , loss value =  1.0368271208251307\n",
            "epochs =  14 , step =  4000 , loss value =  0.8925282824416131\n",
            "epochs =  14 , step =  5000 , loss value =  0.8549528213537273\n",
            "epochs =  14 , step =  6000 , loss value =  0.9722969701588935\n",
            "epochs =  14 , step =  7000 , loss value =  1.056094738839603\n",
            "epochs =  14 , step =  8000 , loss value =  1.0206853314647786\n",
            "epochs =  14 , step =  9000 , loss value =  1.08484371668409\n",
            "epochs =  14 , step =  10000 , loss value =  1.1314996674932114\n",
            "epochs =  14 , step =  11000 , loss value =  0.8896914763547676\n",
            "epochs =  14 , step =  12000 , loss value =  0.7750943387444776\n",
            "epochs =  14 , step =  13000 , loss value =  0.8581931028256942\n",
            "epochs =  14 , step =  14000 , loss value =  1.0083686963795881\n",
            "epochs =  14 , step =  15000 , loss value =  0.9254905771110813\n",
            "epochs =  14 , step =  16000 , loss value =  0.9694163497111266\n",
            "epochs =  14 , step =  17000 , loss value =  0.9497058416731639\n",
            "epochs =  14 , step =  18000 , loss value =  1.017418235481681\n",
            "epochs =  14 , step =  19000 , loss value =  0.8978013991897286\n",
            "epochs =  14 , step =  20000 , loss value =  0.8415556455140574\n",
            "epochs =  14 , step =  21000 , loss value =  0.9558234611691349\n",
            "epochs =  14 , step =  22000 , loss value =  0.8972249579992356\n",
            "epochs =  14 , step =  23000 , loss value =  0.9340132355958288\n",
            "epochs =  14 , step =  24000 , loss value =  0.8613025552699919\n",
            "epochs =  14 , step =  25000 , loss value =  0.9989925531582211\n",
            "epochs =  14 , step =  26000 , loss value =  0.9425900112944473\n",
            "epochs =  14 , step =  27000 , loss value =  0.9961602188308402\n",
            "epochs =  14 , step =  28000 , loss value =  0.8434886865464452\n",
            "epochs =  14 , step =  29000 , loss value =  0.9611078040695754\n",
            "epochs =  14 , step =  30000 , loss value =  0.8270732812224955\n",
            "epochs =  14 , step =  31000 , loss value =  0.7915818382421418\n",
            "epochs =  14 , step =  32000 , loss value =  1.034502569604194\n",
            "epochs =  14 , step =  33000 , loss value =  1.0314894579653886\n",
            "epochs =  14 , step =  34000 , loss value =  0.8551806133183083\n",
            "epochs =  14 , step =  35000 , loss value =  0.8645698124673165\n",
            "epochs =  14 , step =  36000 , loss value =  0.9011987937278679\n",
            "epochs =  14 , step =  37000 , loss value =  0.8625067742985599\n",
            "epochs =  14 , step =  38000 , loss value =  0.9386867902429461\n",
            "epochs =  14 , step =  39000 , loss value =  0.9140053450554544\n",
            "epochs =  14 , step =  40000 , loss value =  1.0589782516020043\n",
            "epochs =  14 , step =  41000 , loss value =  0.9397398091536321\n",
            "epochs =  14 , step =  42000 , loss value =  1.0229445508505908\n",
            "epochs =  14 , step =  43000 , loss value =  0.9374812817904902\n",
            "epochs =  14 , step =  44000 , loss value =  0.857555413881369\n",
            "epochs =  14 , step =  45000 , loss value =  0.8930720392078069\n",
            "epochs =  14 , step =  46000 , loss value =  1.0416323591690166\n",
            "epochs =  14 , step =  47000 , loss value =  1.052035103847325\n",
            "\n",
            " current epochs =  14 , current training accuracy =  99.0 %\n",
            "current epochs =  14 , current validation accuracy =  97.39999999999999 %\n",
            "\n",
            "epochs =  15 , step =  0 , loss value =  0.8476459180118621\n",
            "epochs =  15 , step =  1000 , loss value =  1.0647820014480414\n",
            "epochs =  15 , step =  2000 , loss value =  0.9235636301186879\n",
            "epochs =  15 , step =  3000 , loss value =  1.0470620327775257\n",
            "epochs =  15 , step =  4000 , loss value =  0.9012526505061114\n",
            "epochs =  15 , step =  5000 , loss value =  0.8645080874181312\n",
            "epochs =  15 , step =  6000 , loss value =  0.9783024730653072\n",
            "epochs =  15 , step =  7000 , loss value =  1.0603033568318185\n",
            "epochs =  15 , step =  8000 , loss value =  1.0336675435975473\n",
            "epochs =  15 , step =  9000 , loss value =  1.0929232131632416\n",
            "epochs =  15 , step =  10000 , loss value =  1.1386115404577555\n",
            "epochs =  15 , step =  11000 , loss value =  0.8992456389859355\n",
            "epochs =  15 , step =  12000 , loss value =  0.7794896998443165\n",
            "epochs =  15 , step =  13000 , loss value =  0.8677415567948035\n",
            "epochs =  15 , step =  14000 , loss value =  1.0202689648098646\n",
            "epochs =  15 , step =  15000 , loss value =  0.9177451191772266\n",
            "epochs =  15 , step =  16000 , loss value =  0.9785059302707003\n",
            "epochs =  15 , step =  17000 , loss value =  0.9606827123287979\n",
            "epochs =  15 , step =  18000 , loss value =  1.0141457182298874\n",
            "epochs =  15 , step =  19000 , loss value =  0.9093595457746879\n",
            "epochs =  15 , step =  20000 , loss value =  0.8528699521751406\n",
            "epochs =  15 , step =  21000 , loss value =  0.9690203367048963\n",
            "epochs =  15 , step =  22000 , loss value =  0.9090379955830553\n",
            "epochs =  15 , step =  23000 , loss value =  0.9313533477897337\n",
            "epochs =  15 , step =  24000 , loss value =  0.8679311955424049\n",
            "epochs =  15 , step =  25000 , loss value =  1.0095496104580435\n",
            "epochs =  15 , step =  26000 , loss value =  0.9602811974840303\n",
            "epochs =  15 , step =  27000 , loss value =  1.0118248659233102\n",
            "epochs =  15 , step =  28000 , loss value =  0.8544220956264773\n",
            "epochs =  15 , step =  29000 , loss value =  0.9690623242150813\n",
            "epochs =  15 , step =  30000 , loss value =  0.8350476090712757\n",
            "epochs =  15 , step =  31000 , loss value =  0.8022002700005967\n",
            "epochs =  15 , step =  32000 , loss value =  1.0402515725413326\n",
            "epochs =  15 , step =  33000 , loss value =  1.0431166525514202\n",
            "epochs =  15 , step =  34000 , loss value =  0.8573392952518809\n",
            "epochs =  15 , step =  35000 , loss value =  0.870804168052793\n",
            "epochs =  15 , step =  36000 , loss value =  0.908413400567146\n",
            "epochs =  15 , step =  37000 , loss value =  0.8768191594188104\n",
            "epochs =  15 , step =  38000 , loss value =  0.9485097496132746\n",
            "epochs =  15 , step =  39000 , loss value =  0.929250704966277\n",
            "epochs =  15 , step =  40000 , loss value =  1.0660322087093586\n",
            "epochs =  15 , step =  41000 , loss value =  0.9515673412579976\n",
            "epochs =  15 , step =  42000 , loss value =  1.0262526584412506\n",
            "epochs =  15 , step =  43000 , loss value =  0.9415235094103784\n",
            "epochs =  15 , step =  44000 , loss value =  0.8640906923900852\n",
            "epochs =  15 , step =  45000 , loss value =  0.8994768620455428\n",
            "epochs =  15 , step =  46000 , loss value =  1.059562821650193\n",
            "epochs =  15 , step =  47000 , loss value =  1.0573772106453962\n",
            "\n",
            " current epochs =  15 , current training accuracy =  99.0 %\n",
            "current epochs =  15 , current validation accuracy =  97.39999999999999 %\n",
            "\n",
            "epochs =  16 , step =  0 , loss value =  0.855501233520355\n",
            "epochs =  16 , step =  1000 , loss value =  1.075832967214276\n",
            "epochs =  16 , step =  2000 , loss value =  0.942638983913139\n",
            "epochs =  16 , step =  3000 , loss value =  1.0597967363521108\n",
            "epochs =  16 , step =  4000 , loss value =  0.9103196847116692\n",
            "epochs =  16 , step =  5000 , loss value =  0.8737727340659659\n",
            "epochs =  16 , step =  6000 , loss value =  0.9869579560652131\n",
            "epochs =  16 , step =  7000 , loss value =  1.0639631720841398\n",
            "epochs =  16 , step =  8000 , loss value =  1.045790915443301\n",
            "epochs =  16 , step =  9000 , loss value =  1.0998778087950407\n",
            "epochs =  16 , step =  10000 , loss value =  1.1457680235743626\n",
            "epochs =  16 , step =  11000 , loss value =  0.9094450714341443\n",
            "epochs =  16 , step =  12000 , loss value =  0.7827708934156454\n",
            "epochs =  16 , step =  13000 , loss value =  0.876013231850479\n",
            "epochs =  16 , step =  14000 , loss value =  1.0314250067629311\n",
            "epochs =  16 , step =  15000 , loss value =  0.9099892783491149\n",
            "epochs =  16 , step =  16000 , loss value =  0.9866284386643426\n",
            "epochs =  16 , step =  17000 , loss value =  0.9714231863657065\n",
            "epochs =  16 , step =  18000 , loss value =  1.0136647833369121\n",
            "epochs =  16 , step =  19000 , loss value =  0.9237566950723208\n",
            "epochs =  16 , step =  20000 , loss value =  0.8645324098159721\n",
            "epochs =  16 , step =  21000 , loss value =  0.9780515399338844\n",
            "epochs =  16 , step =  22000 , loss value =  0.9178538875177307\n",
            "epochs =  16 , step =  23000 , loss value =  0.9357977022925151\n",
            "epochs =  16 , step =  24000 , loss value =  0.8741508069713753\n",
            "epochs =  16 , step =  25000 , loss value =  1.02057077024964\n",
            "epochs =  16 , step =  26000 , loss value =  0.975607253268541\n",
            "epochs =  16 , step =  27000 , loss value =  1.0233481660904054\n",
            "epochs =  16 , step =  28000 , loss value =  0.8662601334649354\n",
            "epochs =  16 , step =  29000 , loss value =  0.9756439273814788\n",
            "epochs =  16 , step =  30000 , loss value =  0.841899372470992\n",
            "epochs =  16 , step =  31000 , loss value =  0.8129034839765038\n",
            "epochs =  16 , step =  32000 , loss value =  1.0433677267915065\n",
            "epochs =  16 , step =  33000 , loss value =  1.0536297118395601\n",
            "epochs =  16 , step =  34000 , loss value =  0.8589456567735752\n",
            "epochs =  16 , step =  35000 , loss value =  0.8760056861126735\n",
            "epochs =  16 , step =  36000 , loss value =  0.9170114187568191\n",
            "epochs =  16 , step =  37000 , loss value =  0.8902074889990702\n",
            "epochs =  16 , step =  38000 , loss value =  0.9572932688392632\n",
            "epochs =  16 , step =  39000 , loss value =  0.9435486656423887\n",
            "epochs =  16 , step =  40000 , loss value =  1.06565258592494\n",
            "epochs =  16 , step =  41000 , loss value =  0.9604574885925687\n",
            "epochs =  16 , step =  42000 , loss value =  1.028602490307763\n",
            "epochs =  16 , step =  43000 , loss value =  0.9468370601339525\n",
            "epochs =  16 , step =  44000 , loss value =  0.8701467305646544\n",
            "epochs =  16 , step =  45000 , loss value =  0.9055446604671372\n",
            "epochs =  16 , step =  46000 , loss value =  1.0769479314777957\n",
            "epochs =  16 , step =  47000 , loss value =  1.05916346877795\n",
            "\n",
            " current epochs =  16 , current training accuracy =  99.1 %\n",
            "current epochs =  16 , current validation accuracy =  97.39999999999999 %\n",
            "\n",
            "epochs =  17 , step =  0 , loss value =  0.8642592579805543\n",
            "epochs =  17 , step =  1000 , loss value =  1.0870094080402934\n",
            "epochs =  17 , step =  2000 , loss value =  0.9599708850877035\n",
            "epochs =  17 , step =  3000 , loss value =  1.073363431301546\n",
            "epochs =  17 , step =  4000 , loss value =  0.918353005035262\n",
            "epochs =  17 , step =  5000 , loss value =  0.8833984154885594\n",
            "epochs =  17 , step =  6000 , loss value =  0.9966973431269731\n",
            "epochs =  17 , step =  7000 , loss value =  1.0674251287747116\n",
            "epochs =  17 , step =  8000 , loss value =  1.0559318972460907\n",
            "epochs =  17 , step =  9000 , loss value =  1.1062953113539284\n",
            "epochs =  17 , step =  10000 , loss value =  1.1516081143622046\n",
            "epochs =  17 , step =  11000 , loss value =  0.9194075350647231\n",
            "epochs =  17 , step =  12000 , loss value =  0.78487142876755\n",
            "epochs =  17 , step =  13000 , loss value =  0.8830416019689729\n",
            "epochs =  17 , step =  14000 , loss value =  1.0411787311398142\n",
            "epochs =  17 , step =  15000 , loss value =  0.9029013460763454\n",
            "epochs =  17 , step =  16000 , loss value =  0.9941077603305384\n",
            "epochs =  17 , step =  17000 , loss value =  0.9825102054336431\n",
            "epochs =  17 , step =  18000 , loss value =  1.0155484054876374\n",
            "epochs =  17 , step =  19000 , loss value =  0.9392786648785243\n",
            "epochs =  17 , step =  20000 , loss value =  0.8752233739776178\n",
            "epochs =  17 , step =  21000 , loss value =  0.9843692026011994\n",
            "epochs =  17 , step =  22000 , loss value =  0.9259214305939689\n",
            "epochs =  17 , step =  23000 , loss value =  0.9417261997010631\n",
            "epochs =  17 , step =  24000 , loss value =  0.8810436805400327\n",
            "epochs =  17 , step =  25000 , loss value =  1.030570034802942\n",
            "epochs =  17 , step =  26000 , loss value =  0.9898859374732537\n",
            "epochs =  17 , step =  27000 , loss value =  1.0340672479209532\n",
            "epochs =  17 , step =  28000 , loss value =  0.8779771908102868\n",
            "epochs =  17 , step =  29000 , loss value =  0.9827097216413894\n",
            "epochs =  17 , step =  30000 , loss value =  0.848033778120859\n",
            "epochs =  17 , step =  31000 , loss value =  0.8231969323644399\n",
            "epochs =  17 , step =  32000 , loss value =  1.0461232373453317\n",
            "epochs =  17 , step =  33000 , loss value =  1.0636063964611933\n",
            "epochs =  17 , step =  34000 , loss value =  0.8616427468765895\n",
            "epochs =  17 , step =  35000 , loss value =  0.8800656589285379\n",
            "epochs =  17 , step =  36000 , loss value =  0.925363704771226\n",
            "epochs =  17 , step =  37000 , loss value =  0.9027421338854218\n",
            "epochs =  17 , step =  38000 , loss value =  0.9638322734763308\n",
            "epochs =  17 , step =  39000 , loss value =  0.9581803282021681\n",
            "epochs =  17 , step =  40000 , loss value =  1.0654444935700187\n",
            "epochs =  17 , step =  41000 , loss value =  0.9675672528846635\n",
            "epochs =  17 , step =  42000 , loss value =  1.0315227364722435\n",
            "epochs =  17 , step =  43000 , loss value =  0.9526325560024005\n",
            "epochs =  17 , step =  44000 , loss value =  0.8763682365665877\n",
            "epochs =  17 , step =  45000 , loss value =  0.9111644850075922\n",
            "epochs =  17 , step =  46000 , loss value =  1.0928306927185003\n",
            "epochs =  17 , step =  47000 , loss value =  1.061773966486776\n",
            "\n",
            " current epochs =  17 , current training accuracy =  99.1 %\n",
            "current epochs =  17 , current validation accuracy =  97.39999999999999 %\n",
            "\n",
            "epochs =  18 , step =  0 , loss value =  0.8748069103305607\n",
            "epochs =  18 , step =  1000 , loss value =  1.0975564054843212\n",
            "epochs =  18 , step =  2000 , loss value =  0.9753650070301703\n",
            "epochs =  18 , step =  3000 , loss value =  1.0871214982781445\n",
            "epochs =  18 , step =  4000 , loss value =  0.9265245810286226\n",
            "epochs =  18 , step =  5000 , loss value =  0.8924691831300363\n",
            "epochs =  18 , step =  6000 , loss value =  1.0064971136099026\n",
            "epochs =  18 , step =  7000 , loss value =  1.0711243974580438\n",
            "epochs =  18 , step =  8000 , loss value =  1.0642052658318057\n",
            "epochs =  18 , step =  9000 , loss value =  1.1126947698002503\n",
            "epochs =  18 , step =  10000 , loss value =  1.1559108256772404\n",
            "epochs =  18 , step =  11000 , loss value =  0.9283664389800267\n",
            "epochs =  18 , step =  12000 , loss value =  0.7871247468316546\n",
            "epochs =  18 , step =  13000 , loss value =  0.8889390167485182\n",
            "epochs =  18 , step =  14000 , loss value =  1.0493288622022154\n",
            "epochs =  18 , step =  15000 , loss value =  0.897978677409302\n",
            "epochs =  18 , step =  16000 , loss value =  1.0026071206967782\n",
            "epochs =  18 , step =  17000 , loss value =  0.9937220219731001\n",
            "epochs =  18 , step =  18000 , loss value =  1.0192778993861709\n",
            "epochs =  18 , step =  19000 , loss value =  0.9556842271254415\n",
            "epochs =  18 , step =  20000 , loss value =  0.8850797787737628\n",
            "epochs =  18 , step =  21000 , loss value =  0.9894558053985729\n",
            "epochs =  18 , step =  22000 , loss value =  0.9338738197333383\n",
            "epochs =  18 , step =  23000 , loss value =  0.948431719319321\n",
            "epochs =  18 , step =  24000 , loss value =  0.8892988907360195\n",
            "epochs =  18 , step =  25000 , loss value =  1.0403007166247034\n",
            "epochs =  18 , step =  26000 , loss value =  1.002134380272378\n",
            "epochs =  18 , step =  27000 , loss value =  1.0452848423186616\n",
            "epochs =  18 , step =  28000 , loss value =  0.8893082754187451\n",
            "epochs =  18 , step =  29000 , loss value =  0.9906808764242597\n",
            "epochs =  18 , step =  30000 , loss value =  0.8564161657800939\n",
            "epochs =  18 , step =  31000 , loss value =  0.8331959406149544\n",
            "epochs =  18 , step =  32000 , loss value =  1.0516407735023177\n",
            "epochs =  18 , step =  33000 , loss value =  1.0734612154957535\n",
            "epochs =  18 , step =  34000 , loss value =  0.866431760881481\n",
            "epochs =  18 , step =  35000 , loss value =  0.8837103313261145\n",
            "epochs =  18 , step =  36000 , loss value =  0.9347091858128331\n",
            "epochs =  18 , step =  37000 , loss value =  0.9148400742266586\n",
            "epochs =  18 , step =  38000 , loss value =  0.9689308536888781\n",
            "epochs =  18 , step =  39000 , loss value =  0.9731902168355497\n",
            "epochs =  18 , step =  40000 , loss value =  1.0680879510701986\n",
            "epochs =  18 , step =  41000 , loss value =  0.9750377007516462\n",
            "epochs =  18 , step =  42000 , loss value =  1.0354704805807504\n",
            "epochs =  18 , step =  43000 , loss value =  0.9567904275410477\n",
            "epochs =  18 , step =  44000 , loss value =  0.8836227838451455\n",
            "epochs =  18 , step =  45000 , loss value =  0.9161262695246\n",
            "epochs =  18 , step =  46000 , loss value =  1.1062326673544272\n",
            "epochs =  18 , step =  47000 , loss value =  1.073185636241888\n",
            "\n",
            " current epochs =  18 , current training accuracy =  99.1 %\n",
            "current epochs =  18 , current validation accuracy =  97.5 %\n",
            "\n",
            "epochs =  19 , step =  0 , loss value =  0.8856898456726916\n",
            "epochs =  19 , step =  1000 , loss value =  1.1083001049848802\n",
            "epochs =  19 , step =  2000 , loss value =  0.9902986768728841\n",
            "epochs =  19 , step =  3000 , loss value =  1.1021406832390443\n",
            "epochs =  19 , step =  4000 , loss value =  0.9363743744274998\n",
            "epochs =  19 , step =  5000 , loss value =  0.9008718409039702\n",
            "epochs =  19 , step =  6000 , loss value =  1.013093051395193\n",
            "epochs =  19 , step =  7000 , loss value =  1.0744258200050267\n",
            "epochs =  19 , step =  8000 , loss value =  1.0722953940007152\n",
            "epochs =  19 , step =  9000 , loss value =  1.1199272965438807\n",
            "epochs =  19 , step =  10000 , loss value =  1.159470631561373\n",
            "epochs =  19 , step =  11000 , loss value =  0.9369631031622349\n",
            "epochs =  19 , step =  12000 , loss value =  0.7937699397485435\n",
            "epochs =  19 , step =  13000 , loss value =  0.8963759621710815\n",
            "epochs =  19 , step =  14000 , loss value =  1.0559615213391922\n",
            "epochs =  19 , step =  15000 , loss value =  0.895415939390152\n",
            "epochs =  19 , step =  16000 , loss value =  1.0125328320903169\n",
            "epochs =  19 , step =  17000 , loss value =  1.0002757314143484\n",
            "epochs =  19 , step =  18000 , loss value =  1.0240383878477404\n",
            "epochs =  19 , step =  19000 , loss value =  0.9725784344872894\n",
            "epochs =  19 , step =  20000 , loss value =  0.8946044956357087\n",
            "epochs =  19 , step =  21000 , loss value =  0.9957184764193654\n",
            "epochs =  19 , step =  22000 , loss value =  0.942409260120824\n",
            "epochs =  19 , step =  23000 , loss value =  0.9556708981873949\n",
            "epochs =  19 , step =  24000 , loss value =  0.8983200569271177\n",
            "epochs =  19 , step =  25000 , loss value =  1.0505542756740591\n",
            "epochs =  19 , step =  26000 , loss value =  1.0123553592150394\n",
            "epochs =  19 , step =  27000 , loss value =  1.0562343316112435\n",
            "epochs =  19 , step =  28000 , loss value =  0.9004174540711282\n",
            "epochs =  19 , step =  29000 , loss value =  0.9998879086718901\n",
            "epochs =  19 , step =  30000 , loss value =  0.8655615745297578\n",
            "epochs =  19 , step =  31000 , loss value =  0.8428832542235776\n",
            "epochs =  19 , step =  32000 , loss value =  1.0612256937738693\n",
            "epochs =  19 , step =  33000 , loss value =  1.0838813585418696\n",
            "epochs =  19 , step =  34000 , loss value =  0.8727368706344283\n",
            "epochs =  19 , step =  35000 , loss value =  0.8875593013655132\n",
            "epochs =  19 , step =  36000 , loss value =  0.9453353859915595\n",
            "epochs =  19 , step =  37000 , loss value =  0.9266119540052793\n",
            "epochs =  19 , step =  38000 , loss value =  0.9746286098607515\n",
            "epochs =  19 , step =  39000 , loss value =  0.9876232080984387\n",
            "epochs =  19 , step =  40000 , loss value =  1.071784423699672\n",
            "epochs =  19 , step =  41000 , loss value =  0.9832630893776533\n",
            "epochs =  19 , step =  42000 , loss value =  1.040229866959162\n",
            "epochs =  19 , step =  43000 , loss value =  0.9587463903551152\n",
            "epochs =  19 , step =  44000 , loss value =  0.8912016765931448\n",
            "epochs =  19 , step =  45000 , loss value =  0.9213440469490572\n",
            "epochs =  19 , step =  46000 , loss value =  1.1209746576016224\n",
            "epochs =  19 , step =  47000 , loss value =  1.0865159965226565\n",
            "\n",
            " current epochs =  19 , current training accuracy =  99.2 %\n",
            "current epochs =  19 , current validation accuracy =  97.5 %\n",
            "\n",
            "\n",
            "Elpased time =  0:13:59.925917\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "1OedzfmbUkoo",
        "outputId": "246d90c4-8135-4b63-b172-254449123076"
      },
      "source": [
        "plt.title('Training / Validation Accuracy Trend')\r\n",
        "plt.xlabel('epochs')\r\n",
        "plt.ylabel('Accuracy')\r\n",
        "plt.grid()\r\n",
        "plt.plot(training_accuracy_list)\r\n",
        "plt.plot(validation_accuracy_list)\r\n",
        "plt.legend(['training acc', 'validation acc'])\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbQdYJ6QKFyh",
        "outputId": "bac823b5-f5e7-401d-bf70-1159757e4006"
      },
      "source": [
        "test_data = np.loadtxt('./drive/MyDrive/AI_INOVATION_SQUARE/data/mnist_test.csv', delimiter=',', dtype=np.float32)\r\n",
        "\r\n",
        "print(\"test_data.shape = \",test_data.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_data.shape =  (10000, 785)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGIHpsucUHXk",
        "outputId": "5e0de20f-d1e0-4fb8-8391-ed48c85392e6"
      },
      "source": [
        "test_input_data = test_data[:, 1:]\r\n",
        "test_target_data = test_data[:,0]\r\n",
        "\r\n",
        "(test_accuracy, index_label_prediction_list) = nn.accuracy(test_input_data, test_target_data)\r\n",
        "\r\n",
        "print(\"Accuracy = \", 100* np.round(test_accuracy,3),'%')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy =  97.6 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xnzd4HDVGwa",
        "outputId": "e2de9051-f3c8-4c6c-e9b3-375c8f60acf7"
      },
      "source": [
        "total_test_data_num = len(test_data)\r\n",
        "# 총 오답 개수\r\n",
        "false_prediction_data_num = len(index_label_prediction_list)\r\n",
        "\r\n",
        "print(\"false prediction data num = \", false_prediction_data_num)\r\n",
        "\r\n",
        "# index_label_prediction_list 확인\r\n",
        "print(index_label_prediction_list)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "false prediction data num =  237\n",
            "[[8, 5, 6], [96, 1, 9], [247, 4, 2], [259, 6, 0], [321, 2, 7], [340, 5, 3], [445, 6, 0], [448, 9, 8], [449, 3, 5], [495, 8, 2], [582, 8, 2], [619, 1, 8], [659, 2, 8], [674, 5, 3], [691, 8, 4], [707, 4, 9], [717, 0, 6], [720, 5, 8], [740, 4, 9], [810, 7, 2], [882, 9, 7], [938, 3, 5], [965, 6, 0], [1014, 6, 5], [1039, 7, 8], [1044, 6, 2], [1107, 9, 3], [1112, 4, 6], [1156, 7, 8], [1182, 6, 8], [1192, 9, 4], [1226, 7, 2], [1232, 9, 4], [1242, 4, 9], [1247, 9, 3], [1260, 7, 1], [1283, 7, 2], [1289, 5, 9], [1299, 5, 7], [1319, 8, 3], [1326, 7, 1], [1378, 5, 6], [1414, 9, 7], [1425, 8, 4], [1494, 7, 0], [1500, 7, 1], [1522, 7, 9], [1527, 1, 3], [1549, 4, 2], [1553, 9, 8], [1609, 2, 6], [1681, 3, 7], [1709, 9, 3], [1754, 7, 2], [1790, 2, 8], [1828, 3, 7], [1878, 8, 3], [1901, 9, 4], [1940, 5, 0], [1941, 7, 5], [1952, 9, 3], [2004, 8, 9], [2016, 7, 2], [2018, 1, 7], [2033, 0, 4], [2035, 5, 3], [2044, 2, 7], [2053, 4, 9], [2098, 2, 0], [2109, 3, 7], [2118, 6, 0], [2129, 9, 2], [2130, 4, 9], [2135, 6, 1], [2162, 5, 8], [2182, 1, 2], [2186, 2, 3], [2224, 5, 8], [2293, 9, 0], [2299, 2, 7], [2369, 5, 9], [2371, 4, 9], [2387, 9, 1], [2422, 6, 4], [2454, 6, 8], [2488, 2, 4], [2526, 5, 3], [2560, 3, 5], [2607, 7, 2], [2648, 9, 0], [2654, 6, 1], [2771, 4, 9], [2810, 5, 3], [2896, 8, 0], [2921, 3, 2], [2927, 3, 2], [2939, 9, 7], [2953, 3, 5], [2979, 9, 7], [2995, 6, 8], [3005, 9, 1], [3030, 6, 8], [3060, 9, 7], [3073, 1, 2], [3117, 5, 9], [3146, 3, 5], [3189, 7, 6], [3218, 6, 5], [3333, 7, 9], [3422, 6, 0], [3503, 9, 1], [3520, 6, 4], [3533, 4, 9], [3549, 3, 2], [3558, 5, 0], [3559, 8, 5], [3567, 8, 5], [3597, 9, 3], [3767, 7, 2], [3776, 5, 8], [3780, 4, 6], [3811, 2, 3], [3818, 0, 4], [3853, 6, 5], [3855, 5, 0], [3893, 5, 6], [3902, 5, 3], [3906, 1, 2], [3926, 9, 3], [3941, 4, 2], [3968, 5, 3], [3976, 7, 1], [4063, 6, 5], [4065, 0, 2], [4078, 9, 3], [4152, 5, 1], [4163, 9, 0], [4176, 2, 6], [4199, 7, 9], [4201, 1, 7], [4211, 6, 5], [4224, 9, 7], [4248, 2, 8], [4255, 5, 3], [4289, 2, 7], [4306, 3, 7], [4369, 9, 4], [4374, 5, 6], [4437, 3, 2], [4443, 3, 2], [4477, 0, 6], [4497, 8, 7], [4536, 6, 5], [4547, 6, 4], [4571, 6, 8], [4575, 4, 2], [4601, 8, 4], [4620, 6, 2], [4639, 8, 9], [4690, 7, 2], [4731, 8, 7], [4807, 8, 3], [4823, 9, 4], [4837, 7, 2], [4874, 9, 6], [4880, 0, 8], [4886, 7, 1], [4956, 8, 4], [4966, 7, 9], [4990, 3, 2], [5246, 7, 2], [5331, 1, 6], [5457, 1, 8], [5642, 1, 5], [5676, 4, 3], [5734, 3, 7], [5749, 8, 2], [5936, 4, 9], [5937, 5, 3], [5955, 3, 8], [5972, 5, 3], [5973, 3, 8], [5982, 5, 3], [6023, 3, 5], [6045, 3, 9], [6059, 3, 9], [6071, 9, 3], [6091, 9, 8], [6166, 9, 3], [6172, 9, 5], [6173, 9, 8], [6400, 0, 6], [6505, 9, 0], [6555, 8, 9], [6560, 9, 8], [6568, 9, 4], [6571, 9, 7], [6597, 0, 7], [6625, 8, 7], [6632, 9, 5], [6651, 0, 5], [6755, 8, 3], [7216, 0, 6], [7432, 7, 1], [7434, 4, 8], [7459, 9, 5], [7797, 5, 6], [7800, 3, 2], [7821, 3, 2], [7823, 8, 2], [7849, 3, 2], [8020, 1, 8], [8094, 2, 8], [8408, 8, 6], [8522, 8, 6], [9009, 7, 2], [9015, 7, 2], [9024, 7, 2], [9280, 8, 5], [9530, 9, 8], [9587, 9, 4], [9664, 2, 7], [9679, 6, 3], [9692, 9, 7], [9729, 5, 6], [9749, 5, 6], [9768, 2, 0], [9770, 5, 0], [9777, 5, 0], [9779, 2, 0], [9792, 4, 9], [9808, 9, 4], [9839, 2, 7], [9905, 3, 7], [9941, 5, 8], [9944, 3, 9], [9982, 5, 6]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QKQ0UxlYe_X"
      },
      "source": [
        "### index_label_prediction_list 이미지 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "flEe4c6TVqeb",
        "outputId": "b4ccabb3-bbd8-417b-98fa-9dbd0ff8902e"
      },
      "source": [
        "index = np.random.randint(0, len(index_label_prediction_list))\r\n",
        "\r\n",
        "false_data_info = index_label_prediction_list[index]\r\n",
        "\r\n",
        "mnist_index = false_data_info[0]\r\n",
        "label = false_data_info[1]\r\n",
        "predicted_num = false_data_info[2]\r\n",
        "\r\n",
        "title_str = 'index = ', mnist_index, \", label = \", label, \", predicted_num = \", predicted_num\r\n",
        "\r\n",
        "img = test_data[mnist_index,1: ].reshape(28,28)\r\n",
        "\r\n",
        "plt.title(title_str)\r\n",
        "plt.imshow(img, cmap='gray')\r\n",
        "plt.show()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVsAAAEICAYAAADx1Ve0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAXY0lEQVR4nO3debQcdZnG8e9DgEQSlrCYSUJCIoK4zAwMiCMyGg0yEeUgOKIxYCJLVGCUGXFE1EOOuACDomd00KA5wIAgaFTUoMQoizKCgcMSiSwTEpOYhRB2OGjCO3/U70Ll2l13yb2/6u77fM7pk+56q6rfrup+uvrXdTuKCMzMbHBtU3cDZmZDgcPWzCwDh62ZWQYOWzOzDBy2ZmYZOGzNzDLoVdhK+qKk05vUnpL0sv7cuaQbJJ3Un2Vt60iaI+nyXs57iaTP9fN++r2svai8HSX9k6T7Mt1vSHp5jvtqR5KOlPTd3szbY9hK2gN4P/DNdHuKpBu66hExKiKW9bPXliFplqRLejnvTEm3S3pC0ipJ50vatlR/qttls6T/SrUZ3WrPpCf0gan+Zkm/kvS4pOWD9RjaWXqjmNPHZbaXtFTSqsG8nxwi4uaIeEVP86Xnw69z9NRuJC2XNKmX8x4i6TZJT0q6W9KhXbWI+DHwakl/19N6enNkOwtYEBHP9qaxIWIH4HRgd+B1wFTgjK5iegMaFRGjgL8BngWuSbUrutVPAZYBd6TFnwbmAR/P9WCGiI8DD9fdBED5jdlam6RdgR8D/wnsApwP/FjS6NJsVwKze1pXb8L2bcCNFc288DEjfdT5uqSfpneBWyXtXZr3rZL+kI7avgao27pOSEcfj0r6uaS90vRPpHVtm25/WNLvJY3oRf8DLiIuSkcXf46I1cAVwBuazP4uYD1wc5P6TOCySH/KFxG3RcT/UARwNpKukbQ27ZubJL262yy7S1qY9uuNXfsmLbtfqm2UdJ+kY3P23hNJk4HjgC8O4n1cIukbFdsoJJ0q6QHggTTtHZLulPSYpFvKR0eSDpB0R1rXd4ERpdqU8hG6pAmS5kt6WNIjkr4m6ZXAN4DXp09Qj6V5h0u6QNIfJa1LPb+ktK6PS1oj6U+STujDY2/4upc0KT328ie/F4YP09H3byRdmLbDsnQkOUvSSknrJc3s6/4YQIcAayPimojYHBGXU7xpH1Oa5wbg7T2uKSIqL2nFr62oB/DydP0S4BHgYGBbihC6KtV2B54E/gXYDvg3YBNwUqofBTwIvDIt+2ngllTbBrgJmAPsAzwKHNCkn4nAYxWX9/X0mPt6AX4InNuk9ktgTpPaXsBmYHKD2mHA8oHutbT+OcDlpdsnADsCw4GvAHeWapekfffGVP8q8OtUGwmsBD6Q9tsBwAbgVaVlP9ekh0N72FeHDtBj/QlwNDAFWDVI27PpNiq9ThYCuwIvSdtpPcUno2EUb7rL07LbAyvSa2S79Jr5S9d2LD+OtOxdwIVpX4zo2m4Un0p/3a3PC4FrUx87Uhy1fTHVpgHrgNekdX2H0uu7h8fe7HU/Ka1j29L8N/Di634WRQ58ID2WzwF/BL6etsXhabuOanLf/13x/Ll7APbrO4B7u017ALiwdHvX9Bh3qlxXL+7sL8B+FfXuYfutUu0I4A/p+vuB35ZqAlaVNvp1wIml+jbAM8BepZ22EVgKfHIwXjD93BknpMexe4Na0zBN9c8ANzSpZQ3bbrVd0n7dubRfryrVR6XHNQF4D3Bzt+W/CZxdWrZh2GbaP0cD16XrUxjcsG24jdLtAN5Sql8EnNNtHfcBb6II7D8BKtVuoXHYvp7igGjbBj3NYsvAF8Uw1d6laa8HHkrX51E6aAD2pfdh2+x1P4mew/aBUu1v0/xjStMeAfav6fmzG0VwT6d445sJPA98szTPdqnniVXr6s0wwqMU74C9tbZ0/RmKJx3AOIojIACi6HJlad69gK+mjxKPUQSrgPFp/uXAryh23tf70M+gkfROio+mb4uIDQ1mOZ7iyf5Qk1W8H7h0sPrrLUnDJJ0r6f8kPUFxhAXFp5Eu5X33FMX+GUex317Xtd/SvptBMVZdK0kjKcbYPpLpLptto7+qU2y3j3XbbhPS/OOA1ek10mVFk/ucAKyIiE296G8Piu8bbi/d58/SdOj2Gq24z0aave57Y13p+rMAEdF9Wl/WN2Ai4hGKT93/TtHnNOAXFAdYXbry8bGqdfUmbO+meIfbWmsonhgASFL5NsVO/mBE7FK6vCQibknzv53iXXgRxWB1Q5Im6q/PBihfZgzAY0HSNOBi4MiIuKfJbE3DVNIbKJ7c3xuIfrbS+yieUIcBO1O8ocGWY+rlfTeK4qPTnyj2243d9tuoiPhwT3eq4hSmqn31T1v5uPZJj+VmSWuB+cDYNDY9qWK5/mq2jbqUw3Ml8Plu222HiLiS4rUyPr1Gukxscp8rgYlq/KVb95/020ARXK8u3efOUXxRC91eoxX32RdPp393KE0bsDfiNObc7Pnz+4G4j4i4MSJeGxG7UhxA7QfcVprllRSfQp+oWk9vwnYBxUebrfVTilMkjklPjI+w5Ub/BvBJpS9mJO0s6d3p+u7At4CTKA7jj5R0RKM7iYg/Runb/gaXK3rTrIpTQ2Y1qb2FYlzqXRFxW5N5DqE4Kr+myV3MBL4fEU92W24bFV/8bVfc1AhJ25fqN6iXpyNVPYZudgSeo/i4tgPwhQbzHCHp0NTLORRDQispxkP3lXS8pO3S5bXpC5pKUXzJWLWvmn2p2P1xhqQpDUpLKMJj/3Q5ieLoZH/SEVwftlHV/XRpto0auRj4kKTXqTBS0tsl7Qj8L8U45kfS9jyGYjy0kdsoQvLctI4R6Y2c9Fj37Hr+RMTz6X4vlPTS9JjGS/rnNP/VwCxJr5K0A3B2z1ulWkQ8DKwGjkufoE4A9u5hsb6s/0MVz5/uX/I2lL6MW15RPyDth52AC4CVEfHz0ixvohgGrdSbsL2M4kn0kh7nrJA+Zr8bOJfiRb0P8JtS/QfAecBV6aPsEoozIQDmAj+KiAXpsP5E4FuSdtuanppJT87dgN82meUzFEeAC0rvot039kxgfvcwTesfARxL46PeN1IcfSygOLJ4Fri+VJ9AabttxWMou4ziI+Nq4N4my3yH4sW3ETiQ4tt90uM7HHgvxVHcWor9OLwX97vVJE2g+ALlrz5dRMSmiFjbdUm9P59ub+7LNqq6n5KG26iRiFgMnAx8jWKo7kGK8Usi4s8U33bPSut6D8VReaP1bAaOBF5O8cXSqjQ/FF/O/h5YK6lrmOsT6b5+m15nvwBekdZ1HcWXo79M8/yy4rH2xckUp949AryaYvy5lfT0mvoPik8FK4GxFN8DlE0n/R1CFW05LNRkJukLwPqI+EqPM3cAFSctnxoR0+vupUzSnsDVEXFIL+Ztyccw0CQdR/Gx+JP9WLbX26in+1HxxySrIuLTfe3D6iXpeuCjEbG0H8seCRwfET2e7tirsDWzag5b64l/iMbMeqTij4gG7QvnocBHtmZmGfjI1swsA/8gBsUpPXX3YNbpIkI9z9W5OvLIVtI0FT+I8qCkM+vux8ys48ZsJQ0D7gfeSnHO4e+A6RFxb8UynbURzFqQj2w7z8HAgxGxLJ0cfhXFn6KamdWmE8N2PFv+mMaqNG0LkmZLWixpcbbOzGzIGrJfkEXEXIo/A/YwgpkNuk48sl3Nlr9ctGeaZmZWm04M298B+0ianH5o5L0Uv0xvZlabjhtGiIhNkk4Dfk7x32zMi4gB+V1LM7P+6rhTv/rDY7Zmg8+nfpmZ2aBz2JqZZeCwNTPLwGFrZpaBw9bMLAOHrZlZBg5bM7MMHLZmZhk4bM3MMnDYmpll4LA1M8vAYWtmloHD1swsA4etmVkGDlszswwctmZmGThszcwycNiamWXgsDUzy8Bha2aWgcPWzCwDh62ZWQYOWzOzDBy2ZmYZOGzNzDJw2JqZZeCwNTPLwGFrZpaBw9bMLAOHrZlZBtvW3cBgkLQceBLYDGyKiIPq7cjMhrqODNvkzRGxoe4mzMzAwwhmZll0atgGcL2k2yXNbjSDpNmSFktanLk3MxuCFBF19zDgJI2PiNWSXgosBP41Im6qmL/zNoJZi4kI1d1DnTryyDYiVqd/1wM/AA6utyMzG+o6LmwljZS0Y9d14HBgSb1dmdlQ14lnI4wBfiAJisf3nYj4Wb0tWas555xzmtZOPPHEymXHjRs30O3YENBxYRsRy4C/r7sPM7OyjhtGMDNrRQ5bM7MMHLZmZhk4bM3MMnDYmpll0JF/QdZX/guy/BYuXFhZnzFjRmV9/fr1lfXRo0dX1h966KGmtaeffrpy2fHjx1fWrTH/BZmZmQ06h62ZWQYOWzOzDBy2ZmYZOGzNzDJw2JqZZeCwNTPLoON+9cvyGTlyZGX9uOOOa1obMWJE5bKbNm3qV09devqZxJ122qlprafzbM36w0e2ZmYZOGzNzDJw2JqZZeCwNTPLwGFrZpaBw9bMLAOHrZlZBj7P1poaPnx4Zf3yyy+vrE+bNq1praffhN24cWNl3azd+MjWzCwDh62ZWQYOWzOzDBy2ZmYZOGzNzDJw2JqZZeCwNTPLwOfZWlOnnXZaZf2www6rrB9zzDFNa4N9Hm1PvVVZuXLlAHZiVmjrI1tJ8yStl7SkNG1XSQslPZD+HV1nj2Zm0OZhC1wCdP8zpTOBRRGxD7Ao3TYzq1Vbh21E3AR0/zx6FHBpun4p8M6sTZmZNdCJY7ZjImJNur4WGNNoJkmzgdnZujKzIa0Tw/YFERGSokltLjAXoNk8ZmYDpa2HEZpYJ2ksQPp3fc39mJl1ZNheC8xM12cCP6qxFzMzoM2HESRdCUwBdpe0CjgbOBe4WtKJwArg2Po6bG177rlnZf2UU06prC9durSyft111/W5p96aOnXqVtWrzJ8/v9/LmjXT1mEbEdOblPr/SjMzGwSdOIxgZtZyHLZmZhk4bM3MMnDYmpll4LA1M8ugrc9GsK0ze3b1XytPnjy5sn7GGWcMZDt9cvzxx1fWhw0bVllft25d09q8efP61ZNZFR/Zmpll4LA1M8vAYWtmloHD1swsA4etmVkGDlszswwctmZmGfg82yFsl112qazfddddlfUFCxYMZDtb2G233SrrBx54YGX91ltvraw//vjjTWsbNmyoXNasP3xka2aWgcPWzCwDh62ZWQYOWzOzDBy2ZmYZOGzNzDJw2JqZZeDzbIew4cOHV9bvv//+yvpzzz03kO1s4VOf+lRlfY899qisL1u2rLLe02M3G2g+sjUzy8Bha2aWgcPWzCwDh62ZWQYOWzOzDBy2ZmYZOGzNzDLwebZD2Lp16yrrU6dOraxPmDChsv7MM880rc2YMaNy2Z7qJ598cmX9vPPOq6yvWLGism420Nr2yFbSPEnrJS0pTZsjabWkO9PliDp7NDPr0rZhC1wCTGsw/cKI2D9dBu+/EjAz64O2DduIuAnYWHcfZma90bZhW+E0SXenYYbRzWaSNFvSYkmLczZnZkNTp4XtRcDewP7AGuBLzWaMiLkRcVBEHJSrOTMbujoqbCNiXURsjojngYuBg+vuycwMOixsJY0t3TwaWNJsXjOznNr2PFtJVwJTgN0lrQLOBqZI2h8IYDnwwdoabANLly6trE+ePLmyfsstt1TWN2/e3LQ2ceLEymU/+9nPVtZ/8pOfVNbPP//8yrpZbm0bthExvcHkb2dvxMysFzpqGMHMrFU5bM3MMnDYmpll4LA1M8vAYWtmlkHbno1gW+/KK6+srG/YsKGyPm7cuIFsZws9ndp1yCGHVNb33Xffyvry5cv72pLZVvGRrZlZBg5bM7MMHLZmZhk4bM3MMnDYmpll4LA1M8vAYWtmloHPs7WmFi5cWHcLTe23335btfz3vve9AerErHd8ZGtmloHD1swsA4etmVkGDlszswwctmZmGThszcwycNiamWXg82ytLT311FNbtfzjjz8+QJ2Y9Y6PbM3MMnDYmpll4LA1M8vAYWtmloHD1swsA4etmVkGDlszswza9jxbSROAy4AxQABzI+KrknYFvgtMApYDx0bEo3X1aYNj2rRplXVJmTox6512PrLdBHwsIl4F/CNwqqRXAWcCiyJiH2BRum1mVqu2DduIWBMRd6TrTwJLgfHAUcClabZLgXfW06GZ2YvaNmzLJE0CDgBuBcZExJpUWksxzGBmVqu2HbPtImkU8H3g9Ih4ojxWFxEhKZosNxuYnadLMxvq2vrIVtJ2FEF7RUTMT5PXSRqb6mOB9Y2WjYi5EXFQRByUp1szG8raNmxVHMJ+G1gaEV8ula4FZqbrM4Ef5e7NzKy7dh5GeANwPHCPpDvTtLOAc4GrJZ0IrACOrak/q1FEw9Ejs9q0bdhGxK+BZidTTs3Zi5lZT9p2GMHMrJ04bM3MMnDYmpll4LA1M8vAYWtmloHD1swsg7Y99cusytNPP11ZX7RoUaZOzAo+sjUzy8Bha2aWgcPWzCwDh62ZWQYOWzOzDBy2ZmYZOGzNzDLwebbWkUaOHFlZnzq1+a9wXnPNNQPdjpmPbM3McnDYmpll4LA1M8vAYWtmloHD1swsA4etmVkGDlszswx8nq11JKnZ/3JvVg8f2ZqZZeCwNTPLwGFrZpaBw9bMLAOHrZlZBg5bM7MMHLZmZhm07Xm2kiYAlwFjgADmRsRXJc0BTgYeTrOeFREL6unSBst9991XWV+8eHFlfdGiRQPZjlmP2jZsgU3AxyLiDkk7ArdLWphqF0bEBTX2Zma2hbYN24hYA6xJ15+UtBQYX29XZmaNdcSYraRJwAHArWnSaZLuljRP0ugmy8yWtFhS9edNM7MB0PZhK2kU8H3g9Ih4ArgI2BvYn+LI90uNlouIuRFxUEQclK1ZMxuy2jpsJW1HEbRXRMR8gIhYFxGbI+J54GLg4Dp7NDODNg5bFT/r9G1gaUR8uTR9bGm2o4EluXszM+tOEVF3D/0i6VDgZuAe4Pk0+SxgOsUQQgDLgQ+mL9Oq1tWeG8GsjUTEkP7dy7YN24HksDUbfEM9bNt2GMHMrJ04bM3MMnDYmpll4LA1M8vAYWtmloHD1swsA4etmVkGDlszswwctmZmGThszcwycNiamWXgsDUzy8Bha2aWgcPWzCyDtv0PHwfYBmBF6fbuaVorcm9916p9wdDpba8BWk/b8u/ZNiBpcav+32Ture9atS9wb0OJhxHMzDJw2JqZZeCwbWxu3Q1UcG9916p9gXsbMjxma2aWgY9szcwycNiamWXgsC2RNE3SfZIelHRm3f2USVou6R5Jd0paXHMv8yStl7SkNG1XSQslPZD+Hd1Cvc2RtDptuzslHVFTbxMk/UrSvZJ+L+mjaXqt266ir5bYbp3CY7aJpGHA/cBbgVXA74DpEXFvrY0lkpYDB0VE7SfAS3oj8BRwWUS8Jk07H9gYEeemN6rREfGJFultDvBURFyQu59uvY0FxkbEHZJ2BG4H3gnMosZtV9HXsbTAdusUPrJ90cHAgxGxLCL+DFwFHFVzTy0pIm4CNnabfBRwabp+KcWLNbsmvbWEiFgTEXek608CS4Hx1LztKvqyAeSwfdF4YGXp9ipa6wkXwPWSbpc0u+5mGhgTEWvS9bXAmDqbaeA0SXenYYZahjjKJE0CDgBupYW2Xbe+oMW2Wztz2LaPQyPiH4C3Aaemj8stKYqxqVYan7oI2BvYH1gDfKnOZiSNAr4PnB4RT5RrdW67Bn211HZrdw7bF60GJpRu75mmtYSIWJ3+XQ/8gGLYo5WsS2N/XWOA62vu5wURsS4iNkfE88DF1LjtJG1HEWhXRMT8NLn2bdeor1babp3AYfui3wH7SJosaXvgvcC1NfcEgKSR6YsLJI0EDgeWVC+V3bXAzHR9JvCjGnvZQleQJUdT07aTJODbwNKI+HKpVOu2a9ZXq2y3TuGzEUrSqS1fAYYB8yLi8zW3BICkl1EczULxs5jfqbM3SVcCUyh+gm8dcDbwQ+BqYCLFz1UeGxHZv6hq0tsUio/CASwHPlgaI83Z26HAzcA9wPNp8lkU46O1bbuKvqbTAtutUzhszcwy8DCCmVkGDlszswwctmZmGThszcwycNiamWXgsDUzy8Bha2aWwf8DGcsO8F8GKnAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7aQN6oyWaDp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}